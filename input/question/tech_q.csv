position,question,topic,example_answer
be,Compare Relational DB (SQL) vs NoSQL. It's also really nice to know about newSQL (a kind of auto sharding DB which support SQL stuff but scale like NoSQL),database,"Relational DB is organized by schema, table. All records in a table must be in the same structure, follow some constraints. Relational DB guarantees ACID characteristics so it is safe and stable.NoSQL is something that is not relational DB. Currently, it contains 4 main kinds:- The first kind is Document. In this kind, each piece of data is a JSON document.- The second is Key-Value DB. Simply, it is like a hash map that maps one key to one value.- The third is Wide Column DB. Records in a table can have a different number of columns.- The last one is Graph which is suitable for some graph-like data, for example, connections of people on a social network."
be,How these 2 things can scale up?,database,"Usually, people scale up Relational DB vertically. Add more CPU, more RAM, more storage. An additional thing we can do is sharding, that device data into different clusters, different nodes. Due to ACID characteristics, relational DB needs to do more work when writing and reading data to ensure those characteristics.Cause NoSQL sacrifices one or some ACID characteristics, it can be easily scaled horizontally just by simply adding nodes."
be,3 normal forms in DBMS,database,"The first normal form is about making everything atomic. It means a column stores a single value, not multiple values.The second normal form is about removing partial dependencies. It means no column depends only on a subset of the candidate key of the relation.The third normal form is about removing transitive dependencies. It means there is no relationship that column A depends on column B, and column B depends on column C."
be,ACID of SQL and BASE of NoSQL? Why NoSQL is eventual consistency?,database,BASE:- Basically Availability- Soft state- Eventually consistency
be,What is parameterized statement (in Java it's prepared statement)? How does it work **internally**?,database,"A parameterized statement is a statement that we can customize, like changing filter conditions."
be,What is SQL injection? How to avoid it?,database,SQL injection is when the attacker sends a parameter that contains SQL queries and hopes this query will be executed in the system's database.SQL injection can be avoided by escaping special characters in the params that users submit to the system.
be,"How many ""requests"" you have to send to Database in a single prepared statement query? // one for compile and one for execute",database,"It includes 2 steps, compile and execute.First, the database management system will compile the statement template then store the result without executing it.Next, the necessary values will be bound into the compiled statement template, then the statement will be executed."
be,Can you reuse the compiled query multiple times? (does it help to speed up your application?),database,"Yes, we can reuse the compiled query multiple times with different bound values. And yes it speeds up the application."
be,How indexing works internally?,database,Indexing adds a data structure with columns for the search conditions and a pointer. The pointer is the address on the memory disk of the row with the rest of the information. The query looks for the specific row in the index; the index refers to the pointer which will find the rest of the information.
be,How composite indexing works?,database,"It's like a single index but the key is a compound key, which is the combined values of these columns that are indexed.Let셲 say we have an index defined on 4 columns  col1, col2, col3, col4. With a composite index, we have search capability on col1, (col1, col2) , (col1, col2, col3) , (col1, col2, col3, col4). So we can use any left side prefix of the indexed columns, but we can셳 omit a column from the middle & use that like  (col1, col3) or (col1, col2, col4) or col3 or col4 etc. These are invalid combinations."
be,How to know your query is using index?,database,"By adding ""explain"" in fe of the query, we will get how the query ran and if it uses index or not.The query optimizer will use index automatically if possible and chose the index that it thinks is the best. And we can force our query to use an index by specifying it in the query."
be,How index work in this case: `WHERE age = 5` and `Where age > 5`? The complexity to go to the next record?,database,"It depends on the index type is hashing or B-Tree. If the index type is B-Tree, there is no difference between these two cases. The complexity to go to the next record is O(1) because all the leaves are linked together as a doubly linked list."
be,Indexing with char?,database,"For text fields, index on that column only is used when filter condition filters a prefix of this column."
be,"Compare `WHERE id = 'a' AND id = 'b' AND id = 'c'` vs `WHERE id in (a, b, c)`?",database,"In MySQL, the values in the IN list will be sorted and MySQL will use binary search to check if the current value is in the list. So the check operator will cost O(log N) complexity, with N being the number of elements that need to be compared."
be,Complexity of this query `SELECT * FROM abc ORDER BY name LIMIT 10 OFFSET 1000000` // SELECT 10 record from offset 10^6 after sort by name (which is a char)? How to optimize it?,database,O(N log N) with N being the total number of records.We can optimize the query by indexing the column name.
be,What is the complexity of COUNT(\*) query?,database,"In MySQL, it depends on the storage engine that the table uses. For MyISAM, the total number of rows is stored with each table so the complexity is O(1), but for InnoDB, it is O(N)."
be,How to write query to avoid full table scan?,database,We need to write a query that takes advantage of index if any.
be,What is Database Replicating? When do we need it?,database,Database replicating is the act of making one or many copies of a database to increase the availability of data.
be,What is bin log? How Master DB sync with Slave DB?,database,"When data is written into DB, first it will be stored in Write Ahead Logs (bin logs). Master DB send these log to Slave DB so Slave DB can also have those changes."
be,Can a Slave DB be a slave of another Slave DB (we do not need to sync from Master DB directly)?,database,Yes it can.
be,What is Database Sharding? When we need it?,database,"Sharding happens when a database is too big so the query time increases. We shard database to improve query time and also increase the availability of the system. If one shard is down, there is only a portion failure."
be,How to ensure primary key is globally unique when sharding?,database,"We can have a key generating system that generates keys for all servers. But this server can be a central point of failure. To improve that, we can have multiple servers to generate keys, each server is in charge of some range of keys."
be,How query can work when we sharding (the data might be in the same or different tables/dbs)?,database,"For a query that we might know exactly where data is using its key, we can detect which shard is holding necessary data and query on this shard.For a query that data might be on a lot of shards, we can execute the query on all possible shards then aggregate data later."
be,What is database transaction?,database,"Relational DB ensures Atomicity by Transaction. A transaction is a collection of operations. Either all of those operations are executed, or non of them is executed. It ensures there is no time when something is failed in the middle and we have no idea when or how to roll back."
be,"What is dirty read, dirty write, read skew, phantom read, write skew, lost update?",database,"Dirty read is when transaction A is allowed to read a value that has been modified by transaction B but has yet been committed. This may cause a problem when transaction B fails and rollback happens, so the value that A reads is not the value in database.Dirty write is when transaction A is allowed to write a value that has been modified by transaction B but has yet been committed.Read skew is when someone needs to read one value multiple times in a transaction. But the result each time is different.Phantom read is when a transaction needs to get a collection of records multiple times in a transaction. But the number of records each time is different.Write skew is when someone needs to read some object then update some object based on the result of the read value.Lost update is a special case of write skew when read and update happen with the same object.Read committed is a weak isolation level that is used to guarantee no dirty read and no dirty write. It assures that all object that can be read is already committed and no write can happen to an uncommitted object.2 stronger isolation levels are snapshot isolation and serializable snapshot isolation. For snapshot isolation, a transaction can read the old version of a value while other transactions are writing. For serializable snapshot isolation, a transaction cannot read while other transactions are writing. It is called 2PL - two-phase locking."
be,Distributed transaction? How to make a transaction when a query needs to access multiple DB?,database,"A distributed transaction is needed when data that suppose to be in a transaction is stored in different databases. There is a technique called 2 phase commit (2PC) that helps to resolve this situation.There will be a coordinator which orchestrates the whole transaction. When the transaction begins, the coordinator generates a global transaction ID for all participants of this transaction. Each participant will execute their own transaction that attaches to the global transaction. When all local transactions are done, the coordinator sends the prepare request for all participants. This is the first phase - the prepare phase in 2PC. Participants can respond yes or no, indicate if they can commit this transaction or not. And the ""yes"" answer is the promise that it will be able to commit this transaction no matter what. If all participants respond ""yes"", the coordinator can decide to commit this transaction and send the commit request to all participants. This is the second phase of 2PC, the commit phase. Once the commit decision is made by the coordinator, it is irreversible. It will keep resending commit requests to participants no matter what. If the coordinator fails, the participant must keep the status of being able to commit this global transaction no matter what."
be,How TCP open a connection? What does it need to open a connection?,networking,"TCP needs to open a connection to determine if the server is available to respond and know there is a way from it to the server before transferring data. To open a connection, firstly server must be bound and listen to a port, it is passive open. Then a process called 3 way handshake happens:- Client sent SYN packet to the server with sequence num A- Server sends SYN-ACK packet to the client with rand sequence num B and ack num A' = A+1- Client sends ACK packet to the server, with ack num B' = B+1 and the sequence number is A' ( the ack num it received in step 2)"
be,Why there are 3 way handshakes but not 2 way?,networking,"2-way will establish a half-duplex connection only. It means this is a one-direction connection the client is the only sender and the server is the only receiver. 3-way will establish a full-duplex connection, both client and server are sender and receiver."
be,"What is syn, ack mean?",networking,Syn means synchronizaton. SYN packet is sent when the sender tries to connect to the receiver.Ack means acknowledgment. ACK packet is sent by the receiver to the sender to help the sender know that the SYN packet that it sent before reached the destination successfully.
be,"Why they have to send 2 ""random"" sequence numbers? The purpose of this sequence number?",networking,"Sequence numbers are used to keep track of the order of data. The initial sequence number needs to be chosen randomly so the data in one flow will not be conflicted with other data bytes in other flows which are transmitted in the same TCP connection. Because sequence number is 32-bit integer so the maximum value of a sequence number is 2^32 - 1. So if the amount of data is greater than 4GB, at least one sequence number value will be reused."
be,What if the 3rd handshake fail? How the server can detect it and what does it do in this case?,networking,Retry and timeout.
be,What happens if some bits are wrong due to connection errors? How to detect them and fix them?,networking,"If some bits are wrong, the checksum of this packet will not match. In this case, the receiver will discard this packet."
be,"What will happen if some ""packet"" is missing on the way?",networking,"When a packet is missing, network congestion is assumed to happen. TCP has its own way to deal with network congestion. It is called TCP Congestion control. It starts when slow-start phrase, in which the transmit rate (congestion window) grows exponentially, doubling each round trip time. When a packet is lost, congestion avoidance begins. The transmit rate is cut into half, then increase linearly, usually by 1 each RTT."
be,How TCP close the connection?,networking,"It does a 4-way handshake. Firstly peer A send a FIN packet to peer B. Then peer B send an ACK packet for the FIN it receives. After that peer B send it own FIN packet to peer A. Then peer A send ACK packet to the peer B. Connection is over.Step 2 and 3 can be merged by one, so it will be 3-way handshake instead."
be,What are the differences between TCP and UDP? And in which case we use which?,networking,"The key difference between TCP and UDP is TCP has a mechanism to resend loss packets, but UDP doesn't. So TCP suits in the case where packet loss can not be acceptable, like transfer file, request... UDP suits in the case packet loss can be tolerated, like in real-time voice/video calls."
be,How Ping command works? What is TTL? How does TTL will be changed?,networking,"Ping command sends a packet to the destination server, waits for the response then calculates round trip time.Time-to-live is a mechanism that prevents a packet to be forward around the internet forever. Like the name, it is the number of times or hops, that packet can be forward before it is discarded by a router. Each time a router receives a packet, it reduces TTL of that packet by 1. If TTL reaches zero, the router will discard this packet then send an ICMP message back to the sender. The recommended default value of TTL is 64."
be,How HTTP works?,networking,HTTP is an application protocol that transfers hypertext messages between client and server. It uses specific request methods to perform specific tasks. They include:- POST: create a new entity- PUT: update an entity entirely- PATCH: update an entity partially- GET: get value- HEAD: get value without data- OPTION: get all the methods that the server supports for this resource- ...
be,Why did people say that HTTP is stateless? The reason they make it stateless?,networking,People say HTTP is stateless because each request is executed independently. Stateless provides high scalability.
be,Can we make a persistent HTTP connection? pros and cons of this way?,networking,"Yes.HTTP persistent connection keeps one connection to send many objects. It can help reduce CPU resources, travel time, network traffic... But resources will be occupied and not be available to others."
be,Why HTTP require cookie each time we send the request?,networking,No it doesn't required cookie.
be,Can someone use your cookie and log in your Facebook account? How to migrate this?,networking,"If Facebook stores authentication straight info in cookies normally and does not do anything special, the answer is yes.We can mitigate it using HttpOnly flag."
be,What is HTTP session? How does authentication work in HTTP? What is JWT?,networking,"Cause HTTP is stateless, HTTP session and cookie are two ways to connect some requests together.Session is created and stored at server side, usually just temporary. Session ID will be sent to client, client may submit it to server as a cookie, or url parameter, so server will know which session this request belongs to. Session ends when user logout, close web browser, or timeout. Session is more secure, compared to cookie.Cookie is stored at client browser. Cookie will expire at the set time.JWT is standard for creating data with opt-in signature and encryption, used for authentication."
be,"Which type of ""data"" HTTP can help us to get or push? (binary file? image? text file? video file? music file?)",networking,"HTTP can help us get or push all kinds of files like text, image, binary, video, music..."
be,REST/RESTful?,networking,"REST stands for representational state transfer. It's a set of constraints that describes how an API should work. It includes four main principles:- Client-Sever: There is always a client and a server. Client sends request to server and server reply with response.- Stateless: Server handles client request independently. Client's request must contain enough information that server requires.- Uniform interface: For example, a resource is identified in URI, HTTP response always comes with status and body.- Cacheability: Client can cache response.An API that follows REST constraints is called RESTful."
be,AJAX technique?,networking,"AJAX uses XMLHttpRequest to communicate with server. The first ""A"" stands for asynchronous, which means using AJAX, we can communicate with server without reloading the page."
be,How HTTPS work?,networking,"HTTPS uses SSL - Secure Socket Layer to protect the communication by encryption. Before exchanging data, an SSL connection must be established first, then data will be encrypted then transferred safely."
be,"When you type ""google.com"" into your browser, that will happen when you type enter till everything is displayed on your screen?",networking,"The first thing that happens is DNS lookup. The browser will get the corresponding IP address with the domain name from its cache, from the computer cache, from the local host file. If there is no data in these places, then the browser will send a request to DNS server to obtain the IP address. ([More](https://serverfault.com/questions/208172/how-does-my-browser-know-where-to-get-data-from-a-server))The second thing is browser will detect if HTTPS is required or not in case we don't type the full url. Browser can get this information from its history data, from a preload list. Otherwise, it will send an HTTP request. (When server receives the request, server can do appropriate action to force user uses HTTPS if it wants.)The third thing is TCP connection establishment. The TCP connection can be established by a process called 3-way handshake. If HTTPS is used, after TCP connection is established, the SSL connection establishment process will start.Fourthly, after having the connection, client will send data to the server and server will send a response back to client through this connection.The next thing is browser will render the data from response based on the content type. If there is no content type, the broswer will read the body of response to know which kind of data it is. If the content type is html, broswer will parse it then get resources like images, js files, css files if necessary."
be,DNS lookup (in case you already access google.com before and also in case you do not know the IP of google.com),networking,"DNS information is cached in browser and operating system. If there is no corresponding data in both of these places, DNS request will be sent to the DNS resolver. The resolver will make necessary request to Top Level Domain server, to Domain Name server to get the IP address of the requested host, then return to user."
be,Which protocol DNS use and why?,networking,"DNS primarily uses UDP as transport protocol because it's fast and DNS data usually is small and fits an UDP packet.TCP is used when the data is greater than 512 bytes, which can not be fit on a single UDP packet."
be,"How to know ""google.com"" require HTTP or HTTPS? how browser can know and redirect from HTTP to HTTPS?",networking,"There are at least two ways that make the web we are accessing change from using HTTP to HTTPS.The first way is the server will redirect to HTTPS when the HTTP request comes.The second way is using HSTS, HTTP strict transport security. When a browser sends the first HTTP request to server, server will add a header into the response indicates that the next request will require using HTTPS. Browser will automatically use HTTPS next time based on that information. In addition, browsers like Chrome have a HSTS preload list, they will automatically use HTTPS for all of the sites in that list."
be,"After you get the HTML content for ""google.com"" how to get the \*.js and image files?",networking,Chain requests.
be,"After your browser display ""google.com"" fully, is there any connection open?",networking,It depends on if the connection is keep alive or not.
be,What is the connection pool? It's advantages and disadvantages? How to implement connection pool in your programing language?,networking,"Connection pool is a cache of database connections so connection can be reused when future request comes. Opening a connection is costly, so after a connection is opened, it is placed into connection pool so it can be reused later."
be,What is socket?,networking,Socket is an endpoint for a program to send and receive data across the network. Socket allows communication between processes on the same machine or different machines.
be,"Why do we need socket? Why socket is a ""file"" in linux?",networking,"Not only socket, everything is treated as files in Linux operating system. It provides a common and universal interface for things to communicate in this OS."
be,What is the maximum number of connections a server can handle? (if it has unlimited resource) (in case of the same client and in case of multiple clients),networking,"TCP has 4 fields to identify the uniqueness of a socket: source IP, source port, destination IP, destination port.Theoretically, if server listens on a port, a client can open a maximum of 2^16 connection. that's is the maximum number of ports a client can open. For multiple clients, the number can be multiplied by 2^32, it is the possible number of source IP addresses. So the maximum number of connections is 2^48.But in practice, the maximum number of connections depends on the kernel configuration. Because each socket needs a file descriptor, the number of sockets is limited by the maximum number of file descriptors that the machine allows. In addition, a file descriptor needs a certain amount of memory so it can also be limited by the number of available memory."
be,"When you open multiple tabs on your chrome, how OS knows which packet (both sending and receiving) correspond to which tab? (how about in se you open many tabs to the same page ""for eg: google.com"")",networking,Because each connection has its own socket that is used to exchange data.
be,"What are the maximum numbers of connection your machine can connect to ""google.com"" (if you have unlimited resource)",networking,"It is the maximum number of ports my machine can open, which is 2^16."
be,Can two processes listen to the same port on your machine? Why? How?,networking,"Yes, and it is useful for multicast purpose. Socket needs to be specified as a reused socket before binding to do so."
be,"What is buffer? why we always need buffer when working with ""file""?",networking,Buffer is a segment of memory that is reserved to store necessary data being processed. Buffer helps reduce the processing time.
be,What is unix socket? When to use it?,networking,Unix socket or IPC socket is a data communication endpoint that allows processes in a same machine to communicate with others.
be,What is TCP proxy? reverse proxy? and VPN?,networking,"A TCP proxy server is a server that acts as an intermediary between and client and server. Its goal is to hide clients on the internet. The server only knows that request came from the proxy server and doesn't know about the actual clients.A reverse proxy, on the other hand, protect server from client. It hides server from client. from the client point of view, client sends data to the reverse proxy and receives data from it too.VPN allows devices on a public network to be connected as they are in a private network."
be,How your router at your home works?,networking,"Router connects devices within a network by forwarding packets between them. Packets might be sent between devices, or from a device to the internet and vice versa. It maintains an ARP (address resolution protocol) table to know where to forward a packet to."
be,"Inside LAN network, it uses IP or MAC address? Why?",networking,"Inside a LAN network, it uses MAC address cause we don't need a layer 3 protocol to communicate between devices that are in the same local network."
be,How does it know which packet comes from (or arrive at) which machine?,networking,Router will use the ARP table to know the MAC address of the device which this packet is sent to.
be,What is the difference between Hub and Switch inside LAN?,networking,"Hub is operated on Physical layer and supports only broadcast transmission.Switch is operated on Data link layer and supports unicast, multicast, and broadcast transmission.s"
be,How load balancer works?,networking,"Load-balancer distributes load to servers. It can do it randomly, uses an algorithm like round-robin, or distribute requests based on the current load of each server."
be,"When the server wants to send data back to the client, does the connection need to go through the load balancer?",networking,It depends on whether the server and the load balancer are in the same private network and share the same IP address.
be,What is different between reverse proxy and load balancer?,networking,Reserve proxy acts as an intermediary without any load distributing operation.
be,Can load balancer be a bottleneck? (Because it is the end point of too many requests) (bottleneck about RAM or CPU or Network?),networking,Yes. And it also can be a single point of failure.
be,"What is `process`, `thread`? What are the differences between them?",operating system,"A process is like a program in execution. And a thread is a segment of a process. Each process has its own memory and is isolated. Meanwhile, threads of the same process can easily communicate with other threads, access common variables, memory."
be,"What data `process`, `thread` need to live? Why do they say that Thread is a lightweight process?",operating system,Thread is a lightweight process because it does not cost much CPU to switch between threads as between processes.
be,How CPU switch (context switch) between processes/threads? How data is to ensure safety? (in case single CPU core and multiple CPU cores),operating system,"When process context switching happens, the state of the current process will be stored in Process Control Block (PCB), so this process can be resumed later. It includes the value of the CPU registers, the process state, and memory-management information. Data pages in memory of the current process can be replaced or not, depending on the availability of memory, and the memory-management method of the operating system.When thread context switching happens, the state of the current thread will be stored in Thread Control Block (TCB), so the thread can be resumed later. It includes the value of the CPU registers, the thread state, a program counter, a stack pointer, and a pointer to the PCB of the process to which the thread belongs. There is one major difference in thread context switching compared to processes: the address space remains the same (the is no page replacement)."
be,What is multi-process and multi-thread? When should we use which?,operating system,"Multi-processing is when more than 2 processes are running simultaneously on a computer. This is probable in a multi-processor computer, where each processor handles a process.Multi-threading is when more than 2 threads created by the same process are running simultaneously."
be,Process has how many states? How does it change between each state?,operating system,"Basically, a process has 5 states: new, ready, running, wait, and terminate. New is the status of the process when it is created. At the ready status, the process waits to be assigned to a processor. When the process is assigned to a processor, its status becomes running and the processor executes the process instructions. If the process need something like I/O, or the CPU is assigned for another process, process status will become waiting. When all the instructions are executed, or the process is terminated by OS, it moves to terminate state where it waits to be removed out of the main memory."
be,Scheduling algorithm,operating system,"There are many types of scheduling algorithms like first come first serve, shortest job first, shortest remaining time first, round-robin, etc."
be,What will happen if a process is waiting? Or a thread is sleeping?,operating system,"When a thread is sleeping, other threads might be running.When a process is waiting, OS can run another process."
be,How CPU detects that a thread is sleeping? Or detect when it wants to run?,operating system,"OS has an OS scheduler that keeps track of the list of processes and their status. When the thread goes to sleep, it tells the scheduler that it gives up its time slide, and it shouldn't be wake up until a certain time has elapsed. The next time the scheduler looks at this process, if the time has elapsed, it will change this thread status as ready to run."
be,What is thread-pool? How to use it? Describe how to create a thread-pool in your programming language,operating system,Thread pool is a design pattern that's used to manage concurrent execution. It is also called as worker model. A thread pool has a limited number of threads to allocate for concurrent execution.
be,Can 2 different processes access or change data of each other address space? (this question may make you confuse with your knowledge about virtual memory),operating system,"Cause memory can be used by a process at this time and later by another process, yes an address space in general does not belongs to any process and can be changed by many processes, but in a certain time, an address space belongs to a process only and can only be modified by this process."
be,Can 2 processes use the same library (for eg: libc is required to every process)? How?,operating system,"It is possible if the library is a shared library, not a static one. Each process has its own virtual memory address that refers to the same physical memory address that stores the shared library."
be,How 2 processes can communicate with each other? (There are a lot of ways but focus on the OS's way),operating system,It can use a shared resource or pass messages to other processes.
be,What is child-process? How to create a child-process?,operating system,"Child process is a process created by another process. Child process inherits most of properties from its parent, such as environment settings, process directory, from its parent. It does not inherit some properties like process id, lock..."
be,Can it read/write data on it's parent process?,operating system,"No, it cannot. If it wants to communicate with its parents, it has to use a separate shared memory segment or use a socket."
be,"What is copy on write (COW), Dirty COW? **(this concept is important to understand OS)**",operating system,"Copy on write is when multiple callers ask for a copy of a resource, OS can return the pointer to the old resource and only make the private copy for a caller when necessary, like when the caller wants to modify this resource. The advantage is if the caller makes no modification, no private copy needs to be created."
be,What will happen when child-process changes a variable of parent process?,operating system,Child process cannot change variables of its parent.
be,If file descriptor also be inherited by the child process. What if 2 processes can handle a same file descriptor or even a same socket?,operating system,"2 processes can handle the same file descriptor/socket. To prevent other processes does further things with the socket that the current process wants to close, we can use shutdown function instead of close function to stop other processes from using this socket."
be,What is critical zone?,operating system,Critical zone or critical region is the segment of code where processes access shared resources.
be,What is race condition and how to handle this case?,operating system,Race condition is when two threads access a variable at the same time. It can lead to data inconsistency if the operations are executed in a certain order. To prevent this we can take advantage of some locking mechanisms.
be,What is locking mechanism? mutex? semaphore? spinlock? read lock vs write lock?,operating system,"Mutex is a mutual exclusive flag to detect if the desired resource is free and claim it for use.Semaphore is a generalized mutex, to control the number of available resources.Spinlock is a mechanism in which a process keeps asking for the availability of the resource via polling."
be,What is deadlock and how to avoid deadlock?,operating system,"Deadlock is when there is a circle where some processes lock something and wait for something that other processes have already locked.Deadlock happens when all of these conditions happen:- Mutual exclusion: It means processes want to access the same resource.- Hold and wait: When processes need more than one resource and it already has some, it will hold them and wait for the rest.- No preemption: A process can not take away resource that is being held by other processes.- Circular wait.This can be avoided by making processes release their locked variable when they cannot get the other necessary resource, or granting some preemption permission for some processes."
be,What is virtual memory? Why do we need it? How does it work?,operating system,"Virtual memory is a memory management technique where secondary memory (eg disks) can be used as main memory like RAM. Virtual memory allows computers to operate quite normally when memory shortages happen.When a process is in use, its data is stored in a physical address using RAM. If at any point, RAM space is needed for something more urgent, data can be swapped out of RAM into virtual memory and swapped back again when needed."
be,How large virtual memory is?,operating system,"The size of virtual memory is unlimited. Actually, it is limited by the disk space but the disk space is quite large so we can consider it unlimited."
be,What is paging?,operating system,Paging is the memory management mechanism that allows OS to get the processes from the secondary memory to the physical memory in form of fixed-size blocks called pages.
be,Can 2 processes map to the same physical address? How and in which case?,operating system,Yes. Each process has its virtual memory address and can be mapped to the same physical memory address when it is processed by CPU. The condition is they need to take turns to be processed.
be,What is heap space and stack space?,operating system,Heap space is for dynamic memory allocation. Stack space is for static memory allocation.
be,What will happen with memory when you open an application?,operating system,The application will be loaded to RAM when we open an application.
be,What will happen when you call another function (with parameters) or return from a function?,operating system,"When we call another function, local variables of the new function will be put to stack, and the stack register will be moved to the appropriate position. If the function takes parameters, it will create a duplicate version of those parameters (If the parameter is a pointer, it still creates a new pointer that points to the same address).When a function returns, local variables will be pop out of stack and the stack pointers will also be moved to the appropriate position."
be,What causes stack overflow?,operating system,Stack overflow happens when the stack memory runs out. The most common cause of stack overflow is infinite recursion.
be,What is dynamic allocating? How does it work?,operating system,Dynamic allocation is the act of asking for a specific segment of memory from the OS.
be,How does deallocation work?,operating system,Deallocation announces for the OS that this segment of memory is free now and can be used by other processes.
be,What happens when your computer is full of memory?,operating system,To be defined. (It will throw error?)
be,"Why you do not need to ""deallocate"" local variable?",operating system,Cause local variable is allocated in stack and will be destroyed automatically after the function returns.
be,How does Garbage Collection work? When it will be triggered?,operating system,"Garbage Collector (GC) will detect which object in heap memory has no reference. It means this object cannot be used anymore and it's safe to sweep this object away. GC will run periodically for languages that have GC. Besides, languages like Java or Python have a mechanism to invoke GC manually."
be,What is a pointer? What difference between pass by value and pass by reference?,operating system,"Pointer is the address of a variable. Pass by value means passing only the value of the variable, while pass by reference means passing the address of this variable in the memory."
be,Where global variable will be saved?,operating system,Process memory is divided into four sections:- Text section: when the code is stored.- Data section: when static and global variables are stored.- Stack section: where local variables are stored.- Heap section: where dynamically allocated variables are stored.
be,"Why in Linux everything is ""file""?",operating system,"It will create a uniform interface for operations on Linux systems. To be more exact, everything in Linux is a stream of bytes that is represented as a file descriptor."
be,How does mouse/keyboard/monitor... communicate with your computer?,operating system,It streams a stream of bytes into our computer.
be,What is file descriptor?,operating system,File descriptor is a unique identifier for a file or input/output resources.
be,What is buffer? Why do we need buffer?,operating system,Buffer is a segment of memory that is reserved to store necessary data being processed. Buffer helps reduce the processing time.
be,What will happen if 2 processes read/write to the same file?,operating system,"If 2 processes read/write to the same file, it means they use the same file descriptor to access this file, also the file offset. So the changes that one process does with the shared file are visible to the other process. ([More](https://walkerlala.github.io/archive/what-if-write-to-the-same-file.html))"
be,What is system call (syscal)?,operating system,"A syscall is a programmatic way that allows a computer program to request a service from the kernel of the operating system, on which the program will be executed."
be,How to do a syscal?,operating system,Some libraries provide functions that allow us to interact with the kernel.
be,What happens with CPU when we execute a syscal?,operating system,"CPU will execute the system call handler, which will perform some action to fulfill the syscall. ([More](https://www.ibm.com/docs/en/aix/7.2?topic=calls-understanding-system-call-execution))"
be,What is user space and kernel space?,operating system,"Memory is divided into kernel space and user space:- Kernel space is where the code of the kernel is stored, and executed.- User space is where the code of everything other than the kernel is stored and executed."
be,What is in-memory cache? (memcached/redis),operating system,In-memory cache is the data storage layer between the application and the database. It stores data in memory which has a much fast data access speed so it is used to speed up the application.
be,LRU? implement LRU in your program language! (How about multi-thread?),operating system,"Least recently used is a strategy to invalidate cache. As the name already said, it will remove the least recently used data when the cache is full. We can implement LRU using a combination of hashmap and a doubly linked list."
be,How to migrate Cache stampede?,operating system,"Cache stampede happens when a lot of data need to be queried at the same time but most of them haven't been cached yet, so the number of queries that need to be executed on database is huge. We can mitigate cache stampede by warming cache, cache locking, or predicting when the cache is expired so we can update cache."
be,Hash vs Encrypt vs Encode,security,"Hashing is the act of transforming data from arbitrary size to a fixed size value. For example the module operator.Encode is a way to transform data to another form to preserve usability. For example, 2 bit 0 and 1 can represent almost every kind of data we know.Encryption is the act of transforming data to another form to preserve confidentiality. For example, AES encryption uses a secret key to transform data into an encrypted string. Only the person who has the same key can decrypt the encrypted string and read the message."
be,Are there any way we can crack Hash,security,"We can always try to guess the original string by calculating the hash of every possible input then comparing the result with the hash string. However, due to hashing collision, there might be more than one input that has the same output."
be,Symmetric vs asymmetric encryption? AES vs RSA?,security,Symmetric encryption uses the same key for both encrypting and decrypting data.Asymmetric encryption uses a public key to encrypt and a private key to decrypt data.
be,Fast Hash vs Slow Hash?,security,"Fast Fash is the type of hash function with fast computation time and Slow Hash is the type hash function with slow computation time. Fast Hash is used for checking the integrity of data, while slow hash is used for hashing password."
be,When we use Encode??,security,"We use Encode so data can be represented in a better use form. For example, we transform text, audio, image into 1 and 0 so computers can understand, store, process, etc."
be,What is the perfect hash function?,security,A perfect hash function of a set is a hash function that maps distinct elements of this set to elements of another set without any collisions.
be,What is the load factor of hashing?,security,"When a map initiates, two things need to be considered are the initial capacity and the load factor. The initial capacity is the capacity of the hash table underlying the map. When the load is bigger than the load factor, it means the underlying table is quite full, a process called rehashing happens, a twice bigger size hash table is allocated to store the data of the map."
be,SSL/TLS,security,"SSL - Secure Socket Layer, is the original encryption protocol developed for HTTP. It now has been replaced by the TLS, Transport Layer Security, but the name SSL is still widely in use. Whenever a client makes a connection to a server over HTTPS, the client and server will initiate a TLS handshake, which happens after the TCP handshake has been finished.The steps of a TLS handshake will vary depending on the key exchange algorithm in use. The RSA key exchange algorithm is used most often. The steps are as followed:1.  The client kicks off the handshake by sending a ""hello"" message to the server. The message will include which TLS version, cipher suites the client supports, and a string of random bytes known as the ""client random.""2.  The server sends back a message containing the server's SSL certificate, the server's chosen cipher suite, and the ""server random"" - another random string of bytes.3.  Authentication: The client verifies the server's SSL certificate with the certificate authority that issued it.4.  The client sends the ""premaster secret"", another random string of bytes. The premaster secret is encrypted with the public key from the SSL certificate and can only be decrypted with the private key by the server.5.  The server decrypts the premaster secret.6.  Session keys created: Both client and server generate session keys from the client random, the server random, and the premaster secret. They should arrive at the same results.7.  Client is ready: The client sends a ""finished"" message that is encrypted with a session key.8.  Server is ready: The server sends a ""finished"" message encrypted with a session key.9.  Secure symmetric encryption achieved: The handshake is completed, and communication continues using the session keys.TLS handshake can also use Diffie-Hellman (DH) as the key exchange algorithm. The steps then will be:1.  Client's hello is the same as above.2.  Server's hello also sends the server's random, chosen cipher suite, SSL certificate. The server also includes a digital signature, created by encrypting the client random, the server random, and its DH parameter using the private key.3.  The client decrypts the server's digital signature using the SSL certificate's public key, verifying that the server controls the private key and is who it says it is. The client then sends its DH parameter to the server.4.  The client and server use the exchanged DH parameters to calculate a matching premaster secret independently.5.  Session keys created: Now both the client and server calculate the session key using the client random, the server random, and the premaster secret like in an RSA handshake.The rest is the same as the RSA handshake."
be,What is CA? how to verify certificate of a CA?,security,"CA stands for certificate authority. It is an entity that verifies the certificate of servers.When a server and a client want to establish an SSL connection, the server will send its public key to the client. So how the client knows this public key is the right one, and no man in the middle tries to interfere in this conversation. To do that, the server also sent a certificate with the public key. The client will ask the CA to verify if the public key is the correct key of the one in the certificate."
be,What is digital signature? What is HMAC?,security,"Digital signature is a mathematical scheme to verify the authenticity of data.HMAC stands for hash based message authentication code, is used to verify both data integrity and data authenticity."
be,"How to store credential information efficiency? (user password, config key, database credential, user information, secret key,.... )",security,"First, we need to know if we need to access the original value or not.For data like passwords, we don't need to access the raw password of users, so we can use some hashing function to hash the password and store it in the database.For data like user information, the raw data will need to be retrieved in some cases, so we need to use encryption, instead of hashing. To reduce the risk of data compromise, we need to store data and the encryption key in 2 different places."
be,"Describe a way to defense DDOS? (actually, there are many kinds of DDOS not just network or memory, so this question is pretty complicated)",security,"Block IP address, apply rate limit for IP, for users."
be,OOP. What is OOP? Why should we use OOP?,programming paradigm,"OOP stands for object-oriented programming. Like its name, OOP means focusing on objects and building things upon them. In real world, almost everything is an entity with some data and some behaviors, which OOP can be used to articulated quite exactly, compared to other programming paradigms like procedural programming or functional programming."
be,What is the 4 principles of OOP?,programming paradigm,"The four principles of OOP are encapsulation, abstraction, inheritance, and polymorphism.- Encapsulation is a feature of OOP that wraps things into a unity, like wraps methods and fields into a class, wrapping classes into a package.- Abstraction means when we use a class, we only care about its public things, like public fields, methods, and don't care about its private stuff, about how it is implemented under the surface.- Inheritance allows a class to inherit the properties and characteristics of other classes.- Polymorphism allows using the same type and the same function call for same same but different action of related entities."
be,What is composition? Compare composition vs inheritance,programming paradigm,"Composition is a has-a relationship. Like a house has rooms, a car has wheels. In OOP, the composition relationship is represented as fields in a class.Inheritance is an is-a relationship. Like a dog is an animal, a rose is a flower. In OOP, the inheritance relationship is represented as a class inheriting another class."
be,Interface vs abstract class,programming paradigm,"The key difference between abstract class and interface is the relationship between it and the classes that extend or implement it.When class A extends the abstract class B, class A is a B. For example, a cat is an animal. But when class A implements an interface C, it only means A has C characteristics, like the Cat class can implement Climbing Tree interface."
be,"What does private, protected, public means and what are the difference?",programming paradigm,"These keywords indicate the access scope of things like methods, fields in an OOP language.- Things with ""private"" scope can be accessed by things in the same class.- Things with ""default"" scope can be accessed in the same package.- Things with ""protected"" scope is being able to be accessed by things in the same package and outside things that has inheritance relationship.- Things with ""public"" scope can be accessed by everything."
be,FP characteristics,programming paradigm,"Some highlight characteristics of functional programming are:- Immutability: variable should be set once and not changed.- Pure function: the return value should depend only on the input value, and create no side effect.- Function is first-class citizen. We can create a function, assign a function to a variable, pass it as a parameter and return it as a value."
be,Explain as much as possible what happens when you access https://www.google.com/ .,networking,"The browser parses the value written on the URL to create an HTTP Request Message and sends a request to the OS. At this point, DNS Lookup is performed because requests cannot be sent to Domain.The DNS lookup process looks for an ip that matches the domain in the order of browser → hosts file → DNS Cache for Chrome. The DNS Lookup, which is commonly described, is found from the root domain server to the subdomain server.This request is contained in a packet by network control software built into the OS called the protocol stack, which adds control information to the packet and sends it to the LAN adapter, which converts it into an electrical signal.Packets are forwarded from the Internet connection router to the ISP via a switching hub, etc., and are directed to the Internet.It is transported to the carrier router by the access line and delivered to the core of the Internet. Packets flow between high-speed routers to their destinations.Packets that pass through the core arrive at the destination LAN, and after the firewall checks the packets, it sends them to the cache server to check if they need to go to the web server.Packets that arrive at the web server are extracted by the protocol stack, which restores the message and hands over to the web server application. The application creates the response data to the request and sends it back to the client, which is sent as it was delivered."
be,Explain the difference between TCP and UDP.,networking,"TCP is a connection-oriented protocol, and UDP is a protocol that transmits data in datagrams.TCP is a protocol that creates virtual circuits to ensure reliability (flow control, congestion control, error control) and is slower than UDP, which does not have a separate procedure to ensure reliability.TCP is therefore used for services where reliability is important, such as file transfer, and UDP is used for services where continuity is more important, such as streaming and RTP.+) However, UDP also does not guarantee reliability in UDP itself, and it can ensure that developers directly guarantee reliability. So HTTP/3 is based on a protocol called QUIC, which is based on UDP. In other words, UDP itself does not guarantee reliability, but it can be guaranteed with additional definitions."
be,Explain TCP 3 and 4 way handshake.,networking,"This is a question that TCP asks about the process of creating and removing virtual lines. If you've studied TCP, you'll know this much, and at actual interviews, we usually explain the network directly.TCP 3way handshake is the step of establishing a virtual line. The process is to verify that a client can send a request to a server, and that a server can send a response to a client. Send and receive SYN, ACK packets, send the SYN flag to any random number, and send the ACK flag plus a value of 1. The exact order is SYN(n) -> ACK(n + 1), SYN(m) -> ACK(m + 1).The tail question may arise why you specify an arbitrary random number. I know that to distinguish it from the existing request, and I've never thought about anything more.TCP 4-way handshake is a step in which the client notifies the server of the disconnection, confirms that the server has received it, sends the client, and finally disconnects. However, even if the server notifies you that the socket is closed, the client waits for a certain amount of time because the packet may arrive later."
be,Explain the difference between HTTP and HTTPS.,networking,"HTTP does not go through a separate encryption process, so packets can be intercepted and modified in the middle. As a result, we can see that security is vulnerable. HTTPS came out to compensate for this. Encrypts packets through the encryption layer in the middle."
be,Explain HTTPS and explain SSL Handshake.,networking,"HTTPS is the addition of a security layer to HTTP. HTTPS uses third-party authentication, public-key encryption, and secret-key encryption.Third-party authentication only trusts certificates registered with a trusted certification authority, and public key encryption is used to share private keys. Secret key encryption is used to encrypt data that communicates.The client sends a Client Hello after performing a TCP 3way handshake. The server sends a certificate (which also sends other information, but is something you can learn by searching). It is usually not required to that extent.) The client verifies that it is a registered certificate authority to trust the certificate it receives. This certificate is encrypted with the certificate authority's private key and can be verified with a public key. Clients (embedded in the browser) can obtain the information of the site and the public key of the server.The server's public key encrypts the secret key to be used for communication and sends it to the server. The server verifies this with a private key, and subsequent communication is encrypted with a shared secret key and communicates.Third-party authentication: certificate, certificate authority/public key encryption: certificate, secret key sharing/secret key encryption: communication process We were also asked why we used a combination of public key encryption and secret key encryption."
be,Explain the difference between GET and POST.,networking,"More HTTP method questions are often asked below. But you can only ask the difference between the two.The GET request requests information that exists on the server. The information returned at this time is not the information itself, but a representation of the information.(The following is related to REST, and you don't have to answer.) In general, it is not common to enter the Request Body, and for legacy systems, the request may not be accepted. A request that is not cached because it performs caching might not be the correct GET request.The POST request requests the server to generate information. Previous HTTP communications were performed together with POST requests for data deletion and modification form requests. POST requests are not maintained because they change the state of the server. It usually sends the requested data to the Request Body."
be,Describe the HTTP method and its role.,networking,"Usually, if you designed REST API, you can explain it understandably.Let's keep in mind the existence of OPTIONS, HEAD, and TRACE. In particular, I don't think you need to know TRACE. OPTIONS is used to determine which methods the server allows for that uri. HEAD is similar to GET, but only the header is imported.<ul><li>GET request is to request data that exists on the server. In terms of CRUD, it's R.</li><li>POST requests the server to generate data. In terms of CRUD, it's C.</li><li>PUT requests modify the data that exists on the server or generate it if it does not exist. In terms of CRUD, it's C,U.The </li>DELETE request requests that the server remove the data. It works the same way even if it doesn't exist. In terms of CRUD, it's D.The </li>PATCH request modifies some of the data that exists on the server. In terms of CRUD, it's U.</li></ul>Let's go further and manage it in a Whitelist way that allows only the necessary methods, not the unnecessary methods. For more information, let's search for HTTP Method vulnerabilities."
be,"What is RESTful, explain it as you know it.",networking,"REST is a very difficult concept. But let's get a rough idea of what REST is. If you designed REST API, it's enough to ask.Displays resources through HTTP URI and expresses processing for resources through HTTP Method. It is characterized by being a human-readable API. Because it uses HTTP, it reflects the characteristics of HTTP. There is also no need to build a separate infrastructure.The downside is that there is no clear standard, and it is very difficult to create an API that fully satisfies RESTful (see if such a REST API is okay).There is a concept called HATEOAS, which allows you to provide dynamic APIs (all relevant actions are informed via URI), which gives the client the advantage of not having to respond to changes in the API one by one."
be,What is CORS and explain it.,networking,"CORS is a common issue in web development. It is usually common when a request is sent locally to an API server during a fe-end development.It means sharing resources between different domains. Most browsers block this by default, and the server informs you of the available resources through the header.Preflight request is a pre-sending request to determine if it is safe to send an actual request. Verify that the request is made using the OPTIONS method and allows CORS. If CORS is an authorized web server, it responds with available resources in the header."
be,"Describe the OSI7 layer, its reason for existence, and the TCP/IP layer 4.",networking,"The OSI7 layer is standardized into seven layers of the components that make up network communication. The benefit of this standardization is that you can understand the process of communication step by step, making it easier to solve problems when they arise.In fact, the network we use most of the time is TCP/IP layer 4. It is a layer that is actually used for communication, with tiers 1 and 2 operating in tier 1, and tiers 5, 6, and 7 operating in tier 4."
be,"Describe where the web server software (Apache, Nginx) works in the OSI 7 layer.",networking,"Apache and NGINX are HTTP web servers, and the HTTP protocol they run is the protocol corresponding to the application layer, which is layer 7 of OSI 7 layers. The HTTP protocol operates over the TCP/IP protocol. The TCP/IP protocol operates on four layers of the OSI 7 layer, the Transport Layer.  As a result, the web server software works with four layers of TCP/IP protocol and seven layers of HTTP protocol."
be,"Describe where the server-to-server routing capabilities of Web Server Software (Apache, Nginx) work among the OSI 7 layers.",networking,"There are two things. Layer 4 (Transport Layer), 그리고 Layer 7 (Application Layer) 입니다. L4 provides routing capabilities based on TCP/UDP port information. In L7, routing functions are provided based on the URI of HTTP as well as TCP/UDP.For example, in the case of Nginx, you can configure multiple ports to be grouped into one upstream block and load-balanced, or distributed requests delivered on a particular path, on each port.For example, using the routing function in L7, you can set up routing for subdomains in Apache and Nginx respectively. If your browser sends a request over the HTTP protocol to a subdomain, such as /test, you can provide routing for the request based on the path information set in the config file within the web server to deliver the static file or act as a reverse proxy for the API server."
be,Explain the difference between a process and a thread.,operating system,"Process means a program that is running. Threads mean that only execution control is isolated.The process is allocated resources from the operating system, but threads are allocated resources from the process and share the code/data/hip area of the process, so they can communicate more efficiently. In addition, context switching is faster on the thread side, which does not require emptying cache memory. In addition, threads can cause problems due to resource sharing, so programming should be done with this in mind.Multiple threads can be created in one process."
be,Explain context switching.,operating system,"Context switching is a way to run multiple tasks alternately so that they can be processed simultaneously, rather than waiting for a task to finish.When an interrupt occurs, it works by saving the status of the current process to the PCB and the status of the new process to the register. At this point, the CPU does nothing, so frequent context switching can cause performance degradation.Threads and processes work slightly differently, but threads have less to store in cache memory or PCB and less to empty, which can lead to relatively faster context switching."
be,"Describe the difference between synchronization and asynchronous (blocking, non-blocking) / pros and cons.",operating system,"Motivation/asynchronous can be divided into two or more things timed/not timed.Synchronization is a method of executing a command that matches the method return and the time the result is received. In addition, the synchronization method is the same as the end time of one function and the start time of the next function.The asynchronous method is a method of running multiple processes together, which can handle more tasks per unit time than the synchronous method. However, asynchronous processing of CPU or memory-intensive tasks can be overloaded. The complexity of the program will also increase.Blocking/non-blocking is a classification of how to deal with targets (IOs/multi-threads) that I can't directly control, with a different perspective than synchronization/asynchronous.Blocking means that the target has control until the end of the operation of the target. Non-blocking, on the other hand, performs new tasks regardless of whether or not the target has completed the task.Because synchronous nonblocking continues to poll, context switching continues to occur, resulting in delays.See https://youtu.be/HKlUvCv9hvA ."
be,Explain multi-threaded programming.,operating system,"Multi-threaded programming is called multi-threaded programming, which creates multiple threads in a single process to minimize redundancy in the creation and management of resources.Benefits<ul><li> Less memory resource consumption compared to multi-processes.</li><li>The hip area enables thread-to-thread communication, making it simpler than process-to-process communication.</li>The context switching of the <li>thread is faster than the context switching of the process.</li></ul>Disadvantages<ul><li>Sync when using resources in the hip area.</li><li>Overuse of the lock for synchronization can degrade performance.</li><li>If one thread operates abnormally, the other thread may also be terminated.</li></ul>"
be,Explain what Thread-safe means and how to design it.,operating system,"A state in which memory visibility is ensured so that the consistency of the operation results can be ensured even if two or more threads enter a race condition or approach the same object at the same time.<ul><li>java.util.concurrent Use the class under the package.</li><li> Do not place the instance variable.Use the </li>Singleton pattern (in this case, the Singleton pattern you typically implement does not have a Thread-safe) [Note] (https://github.com/ksundong/TIL/blob/master/DesignPattern/singleton-pattern.md) </li><li>Syncronized) block to perform the operation.</li></ul>"
be,Describe the process synchronization.,operating system,"There are a lot of things we need to know. During the interview, let's answer by cutting it short. If you go too deep, there is a possibility of reversing your words, and it is easy to give the impression that you do not know well.In a multi-process environment, only one process, such as resources, is accessible.Be careful because there is a possibility that the operation results will be returned incorrectly because the data will be inconsistent if the process is not synchronized.Race Condition: refers to a situation where multiple processes or threads attempt to access resources without a synchronization mechanism. This refers to situations in which execution results may vary depending on the order of access to shared resources.Critical Section: A block of code that accesses shared resources that multiple threads should not access at the same time. Only one thread or process is accessible to one critical zone. To control access to critical zones, we use mechanisms such as Semaphore and Mutex.Conditions for resolving critical zone issues (must meet all)<ul><li>Mutual Exclusion: If one process is operating in a critical zone, the other process is not accessible.</li><li>Progress: If you do not have a process working in a critical zone, select the process you want to enter the threshold zone appropriately so that you can enter it.</li><li>Bound Waiting: After one process requests entry into the critical area, the other process must be limited to a finite number of times. (Prevent starvation)</li></ul>"
be,Explain how to solve the deadlock and hunger.,operating system,"You must know what a Deadlock is. It means that different processes are waiting for the return of resources they occupy with each other.Occurrence condition<ul><li>Mutual exclusion: Only one process at a time should be available for that resource.</li><li>Wait for occupancy: Wait for other resources with allocated resources.</li><li>Non-priority: The resource cannot be taken away until another process finishes using it.</li><li>Circular Standby: Each process has the resources required by the following processes cyclically.</li></ul>Resolution<ul><li>Prevent: Do not satisfy any of the four conditions.</li><li>Avoid: Prevent algorithms from being deadlocked.</li><li>Recover: When a deadlock occurs, resolve it.</li><li>ignore: If the performance of the recovery process is severely degraded, just ignore it.</li></ul>Starvation: When multiple processes compete to occupy scarce resources, a particular process is never allocated resources.Change the priority (change the priority from time to time, increase the priority of the long-awaited process, or use Queue)"
be,Explain the difference between Semaphore and Mutex.,operating system,"Semaphore is a method in which multiple processes manage accessible shared resources, and it can be Mutex, but Mutex is a method in which only one process is managed accessible at a time. Therefore, Mutex cannot be semaphore.In addition, while semaphores can be released by other processes, Mutex can only return the lock by the process that has acquired the lock."
be,Describe the virtual memory.,operating system,"Virtual memory is a technology that enables a process to use memory regardless of the size of the actual memory.Virtual memory consists of a swap area of physical memory (RAM) and auxiliary storage (auxiliary storage).The OS manages the memory through a memory management unit, and the process does not know whether the memory you use is actual memory or swap area.In Java, OOM can occur if the Swap area is not held.Because the Swap area is not real memory, there is a lot of latency, preferably designed to disable Swap memory, and if you continue to use it, you may suspect a memory leak."
be,Describe Cathy's locality.,operating system,"You should know what cache is and why you are using it. I'll link to a good article about it. https://parksb.github.io/article/29.html can be divided into time locality and space locality, time locality refers to the tendency to re-access recently accessed data, and space locality refers to the tendency to re-access the surrounding space of recently accessed data."
be,Please explain the reasons and pros and cons of using indexes in the database.,database,"The reason why databases use indexes is to improve search performance.However, in order to improve search performance in practice, an index must be created that takes into account factors such as Cardinality and Selectivity, whether the query uses an index.A common advantage is fast search performance.The general disadvantage is the cost of constructing an index, i.e., additional operations to form the index during the add, modify, and delete operations.Therefore, when generating an index, the elements in the trade-off relationship must be comprehensively considered.However, using indexes everywhere can have negative effects.1. Generating an index requires additional storage space and may cause overhead for index management.2. If there is an index, the index is also updated when data is inserted, modified, and deleted. Therefore, as the number of indexes decreases, writing performance may decrease.3. If there is an index that is not used for the query, there may be a negative impact on system overall performance because the index unnecessarily occupies system resource space.4. Managing indexes is also a costly task, so it can be difficult to manage if the index increases.Since there are problems such as, sufficient analysis and review of the index is required before generation, so the system must be balanced."
be,Please explain the transaction.,database,"A transaction is a logical unit of work that changes the status of a database, and a transaction can have multiple operations.Transactions can be said to be successful if even one task fails while performing, and all must be successful."
be,Please explain the ACID.,database,"ACID is a property to ensure that transactions are carried out securely.<ul><li>Atomicity: The operation of a transaction must be performed perfectly, and if even one operation fails, all operations within the transaction must fail.</li><li>Consistency: Transactions can only be changed to a valid state.</li><li>Isolation: Transactions must run independently without being affected by other transactions if they run simultaneously.</li><li>Durability: After a transaction is committed, you must ensure that it remains committed even if a system error occurs. </li></ul> (typically means data is stored in non-volatile memory)"
be,Please explain the Transaction Isolation Levels.,database,"The level of transaction isolation controls the trade-off of isolation and performance.<ul><li>READ UNCOMITED: You can also refer to uncommitted content in other transactions.</li><li>READ COMITED: You can refer only to commitments made in other transactions.</li><li>REPEATABLE READ: You can only refer to commitments made prior to entering the transaction.</li><li>SERIALIZABLE: When you enter a transaction, lock it so that it won't be accessible to other transactions.</li></ul>"
be,Please explain the regularization.,database,"Normalization means designing a database to meet data duplication protection, integrity.There were cases where I asked more than this, but I think I need to learn more."
be,Please explain JOIN.,database,You simply need to know how JOIN queries work in SQL.It's better to understand it in a diagram.
be,Please explain RDBMS vs NOSQL.,database,"RDBMS is a database that stores data through the relationship of objects that make up the database. SQL can be used to store, query, modify, and delete data, and it aims to store data efficiently, and structuring is critical.Benefits include ensuring a clear data structure and avoiding duplication.NOSQL stores data in a freer format than RDBMS. It can also be horizontally expanded and supports distributed processing. There are various types of NOSQL databases, such as key-value store, bigtable, dynamo, document db, and graph db.The two are not replaceable, they should be selected and used as appropriate when needed. They can be complementary beings that they both share."
be,Please briefly explain about Redis.,database,"Redis는 key-value store NOSQL DB입니다. It operates as a single thread and supports data structure. And it supports a variety of functions to be used for a variety of purposes. Data can be recovered through snapshots or AOF logs, ensuring some persistence.I understand that spring is often used to manage sessions or caching."
be,Please explain the difference between Redis and Memcached.,database,"Redis operates on a single thread basis, and Memcached supports multi-thread, enabling multi-processing.Redis supports a variety of data structures, and Memcached is saved only as a string.Redis supports a variety of features that can be used for multiple purposes.Redis can recover data through snapshots and AOF logs."
be,Please briefly explain Elastic Search.,database,"Elastic Search is an open-source search engine developed in Java. Instead of using it alone, we usually use additional Logstash, Kibana, and Beats, which are called ELK stacks.It stores data in an Inverted Index structure, ensuring superior performance compared to RDBMS in full-text search.It can be used for a variety of purposes. (Data storage, document retrieval, location retrieval, machine learning-based retrieval, log analysis, security audit analysis, etc.)"
be,Please explain the difference between the index structure of Elastic Search and the index structure of RDBMS.,database,"Elastic Search stores data in an Inverted-Index structure. This is easy if you think about the index of the book, and it's storing docs where certain words appear. RDBMS, on the other hand, uses B-Tree and a similar index. I think it's the difference between where the data exists and in what order it is stored. RDBMS also has various index structures, but the example here is the B-Tree index."
be,Please explain the difference between keyword search in Elastic Search and LIKE search in RDBMS.,database,"Keyword search in Elastic Search separates keywords with the same algorithm that you do when you save the document. Among them, the ranking algorithm displays the results in the most similar order.LIKE searches in RDBMS are relatively slow because they use indexes only if they don't start with wildcards, and they explore the whole thing the rest of the time."
be,Please explain CAP theory and Event Consistency.,database,"The CAP theory is that no system satisfies everyone in a distributed environment.Consistency: Slightly different from ACID consistency. All nodes must show the same data at the same time.Availability: Responses must be returned for all actions.Partition Tolerance: Some of the systems must work even if they are disconnected from the network.CAP can be different depending on how you cluster it if it's hard to say that the system is this. That's why you need to know what strategies you've chosen to take. (Simply MySQL is CA. Rather, think about CA for some reason) and there's a theory that has some limitations, and there's also a PACELC theory.Eventual Consistency is a concept that comes out because it does not guarantee this Consistency, but as a result, it does not fully guarantee Consistency at some point."
be,Please explain the difference between the array and the linked list.,data structure,"The array stores data in order on memory. On the other hand, a linked list is a structure that has a pointer to the location of the following data.The array has high index lookup performance because it can query data by index, and because the data is stored in order in memory, the locality of the cache allows relatively fast navigation.Linked lists have the advantage of being easy to insert or delete data in the middle."
be,Please explain the difference between List and Set.,data structure,"A List is a linear data structure that stores and maintains an order of duplicate data, and a Set is a linear data structure that can store non-overlapping data, and usually does not maintain an order. (Set is a set, such as TreeSet, there are also sets that maintain an order.)"
be,"Please explain Stack, Queue.",data structure,"Stack is a type of linear data structure, and it is a LIFO (Last In First Out) method of data structure that takes out the last stored data first. Examples of stack uses include logging visits (backwarding) and undoing (undo) in a web browser.Q is a type of linear data structure, and it is a FIFO (First In First Out) method of data structure that takes out the first stored data. Examples of queues are waiting to print a printer, waiting to call center customers, and so on."
be,Please explain the worst case of BST and the time complexity.,data structure,"If you think about why you use Self-Balanced Tree rather than BST, it's an easy question to answer.For example, if you store BST sequentially from 1 to 10, the BST will look like a list. This is called the worst case and the time complexity is O(n)."
be,Please explain how to implement the Fibonacci sequence in code.,data structure,"Can the intention of the question be implemented in code the Fibonacci sequence? What is the problem if you used recursive? This leads to the where DP is available.Fibonacci sequences can usually be implemented with a degree of recursion, but redundant operations continue to occur. If you store these duplicated operations in memory and allow them to perform operations only when the results do not exist, you can implement faster operations."
be,Please briefly explain asymmetric key encryption and symmetric key encryption.,security,"Asymmetric key encryption is also known as public key encryption, and public keys are publicly available, and private keys are internally held and can be encrypted or unlocked with each other's own keys. This method is relatively safer than the method of sharing symmetric keys, and instead, computational performance is poor.Symmetric key encryption is a method in which both sides have the same key and use the same key for encryption and unlock. This method may have the problem of exposing the secret key, and it is relatively fast because it requires less computational performance."
be,Please briefly explain unidirectional encryption.,security,"One-way encryption is called non-decryptable encryption. Most of them are implemented using hash algorithms, and when storing sensitive information in a database, they use that method.Normal one-way encryption performs fast, making it vulnerable to indiscriminate college admissions attacks. Therefore, we use the same method as bcrypt to store this information.As the word hash suggests, there is a possibility of collision. The risk of this decryptable encryption means that it caused a hash collision."
be,Please briefly explain about JWT.,security,"JWT can be seen as being used in token authentication methods. Other uses can also be used to share data, but are typically used in token authentication methods.JWT is divided into headers, payloads, and signatures. The header contains the type of token, the encryption algorithm, the payload is the part that contains the token's information, and the signature allows you to determine whether the token's information is reliable.JWT is primarily contrasted with session-based authentication. Session-based authentication costs the server to manage session information. It is also difficult to manage in a distributed environment. However, because JWT has information on its own, it can compensate for the session's shortcomings.There have also been questions comparing JWT with other token-based authentication methods."
be,Please briefly explain OAuth.,security,"OAuth is a third-party authentication method. By default, users cannot trust the server. That is why we are reluctant to write sensitive information. The same is true on the server side. Managing your sensitive information requires resources.So you can understand that OAuth is using OAuth to give trusted servers access to information. This is an advantage because the user can use the service without having to enter sensitive information, and the server does not have to manage sensitive information.Please explain the OAuth architecture."
be,Please list the script and compilation languages and explain the differences.,compiler,"The script languages are PHP, Javascript, and Python, which are representative script languages. Compilation languages include C, C++, Swift, and Go.Java is a bit of a special case. Java is compiled into Java Byte Code when compiled, which operates as an interpreter on the JVM. However, the collaboration between JIT Compiler and Hotspot JVM has enabled us to achieve performance similar to native languages.The difference between the script language and the compilation language is that the script language translates and executes into one-line, one-line machine language in a way called interpreter, and it does not proactively prevent grammar errors, which we call compilation errors. Because it's good to run right away, it's often used in areas that need it. Since the compilation language is translated into machine language code through the compilation process, it can be verified in advance and optimized. This is the advantage of compilers."
be,Please explain the structure of JVM and how Java is executed.,java,"An abbreviation for Java virtual machines, JVM's role is to read Java applications through the class loader and run them with the Java API. It performs memory management (GC) and is a stack-based virtual machine.The structure of the JVM consists of Class Loader, Execution Engine, Runtime Data Area, JNI, and Native Method Library.<ul><li>classloader: a module that loads classes into JVM and places them through links</li><li>Execute engine: Role in executing byte code</li><li>Interpreter: Run byte code line by line.</li><li>JIT Compilers: Compilers to increase interpreter efficiency, and when interpreters find recurring codes, the JIT Compilers will turn recurring codes into native codes. From then on, the interpreter immediately uses code compiled into native code.</li><li>Garbage Collector (GC): Garbage collector refers to removing unused objects from the heap area.</li></ul><li>Runtime Data Area: Different areas used during program execution.</li><ul><li>PC Register: Created at the start of Thread and has the address of the JVM command currently running.</li><li>Stack Area: The area where local variables, parameters, etc. are created. The actual object is assigned to Heap and only its reference is stored in the Stack.</li><li>Heap Area: The target area of the GC where dynamically generated objects and arrays are stored.</li><li>Method Area: Class member variables, method information, type information, Constant Pool, static, final variables, and so on are created. The Constant Pool contains all Symbolic References.</li></ul><li>Java Native Interface (JNI): Provides a way to use functions written in C, C++, and Assembly in Java applications. Call the method using the Native keyword. A typical method is Thread's currentThread().</li><li>Native Method Library: C, C++.</li></ul>How Java runs<ul><li>Java Compiler (javac) reads Java source code (.java) and converts it into Java byte code (.class).</li><li>Load the class files to the JVM via the Class Loader.</li><li>The loaded class files are interpreted through the execution engine.</li><li>The interpreted byte code is placed in the Runtime Data Area for practical performance.</li></ul>"
be,"Please explain what GC is, why you need it, and how it works.",java,"GC is a generic term for removing unused objects from the heap area. This object needs to be removed because Java is a language that the developer cannot directly release the memory. This requires the ability to use and remove objects.The operation of the GC is described in the simplest Serial GC method. The more advanced GC is G1 GC, ZGC, which is not covered here.GC can be divided into Minor GC and Major GC. Minor GC is defined to take place in the young region and Major GC takes place in the old region. (Major GC, Full GC does not have a clearly defined document.) When performing the GC, all threads except those performing the GC are stopped. This is called a stop-the-world.The Minor GC starts with the Eden area full. Mark and copy the objects whose references remain in the Eden area to the survivor area. And empty the Eden area. If the Survivor area is also full, copy and empty it to another Survivor area in the same way. Repeatedly, the object that continues to survive will be moved to the old region.Major GC occurs in the old area. Mark the object that needs to be deleted as opposed to the above. And it's a sweep. Memory is fragmented, so collecting it in one place is called a composition, and it's called a composition. That's why it's called the Mark-Sweep-Compact algorithm.This is important because the system stops when performing GC, which can cause unintended failure. Therefore, adjusting the hip area for this is called GC tuning, and JVM memory should never be adjusted at will."
be,Please explain the collection framework.,java,"Java Collection refers to a library with data structures that can efficiently manage objects and data based on well-known data structures called collection frameworks.List, Set inherits the collection interface, but Map interface is defined separately as a structural difference."
be,Please explain the generics.,java,"Generic is in charge of Java type stability. It is a function that checks the type of the object during the compilation process, which improves the type stability of the object and reduces the hassle of transforming it."
be,Please explain about the announcement.,java,"Annotation is an interface-based grammar that can be attached to the code like an annotation to give the class a special meaning or inject function. The built-in announcement is the @Override announcement that occurs when you inherit and override the method, which is a case in point.Meta Annotation is the annotation you use to declare annotation.<ul><li>@Retention: Specifies the range of notations. (Source, Class, Runtime)</li><li>@Inherit: Specifies whether to forward the annotation to the subclass. With this announcement, you can inherit to the subclass.</li><li>@Target: Decide where to use the annotation. (Type, Field, Method, Parameters, Generator, Local Variables, Annotation Type)</li></ul>"
be,What are overriding and overloading and what's the difference?,java,"Unexpectedly, it's a question that you can hear a lot of answers to.Overriding means redefining the method of the higher class. It is also a runtime polymorphism.Overloading means that you have the same method name within the same class, but you can implement different types and numbers of parameters, and it is also a compilation-time polymorphism. Therefore, it can be overriding.Additionally, think about the reason why you have to write '@Override'. It is recommended to use this annotation because it gives stability to overriding at compilation time."
be,Please explain the difference between the interface and the abstract class.,java,Abstract classes are abstract parent concepts of objects that are used to express common concepts. Single inheritance only. There is an association between sets that inherit abstract classes.The interface is used to ensure that the implementation object does the same. Multiple inheritances are possible. There might be no relationship between the sets that implement the interface.
be,What are the classes and what are the objects?,java,"Classes are used in the same sense as the framework or blueprint that defines the object.An object is an identifiable object or object. The object has a distinguishable identifier, a characteristic behavior, and a changeable state. Use instances as collectives."
be,What is static?,java,"Static is called a class member and is managed by class when the class loader loads the class and loads it into the method memory area.Static members created through the static keyword are stored in PermGen or Metaspace, and the stored memory is shared by all objects and has the advantage of being able to refer to one member anywhere.However, because it exists outside the GC's management area, the memory remains allocated until the end of the program. Too much can adversely affect system performance."
be,What are the primitive types of Java and how many bytes each take up?,java,"Boolean(1), char(unsigned2), byte(1), short(2), int(4), long(8), float(4), double(8) In fact, it is an approximate size rather than an exact size because it is dependent on the JVM."
be,Please explain the type of access controller and what it is.,java,"We have private, default, protected, and public. Private is accessible only within that class, default is accessible in that package, protected is the inherited class, and public is accessible in the entire area.The reason for using the access controller is to selectively provide information that you want to show to the outside world, and there is an aspect that communicates encapsulation."
be,Please explain the object orientation.,java,"If you define object orientation, it's dependency management.Object-oriented dependency management minimizes the impact of changes, enables independent deployment, and enables independent development. Therefore, the most important thing in object orientation is the separation of high-level policy and low-level implementation details through DIP (Dependency Inversion Principles)."
be,Please explain SOLID (the five principles of object orientation).,java,"A Single Responsibility Principle (SRP) should have only one responsibility of one class.The open-close principle (OCP) must be open to expansion but closed to change, and it must take advantage of polymorphism.LSP (Liskop Replacement Principle) is a principle that an object in a program must be able to change to a lower type of instance without breaking the accuracy of the program, and the program must not be broken when the higher type is inherited and redefined.ISP (Interface Isolation Principle) is a principle that clients should not rely on methods they are not using. Multiple interfaces for a particular client are better than one general-purpose interface. In other words, it should be separated into smaller, more specific interfaces than larger ones.The DIP (Inverted Dependency Principle) is the principle that the abstract does not depend on something more specific than one, but rather on something that is changeable. Specifically, it's a principle that you have to rely on the interface, not on the implementation class."
be,"Please explain identity and equality. (equals(), ==)",java,"Equivalence is a comparison of an object's address, and Equivalence is a comparison of the object's equivalence.By default, in Java, the equality() method defined in the Object class performs an identity comparison. As a result, developers can use the equals() method to define the criterion for determining equivalence if desired."
be,Please explain the difference between the raw type and the reference type.,java,"Raw type is a type that only exists in Java. The rest are all reference types, and they're either object classes or classes that inherit them.Raw type must always have a value. Object types, on the other hand, can have null pointers. And when the member variable is initialized, there is also a difference where the raw type has a default, but the reference type has a null pointer."
be,"Please explain the difference between String, StringBuilder, and StringBuffer.",java,"String is constant. StringBuilder and StringBuffer can be seen as variable types used because of the characteristics of these strings.There is a difference between StringBuilder and StringBuffer whether it is Thread-safe or not. StringBuilder is not Thread-safe. Therefore, use StringBuffer when used in a Multi-Thread environment."
be,Please explain CheckedException and UncheckedException. What is the rollback target in spring transaction abstraction?,java,"The difference between the two depends on whether or not you inherit RuntimeException. Inheriting RuntimeException results in UncheckedException. In spring transaction abstraction, the rollback target is UncheckedException.To get to know both of them well, I recommend you watch Toby's Spring."
be,Please explain the features added in Java8.,java,"In Java8, Lambda expression, Stream API, Optional, Date Time API, and StringJoiner were added.Lambda is a function to support functional programming, and the Stream API supports higher-order functions. Optional offers null-safety and is similar to Stream in usage. The date-time API has been influenced by libraries such as Joda-time to become a good API, and StringJoiner provides the ability to easily combine strings into separators."
be,Please explain the try-with-resource.,java,"Try-with-resources is a grammar introduced in Java version 7.If you use one or more resources (objects implementing java.lang.AutoCloseable or java.io .Closeable) before Java 7 version, the developer will randomly select ~~ from the statement.You had to use close() to release the resource.If resources used by developers were omitted without being finally released from the door, the program would malfunction without the resources being released, and even if the resources were finally released from the door, duplicate codes for resource release would occur, which would impair the readability of the source code.To address this, we have introduced the ability to automatically return resources from the JVM regardless of whether logic is completed successfully or abruptly within the try block when explicitly declaring and using resource objects to be used within the try().Additionally, Java 9 version changed to allow you to declare objects outside the try() statement and put variables in the instances created, rather than explicitly declaring objects in the try() statement.Java 7 : try(BufferedReader br = new BufferedReader()) <br>Java 9 : try(br)"
be,Please explain what strong and loose bonds are.,java,"The degree of association represents the degree of dependence and is a measure of how much information you know about other modules.If one module knows too much detail (implementation details) about another module, it is said to have a strong coupling degree.If one module knows only the information it needs about the other (high-level policies abstracted by the interface), the two modules are said to have a low degree of coupling.From an object-oriented perspective, a conjunction plot indicates whether an object or class has only the appropriate level of relationship required for cooperation. From this point of view, strong coupling must be avoided, and developers must consider and design to maintain proper coupling."
be,Please explain serialization and inverse serialization.,java,Serialization refers to both the technology of converting objects or data used inside a Java system into bytes and the technology of converting data back into bytes so that it can also be used on an external Java system.Java serialization is used when persistence is required for object data that resides only in the memory of the JVM. It has the advantage of not disappearing even when the system is shut down and can be transmitted to the network because it is persistent data.
be,Please explain the difference between a mutable object and an Immunable object.,java,"It is often said that a mutable object is a changeable object, and an Imputable object is a constant object.The Mutable object is used as a domain object (domain class or entity). The method of changing a Mutable object is also called the Command method, which defines the return type as void. In addition, any method that changes any state of the void return type is a symbol of the Command method.An Impossible object is an immutable object and is used for value objects, service objects, and so on. The method of changing an Immersible object must return a copy of the object that you changed."
be,Please explain how to safely handle null in Java.,java,"Where it is not a public method, you can use assert to defend against null. You can also use Objects.requireNonNull() to defend when receiving the parameters of the method. You can use the Option to defend against returning null in the return type. Finally, the pre- and post-conditions should be clarified to practice the design by contract."
be,Explain the difference between JDK and JRE.,java,"JDK is an abbreviation for Java Development KIT, a tool used to develop and contains JRE, which is an abbreviation for Java Runtime Environment, which contains the tools needed to run programs made in Java.Install JRE, not JDK, which contains development tools, because places like the production server only require tools to run programs, not tools required for development."
be,How does Spring DI/IoC work?,spring,"IoC (reversal of control) is managed externally rather than directly controlling the control flow of the program, and the final call of the code is made as determined within the framework, not as controlled by the developer.DI (Dependency Injection) is a form of IoC supported by the Spring framework that automatically connects dependencies between classes based on empty configuration information.Spring uses the Spring Container Application Context to create and register configuration information and inject the required objects through the creator or setter."
be,What is Spring Bean?,spring,It is an object contained in an IoC container that is taken from the IoC container and used when needed. You can register a normal object as a Bean by using @Bean or by setting xml.
be,Please explain the process of creating the spring Bean.,spring,"Object creation → dependency setting → initialization → usage → life cycle of extinction process. Bean manages the life cycle by a spring container and uses @PostConstruct for bin initialization and @PreDestroy for bin extinction.When registering the spring bin you created, you can register the bin directly in the bin configuration file using ComponentScan or using @Bean in @Configuration."
be,Please explain the scope of Spring Bean.,spring,"A bin scope refers to the range where a bin can exist, including Single Tone, Prototype, Request, Session, Application, and so on.Singleton is the primary scope, the widest range of scopes maintained until the start and end of the spring container.Prototypes are very short scopes that are only involved in the creation of bins and the injection of dependencies, and no longer manage them.The request is a scope that maintains web requests until they come in and out, the session is a scope that maintains the same scope as the web servlet context until the web session is created and terminated."
be,What is the role of the IoC container?,spring,It instantiates an empty object at the time of application execution and provides one blank for the first time to start the application after DI
be,"What are the DI types, and what is the difference between them?",spring,"There are three ways to DI. There are constructor insertions, method parameter insertions using Setter, and field injections.The generator injection ensures that only one call is made at the time of the generator call and is used for constant, essential dependencies.Setter injection is used for selectable, changeable dependencies and can selectively register spring bins.Field injection uses '@Autowired' and cannot be changed externally, making it difficult to test. It is difficult to operate without the DI framework and is mainly used for spring setting purposes such as test code or '@Configuration' that are not related to the application."
be,Please explain the Autowiring process.,spring,Search the container by type (interface or object) to find and inject empty objects that can be allocated
be,What is the fe controller pattern?,spring,"Making and using a servlet for every client's various requests will inevitably reduce the efficiency of development and maintenance. The fe controller pattern enables greater development and maintenance efficiency by delegating each request to the right place and encapsulates common functions such as security, internationalization, routing and logging for all requests in one place. In Spring, DispatcherServlet is an example of a fe controller pattern, and DispatcherServlet is registered as Bean, scans the package, checks the @Controller, @RestControllerAnnotation, and delegates any request to the appropriate Handler method."
be,What is the difference between the Servlet Filter and the Spring Interceptor?,spring,"Filter는 Servlet Filter로써 javax.Classes included in the servlet specification.The Interceptor is a class included in the Spring MVC specification.The Filter is responsible for the post-processing in the Servlet, and the Interceptor is responsible for any processing before and after executing Handler in Spring or after the View Name returned from the controller through ViewResolver is prepared and returned to render the actual View.The Filter registers with the Web Application (web.xml when using Tomcat), and the Interceptor registers with the Application Context in Spring.Filter is used to replace the Argument in Method Signature, HttpServletRequest or HttpServletResponse, etc., or to convert data (such as compression of download files and data encryption), change XML documents using XSL/T, user authentication, logging of resource access, etc.Interceptor is used to mimic AOP, allow Spring applications to use exceptions in the post-processing logic globally, or check the Handler Method for other actions."
be,Please explain how to solve CORS error in Spring.,spring,"You can set up Cors customized using the Servlet Filter, create a configuration class that implements WebMvcConfiguer to override addCorsMappings(), and finally, Spring Security can address this by registering the CorsConfigurationSource as Bean and adding it to the config.It can be resolved by using the @Crossorgin annotation in the Controller class."
be,Please explain the Bean/Component Annotation and explain the difference between the two.,spring,"Both annotations are used to register a Bean in the IoC container@Component : Generates an instance object once (single tone) at execution time based on the class created by the developer@Controller, @Service, @Repository are all @Component and automatically inject dependencies at execution time@Bean : Based on the method created by the developer, the object returned by the method is created once (single tone) as an instance object"
be,What is POJO? What could POJO be in the Spring Framework?,spring,"POJO is a simple class that does not implement or extend a framework interface, class, and is not dependent on the API provided by Java. It is not dependent on a particular environment, so the code is concise and advantageous for automated testing. In the spring, the target for performing the domain and business logic can be POJO targets."
be,"In Spring Web MVC, Thread will be generated for each request and the request will be performed through the controller, so how can only one controller be created?",spring,"in Spring Web MVC, while each request is handled by a separate thread, the controllers themselves are singleton-scoped, meaning only one instance of each controller is created and reused for all requests. This approach ensures efficient memory usage and performance."
be,"Filter is the specification of the servlet, and Interceptor is the specification of the Spring MVC. What should I do if the Spring application handles exceptions through Filter and Interceptor?",spring,"Because the Filter exists outside the DispatcherServlet, it must be handled by the Error Controller when an exception occurs. However, since the Interceptor exists inside the DispatcherServlet, you can apply @ControllerAdvice to handle it."
be,Please explain how to execute the method when running the Spring application.,spring,"There are two ways to create and run a class that implements CommandLineRunner and ApplicationRunner. There are also methods using Spring's ApplicationEvent, @Postconstruct, implementing InitializingBean interface, and @Bean's initMethod."
be,Please explain the dependency and why you need to inject the set value into the generator factor.,spring,"By injecting all dependencies through the constructor, you can immediately execute any action when you create an instance. In addition, no additional settings are required, and it is easy to test without unexpectedly missing dependencies and settings."
be,Describe the five benefits of the JPA persistence context.,JPA,"Persistency context refers to an environment in which an entity is permanently stored.The reasons for writing persistence contexts are primary cache, identity guarantee, write delay, change detection (Dirty checking), and delay loading.Primary Cache: If you can query and you are not in the primary cache, you can query it in the DB and put it in the primary cache.Ensuring identity: Identical comparisons are possible. (==) Write delay: Write delay supporting transactions is possible, and SQL can be collected and sent without sending right away until transaction commitment is made.Dirty checking: Snapshots take the data that entered the primary cache. Create an update SQL against Entities and snapshots at the point of commitment.Delayed loading: When an entity loads an entity, it flies SQL to get that data."
be,Please explain the phase of JPA Propagation propagation.,JPA,"It is a question that came from a large company interview and is likely to ask questions such as the transaction isolation stage.JPA Propagation is an option for situations where you call (run) another transaction during a transaction operation.@Transactional's propagation property allows you to use the called party's transaction as it is or to create a new transaction from the perspective of the called transaction.REQUIRED (default): Runs within a parent transaction and creates a new transaction if there is no parent transaction.In addition, there are types of REQUIRES_NEW, SUPPORTS, MANDATORY, NOT_SUPPORT, NEVER, and NESTED, but I answered only the REQUIRED value because the newcomer has little experience in dealing with it."
be,"If you use JPA, please explain why.",JPA,"In fact, it is important to understand what the interviewer intended. I remember answering differently when I heard the same question under different conditions.The reason I use JPA is because it is an object-oriented framework. This is because JPA allows business logic to be expressed in Java code, rather than RDBMS dependent. This increases productivity (presupposes familiarity with JPA)In addition, JPA abstracts SQL with JPQL, so it also has the advantage of writing the same query regardless of RDBMS Vendor and expecting the same behavior. This is an advantage because it supports database dialog."
be,Please explain what the N + 1 problem is and why it happens and how to solve it.,JPA,"N + 1 query problems can arise in each situation of immediate and delayed loading strategies. When sub-entities exist, they are not all imported from one query, but each query occurs where necessary.Immediate loading occurs because when JPQL is used, the data is queried directly from the database rather than from the persistence context, and then the Immediate loading strategy works.<br>The reason for the delay loading occurs when loading a child entity using a delay loading strategy, and when unproxy the proxy entity in the JPA, an additional query is executed to query that entity.Resolutions include using JPQL's join fetch called FetchJoin, and other methods include using <code>@EntityGraph</code>, <code>@Fetch@Fetch(FetchMode.SUBSELECT)</code>, adjusting using <code>@BatchSize</code> or setting a global batch-size.Do not create a note for each solution."
be,Is nodeJS a single thread or a multi thread?,nodeJS,The main execution flow of nodeJS is a single thread-based event loop model.It supports non-blocking I/O as a single thread by delegating I/O operations to other threads (which exist in the thread pool managed by libuv) rather than its own main thread (single thread circling the event loop). (Note: Servers using the event-driven model usually operate with the event loop. Examples include redis (multiplexing) and spring webflux (Reactor)
be,Reference Copy (Thick Copy) vs Value Copy (Deep Copy),nodeJS,"1) Shallow copy means a copy of a 'memory address value' stored in reference type data. ```/* Beware of shallow radiation!!! */let origin = [""a"", ""b""];let copy = origin; copy.push(""c""); console.log(origin); //[""a"", ""b"", ""c""]; /// original changed to console.log(c); //[""a"", ""b"", ""c""]; `So be careful not to change to original. 2) On the contrary, deep copying means securing a new memory space and copying it completely."
be,Please explain the difference between List and Tuple.,python,"The biggest difference between List and Tuple is whether you can change the value.<br>1. List can modify values, but Tuple cannot.2. The list is written as [], and the Tuple is written as ( )."
be,Please explain the Python decorator as soon as you know it.,python,"When there is a function, use the decorator when you want to add a function to it without modifying it yourself.In other words, it is usually used when there is a need for pre-processing or post-processing of a function.This can reduce repetition and extend method or function responsibility."
be,How do you respond if there is a failure in high volume traffic?,etc,"If traffic in the cache is unaffordable or erroneous, the DB will walk the circuit breaker to query it and give it another way."
be,Please explain the single tone pattern. (It's harder than I thought),etc,"A pattern that allows you to create only one object without using global variables, and allows you to refer to the created object from anywhere.Create only one instance and return the same instance to all clients with the getInstance method.Characterized by having a private creator, the generated single-tone object defines the same type of static field as itself that can be stored.The problems with single-tone patterns are as follows.Because of the dependency, the client depends on the sphere class.The test is difficult because of the private creator.Because of the way that only one instance of the object is created and shared, stateful design of a single-tone object is a significant failure factor.It should be designed as stateless to address the shortcomings of single tones.There should be no specific client-dependent fields.There should be no fields in which a particular client can change the value.Make it read-only, preferably, and use local variables, parameters, ThreadLocal, etc. that are not shared in Java instead of fields."
be,Please explain the bridge pattern (bridge pattern).,etc,"A bridging pattern is a design pattern that separates the abstract from the implementation. In that pattern, features are defined and utilized through interfaces and implemented through classes that follow those interfaces. This pattern allows users to modify and extend abstracts and implementations independently. The bridging pattern is a pattern consistent with the Single Responsibility Principle (SRP) and Open Closed Principle (OCP) among SOLID principles of object-oriented design."
be,Please explain the strategy pattern.,etc,"A strategy pattern is a design pattern that encapsulates an algorithm object by object. In that pattern, algorithms are defined and utilized through interfaces and implemented through classes that follow those interfaces. This pattern allows users to change their algorithms as needed. The strategic pattern is a pattern consistent with the open-close principle (OCP) among SOLID principles of object-oriented design.Strategic patterns are similar in structure to bridging patterns, but differ in purpose. While the bridging pattern focuses on the ease of independent development through the separation of abstraction and implementation, the strategic pattern focuses on the flexibility of algorithm changes through encapsulation of algorithms."
be,Give an example of a persad pattern.,etc,"With each independent application separated by bound contexts serving as a façade via the UI server, you can use HTTP, Protobuf, and Thrift methods to communicate with the UI server in each bound context."
be,What is CI/CD? Why is CI/CD an advantage?,etc,"You're usually going to ask this question and ask what CI/CD you've used at the same time. It is good to explain the CI/CD tool you used then and explain the pros and cons of that tool.Continuous integration (CI) refers to the process of continuous integration (continuous integration) in which the construction results are automatically distributed to the production server when pushed to the VCS system that manages the code version.Every time it is pushed, it merges the code and automatically integrates the code while performing the test code and build, so you don't have to manually integrate the code anymore, so you can just focus on development.The key to this CI/CD is test automation. Test code must be implemented to ensure that the project is in full condition."
be,Please explain what DevOps is.,etc,"DevOps is a culture and way of empowering your organization to deliver applications and services at a fast pace, performing automation, measurement, sharing, and building up all of that.DevOps enables organizations to innovate and improve products faster than traditional development and infrastructure management processes. This gives you the flexibility to be customer friendly and respond effectively to the market."
ai,What are the assumptions required for linear regression? What if some of these assumptions are violated?,Linear Regression,"There are four assumptions associated with a linear regression model:
Linearity: The relationship between X and the mean of Y is linear.
Homoscedasticity: The variance of the residual is the same for any value of X.
Independence: Observations are independent of each other.
Normality: For any fixed value of X, Y is normally distributed.
Extreme violations of these assumptions will make the results redundant. Small violations of these assumptions will result in a greater bias or variance of the estimate."
ai,"What is collinearity? What is multicollinearity? How do you deal with it?
",Statistics ,"Collinearity is a linear association between two predictors. Multicollinearity is a situation where two or more predictors are highly linearly related.
This can be problematic because it undermines the statistical significance of an independent variable. While it may not necessarily have a large impact on the model’s accuracy, it affects the variance of the prediction and reduces the quality of the interpretation of the independent variables.
You could use the Variance Inflation Factors (VIF) to determine if there is any multicollinearity between independent variables — a standard benchmark is that if the VIF is greater than 5 then multicollinearity exists."
ai,"What are the drawbacks of a linear model?
",Linear Regression,"There are a couple of drawbacks of a linear model:
A linear model holds some strong assumptions that may not be true in application. It assumes a linear relationship, multivariate normality, no or little multicollinearity, no auto-correlation, and homoscedasticity.
A linear model can’t be used for discrete or binary outcomes.
You can’t vary the model flexibility of a linear model."
ai,What are ridge and lasso regression and what are the differences between them?,Linear Regression,"Both L1 and L2 regularization are methods used to reduce the overfitting of training data. Least Squares minimizes the sum of the squared residuals, which can result in low bias but high variance. L2 Regularization, also called ridge regression, minimizes the sum of the squared residuals plus lambda times the slope squared. This additional term is called the Ridge Regression Penalty. This increases the bias of the model, making the fit worse on the training data, but also decreases the variance. If you take the ridge regression penalty and replace it with the absolute value of the slope, then you get Lasso regression or L1 regularization. L2 is less robust but has a stable solution and always one solution. L1 is more robust but has an unstable solution and can possibly have multiple solutions."
ai,How does K-Nearest Neighbor work?,KNN,"K-Nearest Neighbors is a classification technique where a new sample is classified by looking at the nearest classified points, hence ‘K-nearest’. In the example above, if k=1 then the unclassified point would be classified as a blue point.
If the value of k is too low, it can be subject to outliers. However, if it’s too high, it may overlook classes with only a few samples."
ai,How can you select k for k means?,KMeans,"You can use the elbow method, which is a popular method used to determine the optimal value of k. Essentially, what you do is plot the squared error for each value of k on a graph (value of k on the x-axis and squared error on the y-axis). Once the graph is made, the point where the distortion declines the most is the elbow point."
ai,Why is Naive Bayes “naive”?,Naive Bayes,"Naive Bayes is naive because it holds a strong assumption in that the features are assumed to be uncorrelated with one another, which typically is never the case."
ai,What are the support vectors in SVM?,SVM,The support vectors are the data points that touch the boundaries of the maximum margin.
ai,What is pruning in decision trees?,Decision Trees,Pruning is a technique in machine learning and search algorithms that reduces the size of decision trees by removing sections or branches of the tree that provide little to no power for classifying instances.
ai,What are random forests? Why is Naive Bayes better?,"Random Forest, Naive Bayes","Random forests are an ensemble learning technique that builds off of decision trees. Random forests involve creating multiple decision trees using bootstrapped datasets of the original data and randomly selecting a subset of variables at each step of the decision tree. The model then selects the mode of all of the predictions of each decision tree. By relying on a “majority wins” model, it reduces the risk of error from an individual tree. Random forests offer several other benefits including strong performance, can model non-linear boundaries, no cross-validation needed, and gives feature importance.
Naive Bayes is better in the sense that it is easy to train and understand the process and results. A random forest can seem like a black box. Therefore, a Naive Bayes algorithm may be better in terms of implementation and understanding. However, in terms of performance, a random forest is typically stronger because it is an ensemble technique."
ai,When would you use random forests Vs SVM and why?,"Random Forest, SVM","There are a couple of reasons why a random forest is a better choice of an algorithm than a support vector machine:
Random forests allow you to determine the feature importance. SVM’s can’t do this.
Random forests are much quicker and simpler to build than an SVM.
For multi-class classification problems, SVMs require a one-vs-rest method, which is less scalable and more memory intensive."
ai,Do you think 50 small decision trees are better than a large one? Why?,Decision Trees,"Another way of asking this question is “Is a random forest a better model than a decision tree?” And the answer is yes because a random forest is an ensemble method that takes many weak decision trees to make a strong learner. Random forests are more accurate, more robust, and less prone to overfitting."
ai,What’s the difference between an AdaBoosted tree and a Gradient Boosted tree?,"AdaBoost, Gradient Boost","AdaBoost is a boosted algorithm that is similar to Random Forests but has a couple of significant differences:
Rather than a forest of trees, AdaBoost typically makes a forest of stumps (a stump is a tree with only one node and two leaves).
Each stump’s decision is not weighted equally in the final decision. Stumps with less total error (high accuracy) will have a higher say.
The order in which the stumps are created is important, as each subsequent stump emphasizes the importance of the samples that were incorrectly classified in the previous stump.
Gradient Boost is similar to AdaBoost in the sense that it builds multiple trees where each tree is built off of the previous tree. Unlike AdaBoost which builds stumps, Gradient Boost builds trees with usually 8 to 32 leaves.
More importantly, Gradient differs from AdaBoost in the way that the decisions trees are built. Gradient boost starts with an initial prediction, usually the average. Then, a decision tree is built based on the residuals of the samples. A new prediction is made by taking the initial prediction + a learning rate times the outcome of the residual tree, and the process is repeated."
ai,What is the bias-variance tradeoff?,Statistics ,"The bias of an estimator is the difference between the expected value and true value. A model with a high bias tends to be oversimplified and results in underfitting. Variance represents the model’s sensitivity to the data and the noise. A model with high variance results in overfitting.
Therefore, the bias-variance tradeoff is a property of machine learning models in which lower variance results in higher bias and vice versa. Generally, an optimal balance of the two can be found in which error is minimized."
ai,Explain what the bootstrap sampling method is and give an example of when it’s used.,EDA,"Technically speaking, the bootstrap sampling method is a resampling method that uses random sampling with replacement. It’s an essential part of the random forest algorithm, as well as other ensemble learning algorithms."
ai,What is the difference between bagging and boosting?,Methodology,"Bagging, also known as bootstrap aggregating, is the process in which multiple models of the same learning algorithm are trained with bootstrapped samples of the original dataset. Then, like the random forest example above, a vote is taken on all of the models’ outputs. Boosting is a variation of bagging where each individual model is built sequentially, iterating over the previous one. Specifically, any data points that are falsely classified by the previous model is emphasized in the following model. This is done to improve the overall accuracy of the model. Once the first model is built, the falsely classified/predicted points are taken in addition to the second bootstrapped sample to train the second model. Then, the ensemble model (models 1 and 2) are used against the test dataset and the process continues."
ai,How does XGBoost handle the bias-variance tradeoff?,XGBoost,"XGBoost is an ensemble Machine Learning algorithm that leverages the gradient boosting algorithm. In essence, XGBoost is like a bagging and boosting technique on steroids. Therefore, you can say that XGBoost handles bias and variance similar to that of any boosting technique. Boosting is an ensemble meta-algorithm that reduces both bias and variance by takes a weighted average of many weak models. By focusing on weak predictions and iterating through models, the error (thus the bias) is reduced. Similarly, because it takes a weighted average of many weak models, the final model has a lower variance than each of the weaker models themselves."
ai,What is cross-validation?,Methodology,"Cross-validation is essentially a technique used to assess how well a model performs on a new independent dataset.
The simplest example of cross-validation is when you split your data into three groups: training data, validation data, and testing data, where you use the training data to build the model, the validation data to tune the hyperparameters, and the testing data to evaluate your final model."
ai,What is the difference between online and batch learning?,Methodology,"Batch learning, also known as offline learning, is when you learn over groups of patterns. This is the type of learning that most people are familiar with, where you source a dataset and build a model on the whole dataset at once.
Online learning, on the other hand, is an approach that ingests data one observation at a time. Online learning is data-efficient because the data is no longer required once it is consumed, which technically means that you don’t have to store your data."
ai,Give several ways to deal with missing values,EDA,"There are a number of ways to handle null values including the following:
You can omit rows with null values altogether
You can replace null values with measures of central tendency (mean, median, mode) or replace it with a new category (eg. ‘None’)
You can predict the null values based on other variables. For example, if a row has a null value for weight, but it has a value for height, you can replace the null value with the average weight for that given height.
Lastly, you can leave the null values if you are using a machine learning model that automatically deals with null values."
ai,Is mean imputation of missing data acceptable practice? Why or why not?,EDA,"Mean imputation is the practice of replacing null values in a data set with the mean of the data.
Mean imputation is generally bad practice because it doesn’t take into account feature correlation. For example, imagine we have a table showing age and fitness score and imagine that an eighty-year-old has a missing fitness score. If we took the average fitness score from an age range of 15 to 80, then the eighty-year-old will appear to have a much higher fitness score than he actually should.
Second, mean imputation reduces the variance of the data and increases bias in our data. This leads to a less accurate model and a narrower confidence interval due to a smaller variance."
ai,What is a confusion matrix?,Methodology,"A confusion matrix, also known as an error matrix, is a summarized table used to assess the performance of a classification model. The number of correct and incorrect predictions are summarized with count values and broken down by each class."
ai,What is Supervised vs Unsupervised learning?,Methodology,"Supervised learning involves learning on a labeled dataset where the target variable is known.
Unsupervised learning is used to draw inferences and find patterns from input data without references to labeled outcomes — there’s no target variable."
ai,What is ensemble learning?,Methodology,Ensemble learning is a method where multiple learning algorithms are used in conjunction. The purpose of doing so is that it allows you to achieve higher predictive performance than if you were to use an individual algorithm by itself. An example of this is random forests.
ai,How can you identify outliers?,EDA,"There are a couple of ways to identify outliers:
Z-score/standard deviations: if we know that 99.7% of data in a data set lie within three standard deviations, then we can calculate the size of one standard deviation, multiply it by 3, and identify the data points that are outside of this range. Likewise, we can calculate the z-score of a given point, and if it’s equal to +/- 3, then it’s an outlier.
Note: that there are a few contingencies that need to be considered when using this method; the data must be normally distributed, this is not applicable for small data sets, and the presence of too many outliers can throw off z-score.
Interquartile Range (IQR): IQR, the concept used to build boxplots, can also be used to identify outliers. The IQR is equal to the difference between the 3rd quartile and the 1st quartile. You can then identify if a point is an outlier if it is less than Q1–1.5*IRQ or greater than Q3 + 1.5*IQR. This comes to approximately 2.698 standard deviations.
Other methods include DBScan clustering, Isolation Forests, and Robust Random Cut Forests."
ai,What is an inlier?,EDA,"An inlier is a data observation that lies within the rest of the dataset and is unusual or an error. Since it lies in the dataset, it is typically harder to identify than an outlier and requires external data to identify them."
ai,How can outliers be treated?,EDA,"There are a couple of ways:
Remove outliers if they’re a garbage value.
You can try a different model. For example, a non-linear model might treat an outlier differently than a linear model.
You can normalize the data to narrow the range.
You can use algorithms that account for outliers, such as random forests."
ai,How are collaborative filtering and content-based filtering similar? different?,Methodology,"In content-based filtering, you use the properties of the objects to find similar products. For example, using content-based filtering, a movie recommender may recommend movies of the same genre or movies directed by the same director.
In collaborative filtering, your behavior is compared to other users and users with similar behavior dictate what is recommended to you. To give a very simple example, if you bought a tv and another user bought a tv as well as a recliner, you would be recommended the recliner as well."
ai,What is principal component analysis? Explain the sort of problems you would use PCA for.,Methodology,"In its simplest sense, PCA involves project higher dimensional data (eg. 3 dimensions) to a smaller space (eg. 2 dimensions). This results in a lower dimension of data, (2 dimensions instead of 3 dimensions) while keeping all original variables in the model.
PCA is commonly used for compression purposes, to reduce required memory and to speed up the algorithm, as well as for visualization purposes, making it easier to summarize data."
ai,What is the difference between a validation set and a test set?,EDA,"Generally, the validation set is used to tune the hyperparameters of your model, while the testing set is used to evaluate your final model."
ai,How can you avoid overfitting your model?,Methodology,"For those who don’t know, overfitting is a modeling error when a function fits the data too closely, resulting in high levels of error when new data is introduced to the model.
There are a number of ways that you can prevent overfitting of a model:
Cross-validation: Cross-validation is a technique used to assess how well a model performs on a new independent dataset. The simplest example of cross-validation is when you split your data into two groups: training data and testing data, where you use the training data to build the model and the testing data to test the model.
Regularization: Overfitting occurs when models have higher degree polynomials. Thus, regularization reduces overfitting by penalizing higher degree polynomials.
Reduce the number of features: You can also reduce overfitting by simply reducing the number of input features. You can do this by manually removing features, or you can use a technique, called Principal Component Analysis, which projects higher dimensional data (eg. 3 dimensions) to a smaller space (eg. 2 dimensions).
Ensemble Learning Techniques: Ensemble techniques take many weak learners and converts them into a strong learner through bagging and boosting. Through bagging and boosting, these techniques tend to overfit less than their alternative counterparts."
ai,What are some of the steps for data wrangling and data cleaning before applying machine learning algorithms?,EDA,"There are many steps that can be taken when data wrangling and data cleaning. Some of the most common steps are listed below:
Data profiling: Almost everyone starts off by getting an understanding of their dataset. More specifically, you can look at the shape of the dataset with .shape and a description of your numerical variables with .describe().
Data visualizations: Sometimes, it’s useful to visualize your data with histograms, boxplots, and scatterplots to better understand the relationships between variables and also to identify potential outliers.
Syntax error: This includes making sure there’s no white space, making sure letter casing is consistent, and checking for typos. You can check for typos by using .unique() or by using bar graphs.
Standardization or normalization: Depending on the dataset your working with and the machine learning method you decide to use, it may be useful to standardize or normalize your data so that different scales of different variables don’t negatively impact the performance of your model.
Handling null values: There are a number of ways to handle null values including deleting rows with null values altogether, replacing null values with the mean/median/mode, replacing null values with a new category (eg. unknown), predicting the values, or using machine learning models that can deal with null values. Read more here.
Other things include: removing irrelevant data, removing duplicates, and type conversion."
ai,How should you deal with unbalanced binary classification?,Methodology,"There are a number of ways to handle unbalanced binary classification (assuming that you want to identify the minority class):
First, you want to reconsider the metrics that you’d use to evaluate your model. The accuracy of your model might not be the best metric to look at because and I’ll use an example to explain why. Let’s say 99 bank withdrawals were not fraudulent and 1 withdrawal was. If your model simply classified every instance as “not fraudulent”, it would have an accuracy of 99%! Therefore, you may want to consider using metrics like precision and recall.
Another method to improve unbalanced binary classification is by increasing the cost of misclassifying the minority class. By increasing the penalty of such, the model should classify the minority class more accurately.
Lastly, you can improve the balance of classes by oversampling the minority class or by undersampling the majority class."
ai,What is the difference between precision and recall?,Statistics ,Recall attempts to answer “What proportion of actual positives was identified correctly?” Precision attempts to answer “What proportion of positive identifications was actually correct?”
ai,Why is mean square error a bad measure of model performance? What would you suggest instead?,Methodology,"Mean Squared Error (MSE) gives a relatively high weight to large errors — therefore, MSE tends to put too much emphasis on large deviations. A more robust alternative is MAE (mean absolute deviation)."
ai,Explain what a false positive and a false negative are. Why is it important these from each other? Provide examples when false positives are more important than false negatives and when false negatives are more important than false positives.,Statistics ,"A false positive is an incorrect identification of the presence of a condition when it’s absent.
A false negative is an incorrect identification of the absence of a condition when it’s actually present.
An example of when false negatives are more important than false positives is when screening for cancer. It’s much worse to say that someone doesn’t have cancer when they do, instead of saying that someone does and later realizing that they don’t.
This is a subjective argument, but false positives can be worse than false negatives from a psychological point of view. For example, a false positive for winning the lottery could be a worse outcome than a false negative because people normally don’t expect to win the lottery anyway."
ai,What are the feature selection methods used to select the right variables?,EDA,"There are two types of methods for feature selection: filter methods and wrapper methods.
Filter methods include the following:
Linear discrimination analysis
ANOVA
Chi-Square
Wrapper methods include the following:
Forward Selection: We test one feature at a time and keep adding them until we get a good fit
Backward Selection: We test all the features and start removing them to see what works better"
ai,Briefly explain how a basic neural network works,Neural Network,"At its core, a Neural Network is essentially a network of mathematical equations. It takes one or more input variables, and by going through a network of equations, results in one or more output variables. In a neural network, there’s an input layer, one or more hidden layers, and an output layer. The input layer consists of one or more feature variables (or input variables or independent variables) denoted as x1, x2, …, xn. The hidden layer consists of one or more hidden nodes or hidden units. Similarly, the output variable consists of one or more output units. Like I said at the beginning, a neural network is nothing more than a network of equations. Each node in a neural network is composed of two functions, a linear function and an activation function. This is where things can get a little confusing, but for now, think of the linear function as some line of best fit. Also, think of the activation function like a light switch, which results in a number between 1 or 0."
ai,Why is Rectified Linear Unit a good activation function?,Neural Network,"The Rectified Linear Unit, also known as the ReLU function, is known to be a better activation function than the sigmoid function and the tanh function because it performs gradient descent faster."
ai,How are weights initialized in a Network?,Neural Network,"The weights of a neural network MUST be initialized randomly because this is an expectation of stochastic gradient descent.
If you initialized all weights to the same value (i.e. zero or one), then each hidden unit will get exactly the same signal. For example, if all weights are initialized to 0, all hidden units will get zero signal."
ai,What happens if the learning rate is set too high or too low?,Neural Network,"If the learning rate is too low, your model will train very slowly as minimal updates are made to the weights through each iteration. Thus, it would take many updates before reaching the minimum point.
If the learning rate is set too high, this causes undesirable divergent behavior to the loss function due to drastic updates in weights, and it may fail to converge."
ai,What are recurrent neural networks?,Neural Network,"Recurrent neural networks, also known as RNNs, are a class of neural networks that allow previous outputs to be used as inputs while having hidden states.
They are commonly used to recognize the pattern of sequences in data, including time-series data, stock market data, etc…"
ai,What is the role of the activation function?,Neural Network,The purpose of the activation function is to introduce non-linearity into the output of a neuron. The activation function decides whether a neuron should be activated or not by calculating weighted sum and further adding bias with it.
ai,What is the p-value defined as?,Statistics ,"The p-value is the probability of obtaining the observed results of a test, assuming that the null hypothesis is correct; a smaller p-value means that there is stronger evidence in favor of the alternative hypothesis."
ai,What are covariance and correlation? How are they related?,Statistics ,"Covariance is a quantitative measure of the extent to which the deviation of one variable from its mean matches the deviation of the other from its mean.
Correlation is a measurement of the relationship between two variables. It is the covariance of the two variables, normalized by the variance of each variable."
ai,What is the law of large numbers?,Statistics ,"The Law of Large Numbers is a theory that states that as the number of trials increases, the average of the result will become closer to the expected value.
Eg. flipping heads from fair coin 100,000 times should be closer to 0.5 than 100 times."
ai,What is the Central Limit Theorem? Explain it. Why is it important?,Statistics ,"The central limit theorem states that the sampling distribution of the sample mean approaches a normal distribution as the sample size gets larger no matter what the shape of the population distribution.
The central limit theorem is important because it is used in hypothesis testing and also to calculate confidence intervals."
ai,What is the Markov Property?,Statistics ,"When modeling a stochastic process, one in which an agent makes random decisions over time, such an assumption is referred to as the Markov property."
ai,What is statistical power?,Statistics ,"‘Statistical power’ refers to the power of a binary hypothesis, which is the probability that the test rejects the null hypothesis given that the alternative hypothesis is true."
ai,What are confounding variables?,Statistics ,"A confounding variable, or a confounder, is a variable that influences both the dependent variable and the independent variable, causing a spurious association, a mathematical relationship in which two or more variables are associated but not causally related."
ai,How does experimental data contrast with observational data?,Statistics ,"Observational data comes from observational studies which are when you observe certain variables without intervening and try to determine if there is any correlation.
Experimental data comes from experimental studies (with intervention) which are when you control certain variables and hold them constant to determine if there is any causality."
ai,"Explain selection bias (with regard to a dataset, not variable selection). Why is it important? How can data management procedures such as missing data handling make it worse?",Statistics ,"Selection bias is the phenomenon of selecting individuals, groups, or data for analysis in such a way that proper randomization is not achieved, ultimately resulting in a sample that is not representative of the population.
Understanding and identifying selection bias is important because it can significantly skew results and provide false insights about a particular population group.
Types of selection bias include:
Sampling bias: a biased sample caused by non-random sampling
Time interval: selecting a specific time frame that supports the desired conclusion. e.g. conducting a sales analysis near Christmas.
Exposure: includes clinical susceptibility bias, protopathic bias, indication bias. 
Data: includes cherry-picking, suppressing evidence, and the fallacy of incomplete evidence.
Attrition: attrition bias is similar to survivorship bias, where only those that ‘survived’ a long process are included in an analysis, or failure bias, where those that ‘failed’ are only included
Observer selection: related to the Anthropic principle, which is a philosophical consideration that any data we collect about the universe is filtered by the fact that, in order for it to be observable, it must be compatible with the conscious and sapient life that observes it.
Handling missing data can make selection bias worse because different methods impact the data in different ways. For example, if you replace null values with the mean of the data, you adding bias in the sense that you’re assuming that the data is not as spread out as it might actually be."
ai,What is the difference between interpolation and extrapolation and why does it matter?,Statistics ,"Interpolation is when a prediction is made using inputs that lie within the set of observed values.
Extrapolation is when a prediction is made using an input that’s outside of the set of observed values.
It’s important to know the distinction because interpolations are generally more accurate than extrapolations."
ai,Give an example where the median is a better measure than the mean,Statistics ,When there are a number of outliers that positively or negatively skew the data.
ai,What is survivorship bias?,Statistics ,"The phenomenon where only those that ‘survived’ a long process are included or excluded in an analysis, thus creating a biased sample.
A great example provided by Sreenivasan Chandrasekar is the following:
“We enroll for gym membership and attend for a few days. We see the same faces of many people who are fit, motivated and exercising everyday whenever we go to gym. After a few days we become depressed why we aren’t able to stick to our schedule and motivation more than a week when most of the people who we saw at gym could. What we didn’t see was that many of the people who had enrolled for gym membership had also stopped turning up for gym just after a week and we didn’t see them.”"
ai,What is root cause analysis? How can you identify a cause vs. a correlation? Give examples.,Statistics ,"Root cause analysis is a method of problem-solving used for identifying the root cause(s) of a problem
You can identify a correlation using simple data analyses. You can then identify causation by conducting an experiment so that all other variables are isolated (ideally)."
ai,Give me 3 types of statistical biases and explain each of them with an example.,Statistics ,"Sampling bias refers to a biased sample caused by non-random sampling.
To give an example, imagine that there are 10 people in a room and you ask if they prefer grapes or bananas. If you only surveyed the three females and concluded that the majority of people like grapes, you’d have demonstrated sampling bias. Confirmation bias: the tendency to favour information that confirms one’s beliefs.
Survivorship bias: the phenomenon where only those that ‘survived’ a long process are included or excluded in an analysis, thus creating a biased sample."
ai,Explain what a long-tailed distribution is and provide three examples of relevant phenomena that have long tails. Why are they important in classification and regression problems?,Statistics ,"A long-tailed distribution is a type of heavy-tailed distribution that has a tail (or tails) that drop off gradually and asymptotically.
3 practical examples include the power law, the Pareto principle (more commonly known as the 80–20 rule), and product sales (i.e. best selling products vs others).
It’s important to be mindful of long-tailed distributions in classification and regression problems because the least frequently occurring values make up the majority of the population. This can ultimately change the way that you deal with outliers, and it also conflicts with some machine learning techniques with the assumption that the data is normally distributed."
ai,What is A/B testing? When is it used in practice?,Statistics ,"A/B Testing is a statistical hypothesis testing meant for a randomized experiment with two variables, A and B. It is commonly used in product development and marketing."
ai,How do you control for biases?,Statistics ,"There are many things that you can do to control and minimize bias. Two common things include randomization, where participants are assigned by chance, and random sampling, sampling in which each member has an equal probability of being chosen."
ai,"Give examples of data that does not have a Gaussian distribution, nor log-normal.",Statistics ,"Any type of categorical data won’t have a gaussian distribution or lognormal distribution.
Exponential distributions — eg. the amount of time that a car battery lasts or the amount of time until an earthquake occurs."
ai,How do you assess the statistical significance of an insight?,Statistics ,"You would perform hypothesis testing to determine statistical significance. First, you would state the null hypothesis and alternative hypothesis. Second, you would calculate the p-value, the probability of obtaining the observed results of a test assuming that the null hypothesis is true. Last, you would set the level of the significance (alpha) and if the p-value is less than the alpha, you would reject the null — in other words, the result is statistically significant."
ai,The homicide rate in Scotland fell last year to 99 from 115 the year before. Is this reported change really noteworthy?,Statistics ,"Since this is a Poisson distribution question, mean = lambda = variance, which also means that standard deviation = square root of the mean.
a 95% confidence interval implies a z score of 1.96
one standard deviation = sqrt(115) = 10.724
Therefore the confidence interval = 115+/- 21.45 = [93.55, 136.45]. Since 99 is within this confidence interval, we can assume that this change is not very noteworthy."
ai,What is the difference between a boxplot and a histogram?,Statistics ,"While boxplots and histograms are visualizations used to show the distribution of the data, they communicate information differently.
Histograms are bar charts that show the frequency of a numerical variable’s values and are used to approximate the probability distribution of the given variable. It allows you to quickly understand the shape of the distribution, the variation, and potential outliers.
Boxplots communicate different aspects of the distribution of data. While you can’t see the shape of the distribution through a box plot, you can gather other information like the quartiles, the range, and outliers. Boxplots are especially useful when you want to compare multiple charts at the same time because they take up less space than histograms."
ai,What is the meaning of ACF and PACF?,Statistics ,"To understand ACF and PACF, you first need to know what autocorrelation or serial correlation is. Autocorrelation looks at the degree of similarity between a given time series and a lagged version of itself.
Therefore, the autocorrelation function (ACF) is a tool that is used to find patterns in the data, specifically in terms of correlations between points separated by various time lags. For example, ACF(0)=1 means that all data points are perfectly correlated with themselves and ACF(1)=0.9 means that the correlation between one point and the next one is 0.9.
The PACF is short for partial autocorrelation function. Quoting a text from StackExchange, “It can be thought as the correlation between two points that are separated by some number of periods n, but with the effect of the intervening correlations removed.” For example. If T1 is directly correlated with T2 and T2 is directly correlated with T3, it would appear that T1 is correlated with T3. PACF will remove the intervening correlation with T2."
ai,How would you design an experiment for a new feature we’re thinking about. What metrics would matter?,Methodology,"I would conduct an A/B test to determine if the introduction of a new feature results in a statistically significant improvement in a given metric that we care about. The metric(s) chosen depends on the goal of the feature. For example, a feature may be introduced to increase conversion rates, or web traffic, or retention rates.
First I would formulate my null hypothesis (feature X will not improve metric A) and my alternative hypothesis (feature X will improve metric A).
Next, I would create my control and test group through random sampling. Because the t-test inherently considers the sample size, I’m not going to specify a necessary sample size, although the larger the better.
Once I collect my data, depending on the characteristics of my data, I’d then conduct a t-test, Welch’s t-test, chi-squared test, or a Bayesian A/B test to determine whether the differences between my control and test group are statistically significant."
ai,How do you prove that males are on average taller than females by knowing just gender height?,Methodology,"You can use hypothesis testing to prove that males are taller on average than females.
The null hypothesis would state that males and females are the same height on average, while the alternative hypothesis would state that the average height of males is greater than the average height of females.
Then you would collect a random sample of heights of males and females and use a t-test to determine if you reject the null or not."
ai,"If a PM says that they want to double the number of ads in Newsfeed, how would you figure out if this is a good idea or not?",Methodology,"You can perform an A/B test by splitting the users into two groups: a control group with the normal number of ads and a test group with double the number of ads. Then you would choose the metric to define what a “good idea” is. For example, we can say that the null hypothesis is that doubling the number of ads will reduce the time spent on Facebook and the alternative hypothesis is that doubling the number of ads won’t have any impact on the time spent on Facebook. However, you can choose a different metric like the number of active users or the churn rate. Then you would conduct the test and determine the statistical significance of the test to reject or not reject the null."
ai,How can you tell if a given coin is biased?,Methodology,"This isn’t a trick question. The answer is simply to perform a hypothesis test:
The null hypothesis is that the coin is not biased and the probability of flipping heads should equal 50% (p=0.5). The alternative hypothesis is that the coin is biased and p != 0.5.
Flip the coin 500 times.
Calculate Z-score (if the sample is less than 30, you would calculate the t-statistics).
Compare against alpha (two-tailed test so 0.05/2 = 0.025).
If p-value > alpha, the null is not rejected and the coin is not biased.
If p-value < alpha, the null is rejected and the coin is biased."
ai,How to define/select metrics?,Methodology,"There isn’t a one-size-fits-all metric. The metric(s) chosen to evaluate a machine learning model depends on various factors:
Is it a regression or classification task?
What is the business objective? Eg. precision vs recall
What is the distribution of the target variable?
There are a number of metrics that can be used, including adjusted r-squared, MAE, MSE, accuracy, recall, precision, f1 score, and the list goes on."
ai,Why is dimension reduction important?,Methodology,"Dimensionality reduction is the process of reducing the number of features in a dataset. This is important mainly in the case when you want to reduce variance in your model (overfitting).
Wikipedia states four advantages of dimensionality reduction:
It reduces the time and storage space required
Removal of multi-collinearity improves the interpretation of the parameters of the machine learning model
It becomes easier to visualize the data when reduced to very low dimensions such as 2D or 3D
It avoids the curse of dimensionality"
ai,Why is Naive Bayes so bad? How would you improve a spam detection algorithm that uses naive Bayes?,Naive Bayes,"One major drawback of Naive Bayes is that it holds a strong assumption in that the features are assumed to be uncorrelated with one another, which typically is never the case.
One way to improve such an algorithm that uses Naive Bayes is by decorrelating the features so that the assumption holds true."
ai,How to check if the regression model fits the data well?,Linear Regression,"There are a couple of metrics that you can use:
R-squared/Adjusted R-squared: Relative measure of fit. This was explained in a previous answer
F1 Score: Evaluates the null hypothesis that all regression coefficients are equal to zero vs the alternative hypothesis that at least one doesn’t equal zero
RMSE: Absolute measure of fit."
ai,What is a decision tree?,Decision Trees,"Decision trees are a popular model, used in operations research, strategic planning, and machine learning. Each square above is called a node, and the more nodes you have, the more accurate your decision tree will be (generally). The last nodes of the decision tree, where a decision is made, are called the leaves of the tree. Decision trees are intuitive and easy to build but fall short when it comes to accuracy."
ai,What is a kernel? Explain the kernel trick,SVM,"A kernel is a way of computing the dot product of two vectors 𝐱x and 𝐲y in some (possibly very high dimensional) feature space, which is why kernel functions are sometimes called “generalized dot product”. The kernel trick is a method of using a linear classifier to solve a non-linear problem by transforming linearly inseparable data to linearly separable ones in a higher dimension."
ai,Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?,SVM,"When the number of features is greater than the number of observations, then performing dimensionality reduction will generally improve the SVM."
ai,What is overfitting?,Methodology,"Overfitting is an error where the model ‘fits’ the data too well, resulting in a model with high variance and low bias. As a consequence, an overfit model will inaccurately predict new data points even though it has a high accuracy on the training data."
ai,What is boosting?,Methodology,"Boosting is an ensemble method to improve a model by reducing its bias and variance, ultimately converting weak learners to strong learners. The general idea is to train a weak learner and sequentially iterate and improve the model by learning from the previous learner."
ai,Difference between convex and non-convex cost function; what does it mean when a cost function is non-convex?,Statistics,"A convex function is one where a line drawn between any two points on the graph lies on or above the graph. It has one minimum.
A non-convex function is one where a line drawn between any two points on the graph may intersect other points on the graph. It characterized as “wavy”.
When a cost function is non-convex, it means that there’s a likelihood that the function may find local minima instead of the global minimum, which is typically undesired in machine learning models from an optimization perspective."
ai,"What is an outlier? Explain how you might screen for outliers and what would you do if you found them in your dataset. Also, explain what an inlier is and how you might screen for them and what would you do if you found them in your dataset.",EDA,"An outlier is a data point that differs significantly from other observations.
Depending on the cause of the outlier, they can be bad from a machine learning perspective because they can worsen the accuracy of a model. If the outlier is caused by a measurement error, it’s important to remove them from the dataset. There are a couple of ways to identify outliers:
Z-score/standard deviations: if we know that 99.7% of data in a data set lie within three standard deviations, then we can calculate the size of one standard deviation, multiply it by 3, and identify the data points that are outside of this range. Likewise, we can calculate the z-score of a given point, and if it’s equal to +/- 3, then it’s an outlier.
Note: that there are a few contingencies that need to be considered when using this method; the data must be normally distributed, this is not applicable for small data sets, and the presence of too many outliers can throw off z-score. Interquartile Range (IQR): IQR, the concept used to build boxplots, can also be used to identify outliers. The IQR is equal to the difference between the 3rd quartile and the 1st quartile. You can then identify if a point is an outlier if it is less than Q1–1.5*IRQ or greater than Q3 + 1.5*IQR. This comes to approximately 2.698 standard deviations. Other methods include DBScan clustering, Isolation Forests, and Robust Random Cut Forests.
An inlier is a data observation that lies within the rest of the dataset and is unusual or an error. Since it lies in the dataset, it is typically harder to identify than an outlier and requires external data to identify them. Should you identify any inliers, you can simply remove them from the dataset to address them."
ai,How do you handle missing data? What imputation techniques do you recommend?,EDA,"There are several ways to handle missing data:
Delete rows with missing data
Mean/Median/Mode imputation
Assigning a unique value
Predicting the missing values
Using an algorithm which supports missing values, like random forests
The best method is to delete rows with missing data as it ensures that no bias or variance is added or removed, and ultimately results in a robust and accurate model. However, this is only recommended if there’s a lot of data to start with and the percentage of missing values is low."
ai,"You are compiling a report for user content uploaded every month and notice a spike in uploads in October. In particular, a spike in picture uploads. What might you think is the cause of this, and how would you test it?",Methodology,"There are a number of potential reasons for a spike in photo uploads:
A new feature may have been implemented in October which involves uploading photos and gained a lot of traction by users. For example, a feature that gives the ability to create photo albums.
Similarly, it’s possible that the process of uploading photos before was not intuitive and was improved in the month of October.
There may have been a viral social media movement that involved uploading photos that lasted for all of October. Eg. Movember but something more scalable.
It’s possible that the spike is due to people posting pictures of themselves in costumes for Halloween.
The method of testing depends on the cause of the spike, but you would conduct hypothesis testing to determine if the inferred cause is the actual cause."
ai,How do you calculate the needed sample size?,Statistics,You can use the margin of error (ME) formula to determine the desired sample size.
ai,You are running for office and your pollster polled hundred people. Sixty of them claimed they will vote for you. Can you relax?,Methodology,"Assume that there’s only you and one other opponent.
Also, assume that we want a 95% confidence interval. This gives us a z-score of 1.96. p-hat = 60/100 = 0.6
z* = 1.96
n = 100
This gives us a confidence interval of [50.4,69.6]. Therefore, given a confidence interval of 95%, if you are okay with the worst scenario of tying then you can relax. Otherwise, you cannot relax until you got 61 out of 100 to claim yes."
ai,You are given a train data set having 1000 columns and 1 million rows. The data set is based on a classification problem. Your manager has asked you to reduce the dimension of this data so that model computation time can be reduced. Your machine has memory constraints. What would you do? (You are free to make practical assumptions.),Methodology,"Since we have lower RAM, we should close all other applications in our machine, including the web browser, so that most of the memory can be put to use.
We can randomly sample the data set. This means, we can create a smaller data set, let’s say, having 1000 variables and 300000 rows and do the computations.
To reduce dimensionality, we can separate the numerical and categorical variables and remove the correlated variables. For numerical variables, we’ll use correlation. For categorical variables, we’ll use chi-square test.
Also, we can use PCA and pick the components which can explain the maximum variance in the data set.
Using online learning algorithms like Vowpal Wabbit (available in Python) is a possible option.
Building a linear model using Stochastic Gradient Descent is also helpful.
We can also apply our business understanding to estimate which all predictors can impact the response variable. But, this is an intuitive approach, failing to identify useful predictors might result in significant loss of information."
ai,"Is rotation necessary in PCA? If yes, Why? What will happen if you don’t rotate the components?",Methodology,"Yes, rotation (orthogonal) is necessary because it maximizes the difference between variance captured by the component. This makes the components easier to interpret. Not to forget, that’s the motive of doing PCA where, we aim to select fewer components (than features) which can explain the maximum variance in the data set. By doing rotation, the relative location of the components doesn’t change, it only changes the actual coordinates of the points.

If we don’t rotate the components, the effect of PCA will diminish and we’ll have to select more number of components to explain variance in the data set."
ai,You are given a data set. The data set has missing values which spread along 1 standard deviation from the median. What percentage of data would remain unaffected? Why?,Statistics,"This question has enough hints for you to start thinking! Since, the data is spread across median, let’s assume it’s a normal distribution. We know, in a normal distribution, ~68% of the data lies in 1 standard deviation from mean (or mode, median), which leaves ~32% of the data unaffected. Therefore, ~32% of the data would remain unaffected by missing values."
ai,You are given a data set on cancer detection. You’ve build a classification model and achieved an accuracy of 96%. Why shouldn’t you be happy with your model performance? What can you do about it?,Statistics,"If you have worked on enough data sets, you should deduce that cancer detection results in imbalanced data. In an imbalanced data set, accuracy should not be used as a measure of performance because 96% (as given) might only be predicting majority class correctly, but our class of interest is minority class (4%) which is the people who actually got diagnosed with cancer. Hence, in order to evaluate model performance, we should use Sensitivity (True Positive Rate), Specificity (True Negative Rate), F measure to determine class wise performance of the classifier. If the minority class performance is found to to be poor, we can undertake the following steps:               We can use undersampling, oversampling or SMOTE to make the data balanced.
We can alter the prediction threshold value by doing probability caliberation and finding a optimal threshold using AUC-ROC curve.
We can assign weight to classes such that the minority classes gets larger weight.
We can also use anomaly detection."
ai,Why is naive Bayes so ‘naive’ ?,Naive Bayes,"naive Bayes is so ‘naive’ because it assumes that all of the features in a data set are equally important and independent. As we know, these assumption are rarely true in real world scenario."
ai,"Explain prior probability, likelihood and marginal likelihood in context of Naive Bayes algorithm?",Naive Bayes,"Prior probability is nothing but, the proportion of dependent (binary) variable in the data set. It is the closest guess you can make about a class, without any further information. For example: In a data set, the dependent variable is binary (1 and 0). The proportion of 1 (spam) is 70% and 0 (not spam) is 30%. Hence, we can estimate that there are 70% chances that any new email would be classified as spam.

Likelihood is the probability of classifying a given observation as 1 in presence of some other variable. For example: The probability that the word ‘FREE’ is used in previous spam message is likelihood. Marginal likelihood is, the probability that the word ‘FREE’ is used in any message."
ai,"You are working on a time series data set. You manager has asked you to build a high accuracy model. You start with the decision tree algorithm, since you know it works fairly well on all kinds of data. Later, you tried a time series regression model and got higher accuracy than decision tree model. Can this happen? Why?","Time Series, Decision Trees","Time series data is known to posses linearity. On the other hand, a decision tree algorithm is known to work best to detect non – linear interactions. The reason why decision tree failed to provide robust predictions because it couldn’t map the linear relationship as good as a regression model did. Therefore, we learned that, a linear regression model can provide robust prediction given the data set satisfies its linearity assumptions."
ai,"You are assigned a new project which involves helping a food delivery company save more money. The problem is, company’s delivery team aren’t able to deliver food on time. As a result, their customers get unhappy. And, to keep them happy, they end up delivering food for free. Which machine learning algorithm can save them?",Methodology,"You might have started hopping through the list of ML algorithms in your mind. But, wait! Such questions are asked to test your machine learning fundamentals.

This is not a machine learning problem. This is a route optimization problem. A machine learning problem consist of three things:

There exist a pattern.
You cannot solve it mathematically (even by writing exponential equations).
You have data on it.
Always look for these three factors to decide if machine learning is a tool to solve a particular problem."
ai,You came to know that your model is suffering from low bias and high variance. Which algorithm should you use to tackle it? Why?,Methodology,"Low bias occurs when the model’s predicted values are near to actual values. In other words, the model becomes flexible enough to mimic the training data distribution. While it sounds like great achievement, but not to forget, a flexible model has no generalization capabilities. It means, when this model is tested on an unseen data, it gives disappointing results.

In such situations, we can use bagging algorithm (like random forest) to tackle high variance problem. Bagging algorithms divides a data set into subsets made with repeated randomized sampling. Then, these samples are used to generate a set of models using a single learning algorithm. Later, the model predictions are combined using voting (classification) or averaging (regression).

Also, to combat high variance, we can:

Use regularization technique, where higher model coefficients get penalized, hence lowering model complexity.
Use top n features from variable importance chart. May be, with all the variable in the data set, the algorithm is having difficulty in finding the meaningful signal."
ai,"You are given a data set. The data set contains many variables, some of which are highly correlated and you know about it. Your manager has asked you to run PCA. Would you remove correlated variables first? Why?",EDA,"Chances are, you might be tempted to say No, but that would be incorrect. Discarding correlated variables have a substantial effect on PCA because, in presence of correlated variables, the variance explained by a particular component gets inflated.

For example: You have 3 variables in a data set, of which 2 are correlated. If you run PCA on this data set, the first principal component would exhibit twice the variance than it would exhibit with uncorrelated variables. Also, adding correlated variables lets PCA put more importance on those variable, which is misleading."
ai,"After spending several hours, you are now anxious to build a high accuracy model. As a result, you build 5 GBM models, thinking a boosting algorithm would do the magic. Unfortunately, neither of models could perform better than benchmark score. Finally, you decided to combine those models. Though, ensembled models are known to return high accuracy, but you are unfortunate. Where did you miss?",Methodology,"As we know, ensemble learners are based on the idea of combining weak learners to create strong learners. But, these learners provide superior result when the combined models are uncorrelated. Since, we have used 5 GBM models and got no accuracy improvement, suggests that the models are correlated. The problem with correlated models is, all the models provide same information.

For example: If model 1 has classified User1122 as 1, there are high chances model 2 and model 3 would have done the same, even if its actual value is 0. Therefore, ensemble learners are built on the premise of combining weak uncorrelated models to obtain better predictions."
ai,How is kNN different from kmeans clustering?,"KNN, KMeans","Don’t get mislead by ‘k’ in their names. You should know that the fundamental difference between both these algorithms is, kmeans is unsupervised in nature and kNN is supervised in nature. kmeans is a clustering algorithm. kNN is a classification (or regression) algorithm.

kmeans algorithm partitions a data set into clusters such that a cluster formed is homogeneous and the points in each cluster are close to each other. The algorithm tries to maintain enough separability between these clusters. Due to unsupervised nature, the clusters have no labels.

kNN algorithm tries to classify an unlabeled observation based on its k (can be any number ) surrounding neighbors. It is also known as lazy learner because it involves minimal training of model. Hence, it doesn’t use training data to make generalization on unseen data set."
ai,How is True Positive Rate and Recall related? Write the equation.,Statistics,"True Positive Rate = Recall. Yes, they are equal having the formula (TP/TP + FN)."
ai,"You have built a multiple regression model. Your model R² isn’t as good as you wanted. For improvement, your remove the intercept term, your model R² becomes 0.8 from 0.3. Is it possible? How?",Linear Regression,"Yes, it is possible. We need to understand the significance of intercept term in a regression model. The intercept term shows model prediction without any independent variable i.e. mean prediction. The formula of R² = 1 – ∑(y – y´)²/∑(y – ymean)² where y´ is predicted value.

When intercept term is present, R² value evaluates your model wrt. to the mean model. In absence of intercept term (ymean), the model can make no such evaluation, with large denominator, ∑(y - y´)²/∑(y)² equation’s value becomes smaller than actual, resulting in higher R²."
ai,"After analyzing the model, your manager has informed that your regression model is suffering from multicollinearity. How would you check if he’s true? Without losing any information, can you still build a better model?",Linear Regression,"To check multicollinearity, we can create a correlation matrix to identify & remove variables having correlation above 75% (deciding a threshold is subjective). In addition, we can use calculate VIF (variance inflation factor) to check the presence of multicollinearity. VIF value = 10 implies serious multicollinearity. Also, we can use tolerance as an indicator of multicollinearity.

But, removing correlated variables might lead to loss of information. In order to retain those variables, we can use penalized regression models like ridge or lasso regression. Also, we can add some random noise in correlated variable so that the variables become different from each other. But, adding noise might affect the prediction accuracy, hence this approach should be carefully used."
ai,When is Ridge regression favorable over Lasso regression?,Linear Regression,"Conceptually, we can say, lasso regression (L1) does both variable selection and parameter shrinkage, whereas Ridge regression only does parameter shrinkage and end up including all the coefficients in the model. In presence of correlated variables, ridge regression might be the preferred choice. Also, ridge regression works best in situations where the least square estimates have higher variance. Therefore, it depends on our model objective."
ai,Rise in global average temperature led to decrease in number of pirates around the world. Does that mean that decrease in number of pirates caused the climate change?,Statistics,"After reading this question, you should have understood that this is a classic case of “causation and correlation”. No, we can’t conclude that decrease in number of pirates caused the climate change because there might be other factors (lurking or confounding variables) influencing this phenomenon.

Therefore, there might be a correlation between global average temperature and number of pirates, but based on this information we can’t say that pirated died because of rise in global average temperature.
"
ai,"While working on a data set, how do you select important variables? Explain your methods.",EDA,"Following are the methods of variable selection you can use:

Remove the correlated variables prior to selecting important variables
Use linear regression and select variables based on p values
Use Forward Selection, Backward Selection, Stepwise Selection
Use Random Forest, Xgboost and plot variable importance chart
Use Lasso Regression
Measure information gain for the available set of features and select top n features accordingly."
ai,What is the difference between covariance and correlation?,Statistics ,"Correlation is the standardized form of covariance.

Covariances are difficult to compare. For example: if we calculate the covariances of salary ($) and age (years), we’ll get different covariances which can’t be compared because of having unequal scales. To combat such situation, we calculate correlation to get a value between -1 and 1, irrespective of their respective scale."
ai,"Is it possible capture the correlation between continuous and categorical variable? If yes, how?",Statistics ,"Yes, we can use ANCOVA (analysis of covariance) technique to capture association between continuous and categorical variables."
ai,"Both being tree based algorithm, how is random forest different from Gradient boosting algorithm (GBM)?","Random Forest, Gradient Boosting","The fundamental difference is, random forest uses bagging technique to make predictions. GBM uses boosting techniques to make predictions.

In bagging technique, a data set is divided into n samples using randomized sampling. Then, using a single learning algorithm a model is build on all samples. Later, the resultant predictions are combined using voting or averaging. Bagging is done in parallel. In boosting, after the first round of predictions, the algorithm weighs misclassified predictions higher, such that they can be corrected in the succeeding round. This sequential process of giving higher weights to misclassified predictions continue until a stopping criterion is reached.

Random forest improves model accuracy by reducing variance (mainly). The trees grown are uncorrelated to maximize the decrease in variance. On the other hand, GBM improves accuracy my reducing both bias and variance in a model."
ai,Running a binary classification tree algorithm is the easy part. Do you know how does a tree splitting takes place i.e. how does the tree decide which variable to split at the root node and succeeding nodes?,Decision Trees,"A classification trees makes decision based on Gini Index and Node Entropy. In simple words, the tree algorithm find the best possible feature which can divide the data set into purest possible children nodes."
ai,"You’ve built a random forest model with 10000 trees. You got delighted after getting training error as 0.00. But, the validation error is 34.23. What is going on? Haven’t you trained your model perfectly?",Random Forest,"The model has overfitted. Training error 0.00 means the classifier has mimiced the training data patterns to an extent, that they are not available in the unseen data. Hence, when this classifier was run on unseen sample, it couldn’t find those patterns and returned prediction with higher error. In random forest, it happens when we use larger number of trees than necessary. Hence, to avoid these situation, we should tune number of trees using cross validation.
"
ai,You’ve got a data set to work having p (no. of variable) > n (no. of observation). Why is OLS as bad option to work with? Which techniques would be best to use? Why?,Methodology,"In such high dimensional data sets, we can’t use classical regression techniques, since their assumptions tend to fail. When p > n, we can no longer calculate a unique least square coefficient estimate, the variances become infinite, so OLS cannot be used at all.

To combat this situation, we can use penalized regression methods like lasso, LARS, ridge which can shrink the coefficients to reduce variance. Precisely, ridge regression works best in situations where the least square estimates have higher variance.

Among other methods include subset regression, forward stepwise regression."
ai,What is convex hull ? (Hint: Think SVM),SVM,"In case of linearly separable data, convex hull represents the outer boundaries of the two group of data points. Once convex hull is created, we get maximum margin hyperplane (MMH) as a perpendicular bisector between two convex hulls. MMH is the line which attempts to create greatest separation between two groups."
ai,"We know that one hot encoding increasing the dimensionality of a data set. But, label encoding doesn’t. How ?",EDA,"Don’t get baffled at this question. It’s a simple question asking the difference between the two.

Using one hot encoding, the dimensionality (a.k.a features) in a data set get increased because it creates a new variable for each level present in categorical variables. For example: let’s say we have a variable ‘color’. The variable has 3 levels namely Red, Blue and Green. One hot encoding ‘color’ variable will generate three new variables as Color.Red, Color.Blue and Color.Green containing 0 and 1 value.

In label encoding, the levels of a categorical variables gets encoded as 0 and 1, so no new variable is created. Label encoding is majorly used for binary variables."
ai,What cross validation technique would you use on time series data set? Is it k-fold or LOOCV?,Time Series,"Neither.

In time series problem, k fold can be troublesome because there might be some pattern in year 4 or 5 which is not in year 3. Resampling the data set will separate these trends, and we might end up validation on past years, which is incorrect. Instead, we can use forward chaining strategy with 5 fold as shown below:

fold 1 : training [1], test [2]
fold 2 : training [1 2], test [3]
fold 3 : training [1 2 3], test [4]
fold 4 : training [1 2 3 4], test [5]
fold 5 : training [1 2 3 4 5], test [6]
where 1,2,3,4,5,6 represents “year”.
"
ai,"You are given a data set consisting of variables having more than 30% missing values? Let’s say, out of 50 variables, 8 variables have missing values higher than 30%. How will you deal with them?",EDA,"We can deal with them in the following ways:

Assign a unique category to missing values, who knows the missing values might decipher some trend
We can remove them blatantly.
Or, we can sensibly check their distribution with the target variable, and if found any pattern we’ll keep those missing values and assign them a new category while removing others."
ai,"‘People who bought this, also bought…’ recommendations seen on amazon is a result of which algorithm?",Methodology,"The basic idea for this kind of recommendation engine comes from collaborative filtering.

Collaborative Filtering algorithm considers “User Behavior” for recommending items. They exploit behavior of other users and items in terms of transaction history, ratings, selection and purchase information. Other users behaviour and preferences over the items are used to recommend items to the new users. In this case, features of the items are not known."
ai,What do you understand by Type I vs Type II error ?,Statistics ,"Type I error is committed when the null hypothesis is true and we reject it, also known as a ‘False Positive’. Type II error is committed when the null hypothesis is false and we accept it, also known as ‘False Negative’.

In the context of confusion matrix, we can say Type I error occurs when we classify a value as positive (1) when it is actually negative (0). Type II error occurs when we classify a value as negative (0) when it is actually positive(1)."
ai,"You are working on a classification problem. For validation purposes, you’ve randomly sampled the training data set into train and validation. You are confident that your model will work incredibly well on unseen data since your validation accuracy is high. However, you get shocked after getting poor test accuracy. What went wrong?",Methodology,"In case of classification problem, we should always use stratified sampling instead of random sampling. A random sampling doesn’t takes into consideration the proportion of target classes. On the contrary, stratified sampling helps to maintain the distribution of target variable in the resultant distributed samples also."
ai,"You have been asked to evaluate a regression model based on R², adjusted R² and tolerance. What will be your criteria?",Linear Regression,"Tolerance (1 / VIF) is used as an indicator of multicollinearity. It is an indicator of percent of variance in a predictor which cannot be accounted by other predictors. Large values of tolerance is desirable.

We will consider adjusted R² as opposed to R² to evaluate model fit because R² increases irrespective of improvement in prediction accuracy as we add more variables. But, adjusted R² would only increase if an additional variable improves the accuracy of model, otherwise stays same. It is difficult to commit a general threshold value for adjusted R² because it varies between data sets. For example: a gene mutation data set might result in lower adjusted R² and still provide fairly good predictions, as compared to a stock market data where lower adjusted R² implies that model is not good."
ai,"In k-means or kNN, we use euclidean distance to calculate the distance between nearest neighbors. Why not manhattan distance ?","KMeans, KNN","We don’t use manhattan distance because it calculates distance horizontally or vertically only. It has dimension restrictions. On the other hand, euclidean metric can be used in any space to calculate distance. Since, the data points can be present in any dimension, euclidean distance is a more viable option."
ai,Explain machine learning to me like a 5 year old.,Methodology,"It’s simple. It’s just like how babies learn to walk. Every time they fall down, they learn (unconsciously) & realize that their legs should be straight and not in a bend position. The next time they fall down, they feel pain. They cry. But, they learn ‘not to stand like that again’. In order to avoid that pain, they try harder. To succeed, they even seek support from the door or wall or anything near them, which helps them stand firm.

This is how a machine works & develops intuition from its environment."
ai,I know that a linear regression model is generally evaluated using Adjusted R² or F value. How would you evaluate a logistic regression model?,"Linear Regression, Logistic Regression","Since logistic regression is used to predict probabilities, we can use AUC-ROC curve along with confusion matrix to determine its performance.
Also, the analogous metric of adjusted R² in logistic regression is AIC. AIC is the measure of fit which penalizes model for the number of model coefficients. Therefore, we always prefer model with minimum AIC value.
Null Deviance indicates the response predicted by a model with nothing but an intercept. Lower the value, better the model. Residual deviance indicates the response predicted by a model on adding independent variables. Lower the value, better the model."
ai,"Considering the long list of machine learning algorithm, given a data set, how do you decide which one to use?",Methodology,"You should say, the choice of machine learning algorithm solely depends of the type of data. If you are given a data set which is exhibits linearity, then linear regression would be the best algorithm to use. If you given to work on images, audios, then neural network would help you to build a robust model.

If the data comprises of non linear interactions, then a boosting or bagging algorithm should be the choice. If the business requirement is to build a model which can be deployed, then we’ll use regression or a decision tree model (easy to interpret and explain) instead of black box algorithms like SVM, GBM etc.

In short, there is no one master algorithm for all situations. We must be scrupulous enough to understand which algorithm to use."
ai,Do you suggest that treating a categorical variable as continuous variable would result in a better predictive model?,EDA,"For better predictions, categorical variable can be considered as a continuous variable only when the variable is ordinal in nature."
ai,When does regularization becomes necessary in Machine Learning?,Methodology,"Regularization becomes necessary when the model begins to ovefit / underfit. This technique introduces a cost term for bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and hence reduce cost term. This helps to reduce model complexity so that the model can become better at predicting (generalizing).
"
ai,OLS is to linear regression. Maximum likelihood is to logistic regression. Explain the statement.,"Linear Regression, Logistic Regression","OLS and Maximum likelihood are the methods used by the respective regression methods to approximate the unknown parameter (coefficient) value. In simple words,

Ordinary least square(OLS) is a method used in linear regression which approximates the parameters resulting in minimum distance between actual and predicted values. Maximum Likelihood helps in choosing the the values of parameters which maximizes the likelihood that the parameters are most likely to produce observed data."
ai,How is logistic regression done?,Logistic Regression,Logistic regression measures the relationship between the dependent variable (our label of what we want to predict) and one or more independent variables (our features) by estimating probability using its underlying logistic function (sigmoid).
ai,Explain the steps in making a decision tree.,Decision Trees,"Take the entire data set as input
Calculate entropy of the target variable, as well as the predictor attributes
Calculate your information gain of all attributes (we gain information on sorting different objects from each other)
Choose the attribute with the highest information gain as the root node 
Repeat the same procedure on every branch until the decision node of each branch is finalized"
ai,How do you build a random forest model?,Random Forest,"A random forest is built up of a number of decision trees. If you split the data into different packages and make a decision tree in each of the different groups of data, the random forest brings all those trees together.

Steps to build a random forest model:
Randomly select 'k' features from a total of 'm' features where k << m
Among the 'k' features, calculate the node D using the best split point
Split the node into daughter nodes using the best split
Repeat steps two and three until leaf nodes are finalized 
Build forest by repeating steps one to four for 'n' times to create 'n' number of trees "
ai,How can you avoid overfitting your model?,Methodology,"Overfitting refers to a model that is only set for a very small amount of data and ignores the bigger picture. There are three main methods to avoid overfitting:

Keep the model simple—take fewer variables into account, thereby removing some of the noise in the training data
Use cross-validation techniques, such as k folds cross-validation 
Use regularization techniques, such as LASSO, that penalize certain model parameters if they're likely to cause overfitting"
ai,What are the feature selection methods used to select the right variables?,EDA,"There are two main methods for feature selection, i.e, filter, and wrapper methods.

Filter Methods
This involves: 

Linear discrimination analysis
ANOVA
Chi-Square
The best analogy for selecting features is ""bad data in, bad answer out."" When we're limiting or selecting the features, it's all about cleaning up the data coming in. 

Wrapper Methods
This involves: 

Forward Selection: We test one feature at a time and keep adding them until we get a good fit
Backward Selection: We test all the features and start removing them to see what works better
Recursive Feature Elimination: Recursively looks through all the different features and how they pair together
Wrapper methods are very labor-intensive, and high-end computers are needed if a lot of data analysis is performed with the wrapper method. "
ai,What are dimensionality reduction and its benefits?,Methodology,"Dimensionality reduction refers to the process of converting a data set with vast dimensions into data with fewer dimensions (fields) to convey similar information concisely. 

This reduction helps in compressing data and reducing storage space. It also reduces computation time as fewer dimensions lead to less computing. It removes redundant features; for example, there's no point in storing a value in two different units (meters and inches). "
ai,How should you maintain a deployed model?,Methodology,"The steps to maintain a deployed model are:

Monitor 
Constant monitoring of all models is needed to determine their performance accuracy. When you change something, you want to figure out how your changes are going to affect things. This needs to be monitored to ensure it's doing what it's supposed to do.

Evaluate
Evaluation metrics of the current model are calculated to determine if a new algorithm is needed. 

Compare
The new models are compared to each other to determine which model performs the best. 

Rebuild
The best performing model is re-built on the current state of data.
"
ai,What are recommender systems?,Methodology,"A recommender system predicts what a user would rate a specific product based on their preferences. It can be split into two different areas:

Collaborative Filtering
As an example, Last.fm recommends tracks that other users with similar interests play often. This is also commonly seen on Amazon after making a purchase; customers may notice the following message accompanied by product recommendations: ""Users who bought this also bought…""

Content-based Filtering
As an example: Pandora uses the properties of a song to recommend music with similar properties. Here, we look at content, instead of looking at who else is listening to music."
ai,How can you select k for k-means? ,KMeans,"We use the elbow method to select k for k-means clustering. The idea of the elbow method is to run k-means clustering on the data set where 'k' is the number of clusters.

Within the sum of squares (WSS), it is defined as the sum of the squared distance between each member of the cluster and its centroid. "
ai,What is the significance of p-value?,Statistics ,"p-value typically ≤ 0.05

This indicates strong evidence against the null hypothesis; so you reject the null hypothesis.

p-value typically > 0.05

This indicates weak evidence against the null hypothesis, so you accept the null hypothesis. 

p-value at cutoff 0.05 

This is considered to be marginal, meaning it could go either way."
ai,How can time-series data be declared as stationery?,Time Series,It is stationary when the variance and mean of the series are constant with time.
ai,Write the equation and calculate the precision and recall rate.,Statistics ,Precision = (True positive) / (True Positive + False Positive)        Recall Rate = (True Positive) / (Total Positive + False Negative)
ai,People who bought this also bought…' recommendations seen on Amazon are a result of which algorithm?,Methodology,"The recommendation engine is accomplished with collaborative filtering. Collaborative filtering explains the behavior of other users and their purchase history in terms of ratings, selection, etc. 

The engine makes predictions on what might interest a person based on the preferences of other users. In this algorithm, item features are unknown. "
ai,"We want to predict the probability of death from heart disease based on three risk factors: age, gender, and blood cholesterol level. What is the most appropriate algorithm for this case?",Methodology,"Choose the correct option:

Logistic Regression 
Linear Regression
K-means clustering 
Apriori algorithm
The most appropriate algorithm for this case is A, logistic regression. "
ai,Your organization has a website where visitors randomly receive one of two coupons. It is also possible that visitors to the website will not receive a coupon. You have been asked to determine if offering a coupon to website visitors has any impact on their purchase decisions. Which analysis method should you use?,Methodology,"One-way ANOVA 
K-means clustering
Association rules 
Student's t-test 
The answer is A: One-way ANOVA"
ai,What are the feature vectors?,Statistics ,"A feature vector is an n-dimensional vector of numerical features that represent an object. In machine learning, feature vectors are used to represent numeric or symbolic characteristics (called features) of an object in a mathematical way that's easy to analyze."
ai,What are the steps in making a decision tree?,Decision Trees,"Take the entire data set as input.
Look for a split that maximizes the separation of the classes. A split is any test that divides the data into two sets.
Apply the split to the input data (divide step).
Re-apply steps one and two to the divided data.
Stop when you meet any stopping criteria.
This step is called pruning. Clean up the tree if you went too far doing splits."
ai,What is root cause analysis? ,Statistics ,Root cause analysis was initially developed to analyze industrial accidents but is now widely used in other areas. It is a problem-solving technique used for isolating the root causes of faults or problems. A factor is called a root cause if its deduction from the problem-fault-sequence averts the final undesirable event from recurring.
ai,What is logistic regression?,Logistic Regression,Logistic regression is also known as the logit model. It is a technique used to forecast the binary outcome from a linear combination of predictor variables.
ai,Explain cross-validation.,Methodology,"Cross-validation is a model validation technique for evaluating how the outcomes of a statistical analysis will generalize to an independent data set. It is mainly used in backgrounds where the objective is to forecast and one wants to estimate how accurately a model will accomplish in practice. 

The goal of cross-validation is to term a data set to test the model in the training phase (i.e. validation data set) to limit problems like overfitting and gain insight into how the model will generalize to an independent data set."
ai,What is collaborative filtering?,Methodology,"Most recommender systems use this filtering process to find patterns and information by collaborating perspectives, numerous data sources, and several agents."
ai,Do gradient descent methods always converge to similar points?,Methodology,"They do not, because in some cases, they reach a local minima or a local optima point. You would not reach the global optima point. This is governed by the data and the starting conditions."
ai,What is the goal of A/B Testing?,Methodology,"This is statistical hypothesis testing for randomized experiments with two variables, A and B. The objective of A/B testing is to detect any changes to a web page to maximize or increase the outcome of a strategy."
ai,What are the drawbacks of the linear model?,Linear Regression,"The assumption of linearity of the errors
It can't be used for count outcomes or binary outcomes
There are overfitting problems that it can't solve"
ai,What are eigenvalue and eigenvector?,Statistics ,"Eigenvalues are the directions along which a particular linear transformation acts by flipping, compressing, or stretching.

Eigenvectors are for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix. "
ai,What is the difference between Point Estimates and Confidence Interval?,Statistics ,"Point Estimation gives us a particular value as an estimate of a population parameter. Method of Moments and Maximum Likelihood estimator methods are used to derive Point Estimators for population parameters.

A confidence interval gives us a range of values which is likely to contain the population parameter. The confidence interval is generally preferred, as it tells us how likely this interval is to contain the population parameter. This likeliness or probability is called Confidence Level or Confidence coefficient and represented by 1 — alpha, where alpha is the level of significance."
ai,What do you understand by statistical power of sensitivity and how do you calculate it?,Statistics ,"Sensitivity is commonly used to validate the accuracy of a classifier (Logistic, SVM, Random Forest etc.).

Sensitivity is nothing but “Predicted True events/ Total events”. True events here are the events which were true and model also predicted them as true."
ai,"Explain how a ROC curve works?
",Statistics ,The ROC curve is a graphical representation of the contrast between true positive rates and false-positive rates at various thresholds. It is often used as a proxy for the trade-off between the sensitivity(true positive rate) and false-positive rate.
ai,What is TF/IDF vectorization?,Methodology,"TF–IDF is short for term frequency-inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval and text mining.

The TF–IDF value increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general."
ai,Why we generally use Softmax non-linearity function as last operation in-network?,Neural Network,It is because it takes in a vector of real numbers and returns a probability distribution. It should be clear that the output is a probability distribution: each element is non-negative and the sum over all components is 1.
ai,Explain SVM algorithm in detail.,SVM,"SVM stands for support vector machine, it is a supervised machine learning algorithm which can be used for both Regression and Classification. If you have n features in your training data set, SVM tries to plot it in n-dimensional space with the value of each feature being the value of a particular coordinate. SVM uses hyperplanes to separate out different classes based on the provided kernel function."
ai,What are the different kernels in SVM?,SVM,"There are four types of kernels in SVM.

Linear Kernel

Polynomial kernel

Radial basis kernel

Sigmoid kernel"
ai,What is the difference between Regression and classification ML techniques?,Methodology,"Both Regression and classification machine learning techniques come under Supervised machine learning algorithms. In Supervised machine learning algorithm, we have to train the model using labelled data set, While training we have to explicitly provide the correct labels and algorithm tries to learn the pattern from input to output. If our labels are discrete values then it will a classification problem, e.g A,B etc. but if our labels are continuous values then it will be a regression problem, e.g 1.23, 1.333 etc."
ai,What are the various steps involved in an analytics project?,EDA,"Understand the Business problem

Explore the data and become familiar with it.

Prepare the data for modelling by detecting outliers, treating missing values, transforming variables, etc.

After data preparation, start running the model, analyze the result and tweak the approach. This is an iterative step until the best possible outcome is achieved.

Validate the model using a new data set.

Start implementing the model and track the result to analyze the performance of the model over the period of time."
ai,What do you mean by Deep Learning? ,Neural Network,Deep Learning is nothing but a paradigm of machine learning which has shown incredible promise in recent years. This is because of the fact that Deep Learning shows a great analogy with the functioning of the human brain.
ai,What is the difference between machine learning and deep learning?,Methodology,"Machine learning is a field of computer science that gives computers the ability to learn without being explicitly programmed. Machine learning can be categorised in the following three categories.

Supervised machine learning,

Unsupervised machine learning,

Reinforcement learning 

Deep Learning is a subfield of machine learning concerned with algorithms inspired by the structure and function of the brain called artificial neural networks."
ai,"What, in your opinion, is the reason for the popularity of Deep Learning in recent times?",Methodology,"Now although Deep Learning has been around for many years, the major breakthroughs from these techniques came just in recent years. This is because of two main reasons:

The increase in the amount of data generated through various sources

The growth in hardware resources required to run these models

GPUs are multiple times faster and they help us build bigger and deeper deep learning models in comparatively less time than we required previously."
ai,"What Is the Cost Function?
",Statistics ,"Also referred to as “loss” or “error,” cost function is a measure to evaluate how good your model’s performance is. It’s used to compute the error of the output layer during backpropagation. We push that error backwards through the neural network and use that during the different training functions.
"
ai,What Are Hyperparameters?,Statistics ,"With neural networks, you’re usually working with hyperparameters once the data is formatted correctly. A hyperparameter is a parameter whose value is set before the learning process begins. It determines how a network is trained and the structure of the network (such as the number of hidden units, the learning rate, epochs, etc.)."
ai,What Are the Different Layers on CNN?,Neural Network,"Convolutional Layer –  the layer that performs a convolutional operation, creating several smaller picture windows to go over the data.

ReLU Layer – it brings non-linearity to the network and converts all the negative pixels to zero. The output is a rectified feature map.

Pooling Layer – pooling is a down-sampling operation that reduces the dimensionality of the feature map.

Fully Connected Layer – this layer recognizes and classifies the objects in the image."
ai,"What Is Pooling on CNN, and How Does It Work?",Neural Network,Pooling is used to reduce the spatial dimensions of a CNN. It performs down-sampling operations to reduce the dimensionality and creates a pooled feature map by sliding a filter matrix over the input matrix.
ai,What are Recurrent Neural Networks(RNNs)?,Neural Network,"RNNs are a type of artificial neural networks designed to recognise the pattern from the sequence of data such as Time series, stock market and government agencies etc. To understand recurrent nets, first, you have to understand the basics of feedforward nets.

Both these networks RNN and feed-forward named after the way they channel information through a series of mathematical orations performed at the nodes of the network. One feeds information through straight(never touching the same node twice), while the other cycles it through a loop, and the latter are called recurrent.

Recurrent networks, on the other hand, take as their input, not just the current input example they see, but also the what they have perceived previously in time.

The decision a recurrent neural network reached at time t-1 affects the decision that it will reach one moment later at time t. So recurrent networks have two sources of input, the present and the recent past, which combine to determine how they respond to new data, much as we do in life.

The error they generate will return via backpropagation and be used to adjust their weights until error can’t go any lower. Remember, the purpose of recurrent nets is to accurately classify sequential input. We rely on the backpropagation of error and gradient descent to do so.

"
ai,How Does an LSTM Network Work?,Neural Network,"Long-Short-Term Memory (LSTM) is a special kind of recurrent neural network capable of learning long-term dependencies, remembering information for long periods as its default behaviour. There are three steps in an LSTM network:

Step 1: The network decides what to forget and what to remember.
Step 2: It selectively updates cell state values.
Step 3: The network decides what part of the current state makes it to the output."
ai,What Is a Multi-layer Perceptron(MLP)?,Neural Network,"As in Neural Networks, MLPs have an input layer, a hidden layer, and an output layer. It has the same structure as a single layer perceptron with one or more hidden layers. A single layer perceptron can classify only linear separable classes with binary output (0,1), but MLP can classify nonlinear classes.

Except for the input layer, each node in the other layers uses a nonlinear activation function. This means the input layers, the data coming in, and the activation function is based upon all nodes and weights being added together, producing the output. MLP uses a supervised learning method called “backpropagation.” In backpropagation, the neural network calculates the error with the help of cost function. It propagates this error backward from where it came (adjusts the weights to train the model more accurately)."
ai,Explain Gradient Descent.,Neural Network,"To Understand Gradient Descent, Let’s understand what is a Gradient first.

A gradient measures how much the output of a function changes if you change the inputs a little bit. It simply measures the change in all weights with regard to the change in error. You can also think of a gradient as the slope of a function.

Gradient Descent can be thought of climbing down to the bottom of a valley, instead of climbing up a hill.  This is because it is a minimization algorithm that minimizes a given function (Activation Function)."
ai,What is exploding gradients?,Neural Network,"While training an RNN, if you see exponentially growing (very large) error gradients which accumulate and result in very large updates to neural network model weights during training, they’re known as exploding gradients. At an extreme, the values of weights can become so large as to overflow and result in NaN values.

This has the effect of your model is unstable and unable to learn from your training data."
ai,What is vanishing gradients?,Neural Network,"While training an RNN, your slope can become either too small; this makes the training difficult. When the slope is too small, the problem is known as a Vanishing Gradient. It leads to long training times, poor performance, and low accuracy."
ai,What is Back Propagation and Explain it’s Working.,Neural Network,"Backpropagation is a training algorithm used for multilayer neural network. In this method, we move the error from an end of the network to all weights inside the network and thus allowing efficient computation of the gradient.

It has the following steps:

Forward Propagation of Training Data

Derivatives are computed using output and target

Back Propagate for computing derivative of error wrt output activation

Using previously calculated derivatives for output

Update the Weights"
ai,What are the variants of Back Propagation?,Neural Network,"Stochastic Gradient Descent: We use only a single training example for calculation of gradient and update parameters.

Batch Gradient Descent: We calculate the gradient for the whole dataset and perform the update at each iteration.

Mini-batch Gradient Descent: It’s one of the most popular optimization algorithms. It’s a variant of Stochastic Gradient Descent and here instead of single training example, mini-batch of samples is used."
ai,What is an Auto-Encoder? ,Neural Network,"Auto-encoders are simple learning networks that aim to transform inputs into outputs with the minimum possible error. This means that we want the output to be as close to input as possible. We add a couple of layers between the input and the output, and the sizes of these layers are smaller than the input layer. The auto-encoder receives unlabelled input which is then encoded to reconstruct the input."
ai,What Is Dropout and Batch Normalization?,Neural Network,"Dropout is a technique of dropping out hidden and visible units of a network randomly to prevent overfitting of data (typically dropping 20 per cent of the nodes). It doubles the number of iterations needed to converge the network.

Batch normalization is the technique to improve the performance and stability of neural networks by normalizing the inputs in every layer so that they have mean output activation of zero and standard deviation of one."
ai,What Do You Mean by Tensor in Tensorflow?,Neural Network,A tensor is a mathematical object represented as arrays of higher dimensions. These arrays of data with different dimensions and ranks fed as input to the neural network are called “Tensors.”
ai,What is the Central Limit Theorem and why is it important?,Statistics ,"Suppose that we are interested in estimating the average height among all people. Collecting data for every person in the world is impossible. While we can’t obtain a height measurement from everyone in the population, we can still sample some people. The question now becomes, what can we say about the average height of the entire population given a single sample. The Central Limit Theorem addresses this question exactly"
ai,What are the assumptions required for linear regression?,Linear Regression,"There are four major assumptions: 1. There is a linear relationship between the dependent variables and the regressors, meaning the model you are creating actually fits the data, 2. The errors or residuals of the data are normally distributed and independent from each other, 3. There is minimal multicollinearity between explanatory variables, and 4. Homoscedasticity. This means the variance around the regression line is the same for all values of the predictor variable."
ai,"Explain the 80/20 rule, and tell me about its importance in model validation.",EDA,People usually tend to start with a 80-20% split (80% training set – 20% test set) and split the training set once more into a 80-20% ratio to create the validation set.
ai,"Would you use batch normalization? If so, can you explain why?",Neural Network,"The idea here is to standardize the data before sending it to another layer. This approach helps reduce the impact of previous layers by keeping the mean and variance constant. It also makes the layers independent of each other to achieve rapid convergence. For example, when we normalize features from 0 to 1 or from 1 to 100, it helps accelerate the learning cycle."
ai,How would you go about choosing an algorithm to solve a business problem?,EDA,"First, you have to develop a “problem statement” that’s based on the problem provided by the business. This step is essential because it’ll help ensure that you fully understand the type of problem and the input and the output of the problem you want to solve.

The problem statement should be simple and no more than a single sentence. For example, let’s consider enterprise spam that requires an algorithm to identify it.

The problem statement would be: “Is the email fake/spam or not?” In this scenario, the identification of whether it’s fake/spam will be the output.

Once you have defined the problem statement, you have to identify the appropriate algorithm from the following:

Any classification algorithm
Any clustering algorithm
Any regression algorithm
Any recommendation algorithm
Which algorithm you use will depend on the specific problem you’re trying to solve. In this scenario, you can move forward with a clustering algorithm and choose a k-means algorithm to achieve your goal of filtering spam from the email system.

While examples aren’t always necessary when answering questions about artificial intelligence, sometimes it will help make it easier for you to get your point across."
ai,"What’s the difference between inductive, deductive, and abductive learning?",Methodology,"Inductive learning describes smart algorithms that learn from a set of instances to draw conclusions. In statistical ML, k-nearest neighbor and support vector machine are good examples of inductive learning.

There are three literals in (top-down) inductive learning:

Arithmetic literals
Equality and inequality
Predicates
In deductive learning, the smart algorithms draw conclusions by following a truth-generating structure (major premise, minor premise, and conclusion) and then improve them based on previous decisions. In this scenario, the ML algorithm engages in deductive reasoning using a decision tree.

Abductive learning is a DL technique where conclusions are made based on various instances. With this approach, inductive reasoning is applied to causal relationships in deep neural networks."
ai,What steps would you take to evaluate the effectiveness of your ML model?,Methodology,"You have to first split the data set into training and test sets. You also have the option of using a cross-validation technique to further segment the data set into a composite of training and test sets within the data.

Then you have to implement a choice selection of the performance metrics like the following:

Confusion matrix
Accuracy
Precision
Recall or sensitivity
Specificity
F1 score
For the most part, you can use measures such as accuracy, confusion matrix, or F1 score. However, it’ll be critical for you to demonstrate that you understand the nuances of how each model can be measured by choosing the right performance measure to match the problem."
ai,What is Bayes’ Theorem? How is it useful in a machine learning context?,Naive Bayes,"Bayes’ Theorem gives you the posterior probability of an event given what is known as prior knowledge.

Mathematically, it’s expressed as the true positive rate of a condition sample divided by the sum of the false positive rate of the population and the true positive rate of a condition. Say you had a 60% chance of actually having the flu after a flu test, but out of people who had the flu, the test will be false 50% of the time, and the overall population only has a 5% chance of having the flu. Would you actually have a 60% chance of having the flu after having a positive test?

Bayes’ Theorem says no. It says that you have a (.6 * 0.05) (True Positive Rate of a Condition Sample) / (.6*0.05)(True Positive Rate of a Condition Sample) + (.5*0.95) (False Positive Rate of a Population)  = 0.0594 or 5.94% chance of getting a flu.

Bayes’ Theorem is the basis behind a branch of machine learning that most notably includes the Naive Bayes classifier. That’s something important to consider when you’re faced with machine learning interview questions."
ai,Why is “Naive” Bayes naive?,Naive Bayes,"Despite its practical applications, especially in text mining, Naive Bayes is considered “Naive” because it makes an assumption that is virtually impossible to see in real-life data: the conditional probability is calculated as the pure product of the individual probabilities of components. This implies the absolute independence of features — a condition probably never met in real life.

As a Quora commenter put it whimsically, a Naive Bayes classifier that figured out that you liked pickles and ice cream would probably naively recommend you a pickle ice cream."
ai,Explain the difference between L1 and L2 regularization.,Linear Regression,"L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting. L1 corresponds to setting a Laplacean prior on the terms, while L2 corresponds to a Gaussian prior."
ai,What’s a Fourier transform?,Statistics ,"A Fourier transform is a generic method to decompose generic functions into a superposition of symmetric functions. Or as this more intuitive tutorial puts it, given a smoothie, it’s how we find the recipe. The Fourier transform finds the set of cycle speeds, amplitudes, and phases to match any time signal. A Fourier transform converts a signal from time to frequency domain—it’s a very common way to extract features from audio signals or other time series such as sensor data."
ai,"What is deep learning, and how does it contrast with other machine learning algorithms?",Methodology,"Deep learning is a subset of machine learning that is concerned with neural networks: how to use backpropagation and certain principles from neuroscience to more accurately model large sets of unlabelled or semi-structured data. In that sense, deep learning represents an unsupervised learning algorithm that learns representations of data through the use of neural nets."
ai,What’s the difference between a generative and discriminative model?,Methodology,A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.
ai,What’s the F1 score? How would you use it?,Statistics ,"The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much."
ai,When should you use classification over regression?,Methodology,"Classification produces discrete values and dataset to strict categories, while regression gives you continuous results that allow you to better distinguish differences between individual points. You would use classification over regression if you wanted your results to reflect the belongingness of data points in your dataset to certain explicit categories."
ai,What’s the “kernel trick” and how is it useful?,Methodology,"The Kernel trick involves kernel functions that can enable in higher-dimension spaces without explicitly calculating the coordinates of points within that dimension: instead, kernel functions compute the inner products between the images of all pairs of data in a feature space. This allows them the very useful attribute of calculating the coordinates of higher dimensions while being computationally cheaper than the explicit calculation of said coordinates. Many algorithms can be expressed in terms of inner products. Using the kernel trick enables us effectively run algorithms in a high-dimensional space with lower-dimensional data."
ai,Do you have experience with Spark or big data tools for machine learning?,Methodology,"You’ll want to get familiar with the meaning of big data for different companies and the different tools they’ll want. Spark is the big data tool most in demand now, able to handle immense datasets with speed. Be honest if you don’t have experience with the tools demanded, but also take a look at job descriptions and see what tools pop up: you’ll want to invest in familiarizing yourself with them."
ai,How would you build a data pipeline?,Methodology,"Data pipelines are the bread and butter of machine learning engineers, who take data science models and find ways to automate and scale them. Make sure you’re familiar with the tools to build data pipelines (such as Apache Airflow) and the platforms where you can host models and pipelines (such as Google Cloud or AWS or Azure). Explain the steps required in a functioning data pipeline and talk through your actual experience building and scaling them in production. "
ai,Is more data always better?,EDA,"Statistically,
It depends on the quality of your data, for example, if your data is biased, just getting more data won’t help.
It depends on your model. If your model suffers from high bias, getting more data won’t improve your test results beyond a point. You’d need to add more features, etc.

Practically,
Also there’s a tradeoff between having more data and the additional storage, computational power, memory it requires. Hence, always think about the cost of having more data."
ai,"How can you make sure that you don’t analyze something that ends up meaningless?
",EDA,"Proper exploratory data analysis.
In every data analysis task, there's the exploratory phase where you're just graphing things, testing things on small sets of the data, summarizing simple statistics, and getting rough ideas of what hypotheses you might want to pursue further.

Then there's the exploitatory phase, where you look deeply into a set of hypotheses. 

The exploratory phase will generate lots of possible hypotheses, and the exploitatory phase will let you really understand a few of them. Balance the two and you'll prevent yourself from wasting time on many things that end up meaningless, although not all."
ai,How can you determine which features are the most important in your model?,EDA,"Run the features though a Gradient Boosting Machine or Random Forest to generate plots of relative importance and information gain for each feature in the ensembles.

Look at the variables added in forward variable selection "
ai,What are some ways I can make my model more robust to outliers?,Methodology,"We can have regularization such as L1 or L2 to reduce variance (increase bias).

Changes to the algorithm:
Use tree-based methods instead of regression methods as they are more resistant to outliers. For statistical tests, use non parametric tests instead of parametric ones.
Use robust error metrics such as MAE or Huber Loss instead of MSE.

Changes to the data:
Winsorizing the data
Transforming the data (e.g. log)
Remove them only if you’re certain they’re anomalies not worth predicting"
ai,"What are some differences you would expect in a model that minimizes squared error, versus a model that minimizes absolute error? In which cases would each error metric be appropriate?",Methodology,"MSE is more strict to having outliers. MAE is more robust in that sense, but is harder to fit the model for because it cannot be numerically optimized. So when there are less variability in the model and the model is computationally easy to fit, we should use MAE, and if that’s not the case, we should use MSE.
MSE: easier to compute the gradient, MAE: linear programming needed to compute the gradient
MAE more robust to outliers. If the consequences of large errors are great, use MSE
MSE corresponds to maximizing likelihood of Gaussian random variables"
ai,What error metric would you use to evaluate how good a binary classifier is? What if the classes are imbalanced? What if there are more than 2 groups?,Methodology,"Accuracy: proportion of instances you predict correctly. Pros: intuitive, easy to explain, Cons: works poorly when the class labels are imbalanced and the signal from the data is weak
AUROC: plot fpr on the x axis and tpr on the y axis for different threshold. Given a random positive instance and a random negative instance, the AUC is the probability that you can identify who's who. Pros: Works well when testing the ability of distinguishing the two classes, Cons: can’t interpret predictions as probabilities (because AUC is determined by rankings), so can’t explain the uncertainty of the model
logloss/deviance: Pros: error metric based on probabilities, Cons: very sensitive to false positives, negatives
When there are more than 2 groups, we can have k binary classifications and add them up for logloss. Some metrics like AUC is only applicable in the binary case."
ai,"What are various ways to predict a binary response variable? Can you compare two of them and tell me when one would be more appropriate? What’s the difference between these? (SVM, Logistic Regression, Naive Bayes, Decision Tree, etc.)",Methodology,"Things to look at: N, P, linearly seperable?, features independent?, likely to overfit?, speed, performance, memory usage
Logistic Regression
features roughly linear, problem roughly linearly separable
robust to noise, use l1,l2 regularization for model selection, avoid overfitting
the output come as probabilities
efficient and the computation can be distributed
can be used as a baseline for other algorithms
(-) can hardly handle categorical features
SVM
with a nonlinear kernel, can deal with problems that are not linearly separable
(-) slow to train, for most industry scale applications, not really efficient
Naive Bayes
computationally efficient when P is large by alleviating the curse of dimensionality
works surprisingly well for some cases even if the condition doesn’t hold
with word frequencies as features, the independence assumption can be seen reasonable. So the algorithm can be used in text categorization
(-) conditional independence of every other feature should be met
Tree Ensembles
good for large N and large P, can deal with categorical features very well
non parametric, so no need to worry about outliers
GBT’s work better but the parameters are harder to tune
RF works out of the box, but usually performs worse than GBT
Deep Learning
works well for some classification tasks (e.g. image)
used to squeeze something out of the problem"
ai,"Given training data on tweets and their retweets, how would you predict the number of retweets of a given tweet after 7 days after only observing 2 days worth of data?",Methodology,"Build a time series model with the training data with a seven day cycle and then use that for a new data with only 2 days data.
Ask someone for more details.
Build a regression function to estimate the number of retweets as a function of time t
to determine if one regression function can be built, see if there are clusters in terms of the trends in the number of retweets
if not, we have to add features to the regression function
features + # of retweets on the first and the second day -> predict the seventh day"
ai,"In an A/B test, how can you check if assignment to the various buckets was truly random?",Methodology,"Plot the distributions of multiple features for both A and B and make sure that they have the same shape. More rigorously, we can conduct a permutation test to see if the distributions are the same.
MANOVA to compare different means"
ai,"What might be the benefits of running an A/A test, where you have two buckets who are exposed to the exact same product?",Methodology,Verify the sampling algorithm is random.
ai,What would be the hazards of letting users sneak a peek at the other bucket in an A/B test?,Methodology,"The user might not act the same suppose had they not seen the other bucket. You are essentially adding additional variables of whether the user peeked the other bucket, which are not random across groups."
ai,"How would you run an A/B test for many variants, say 20 or more?",Methodology,"one control, 20 treatment, if the sample size for each group is big enough.
Ways to attempt to correct for this include changing your confidence level (e.g. Bonferroni Correction) or doing family-wide tests before you dive in to the individual metrics (e.g. Fisher's Protected LSD)."
ai,How would you run an A/B test if the observations are extremely right-skewed?,Methodology,"lower the variability by modifying the KPI
cap values
percentile metrics
log transform"
ai,What is a p-value? What is the difference between type-1 and type-2 error?,Statistics ,"A p-value is defined such that under the null hypothesis less than the fraction p of events have parameter values more extreme than the observed parameter. It is not the probability that the null hypothesis is wrong.
type-1 error: rejecting Ho when Ho is true
type-2 error: not rejecting Ho when Ha is true"
ai,You are AirBnB and you want to test the hypothesis that a greater number of photographs increases the chances that a buyer selects the listing. How would you test this hypothesis?,Statistics ,"For randomly selected listings with more than 1 pictures, hide 1 random picture for group A, and show all for group B. Compare the booking rate for the two groups."
ai,How would you design an experiment to determine the impact of latency on user engagement?,Statistics ,"The best way I know to quantify the impact of performance is to isolate just that factor using a slowdown experiment, i.e., add a delay in an A/B test."
ai,What is maximum likelihood estimation? Could there be any case where it doesn’t exist?,Statistics ,"A method for parameter optimization (fitting a model). We choose parameters so as to maximize the likelihood function (how likely the outcome would happen given the current data and our model).
maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.
for gaussian mixtures, non parametric models, it doesn’t exist."
ai,What is a confidence interval and how do you interpret it?,Statistics ,"For example, 95% confidence interval is an interval that when constructed for a set of samples each sampled in the same way, the constructed intervals include the true mean 95% of the time.
if confidence intervals are constructed using a given confidence level in an infinite number of independent experiments, the proportion of those intervals that contain the true value of the parameter will match the confidence level."
ai,What is Selection Bias?,Statistics ,"Selection bias is a kind of error that occurs when the researcher decides who is going to be studied. It is usually associated with research where the selection of participants isn’t random. It is sometimes referred to as the selection effect. It is the distortion of statistical analysis, resulting from the method of collecting samples. If the selection bias is not taken into account, then some conclusions of the study may not be accurate.
The types of selection bias include:
Sampling bias: It is a systematic error due to a non-random sample of a population causing some members of the population to be less likely to be included than others resulting in a biased sample.
Time Interval bias: A trial may be terminated early at an extreme value (often for ethical reasons), but the extreme value is likely to be reached by the variable with the largest variance, even if all variables have a similar mean.
Data: When specific subsets of data are chosen to support a conclusion or rejection of bad data on arbitrary grounds, instead of according to previously stated or generally agreed criteria.
Attrition: Attrition bias is a kind of selection bias caused by attrition (loss of participants) discounting trial subjects/tests that did not run to completion."
ai,What is regression? Which models can you use to solve a regression problem?,Methodology,"Regression is a part of supervised ML. Regression models investigate the relationship between a dependent (target) and independent variable (s) (predictor). Here are some common regression models

Linear Regression establishes a linear relationship between target and predictor (s). It predicts a numeric value and has a shape of a straight line.
Polynomial Regression has a regression equation with the power of independent variable more than 1. It is a curve that fits into the data points.
Ridge Regression helps when predictors are highly correlated (multicollinearity problem). It penalizes the squares of regression coefficients but doesn’t allow the coefficients to reach zeros (uses L2 regularization).
Lasso Regression penalizes the absolute values of regression coefficients and allows some of the coefficients to reach absolute zero (thereby allowing feature selection)."
ai,What are the main assumptions of linear regression?,Linear Regression,"There are several assumptions of linear regression. If any of them is violated, model predictions and interpretation may be worthless or misleading.

Linear relationship between features and target variable.
Additivity means that the effect of changes in one of the features on the target variable does not depend on values of other features. For example, a model for predicting revenue of a company have of two features - the number of items a sold and the number of items b sold. When company sells more items a the revenue increases and this is independent of the number of items b sold. But, if customers who buy a stop buying b, the additivity assumption is violated.
Features are not correlated (no collinearity) since it can be difficult to separate out the individual effects of collinear features on the target variable.
Errors are independently and identically normally distributed (yi = B0 + B1*x1i + ... + errori):
No correlation between errors (consecutive errors in the case of time series data).
Constant variance of errors - homoscedasticity. For example, in case of time series, seasonal patterns can increase errors in seasons with higher activity.
Errors are normaly distributed, otherwise some features will have more influence on the target variable than to others. If the error distribution is significantly non-normal, confidence intervals may be too wide or too narrow."
ai,What’s the normal distribution? Why do we care about it?,Statistics ,"The normal distribution derives its importance from the Central Limit Theorem, which states that if we draw a large enough number of samples, their mean will follow a normal distribution regardless of the initial distribution of the sample, i.e the distribution of the mean of the samples is normal. It is important that each sample is independent from the other.

This is powerful because it helps us study processes whose population distribution is unknown to us."
ai,How do we check if a variable follows the normal distribution?,Statistics ,"Plot a histogram out of the sampled data. If you can fit the bell-shaped ""normal"" curve to the histogram, then the hypothesis that the underlying random variable follows the normal distribution can not be rejected.
Check Skewness and Kurtosis of the sampled data. Skewness = 0 and kurtosis = 3 are typical for a normal distribution, so the farther away they are from these values, the more non-normal the distribution.
Use Kolmogorov-Smirnov or/and Shapiro-Wilk tests for normality. They take into account both Skewness and Kurtosis simultaneously.
Check for Quantile-Quantile plot. It is a scatterplot created by plotting two sets of quantiles against one another. Normal Q-Q plot place the data points in a roughly straight line."
ai,What if we want to build a model for predicting prices? Are prices distributed normally? Do we need to do any pre-processing for prices?,Methodology,"Data is not normal. Specially, real-world datasets or uncleaned datasets always have certain skewness. Same goes for the price prediction. Price of houses or any other thing under consideration depends on a number of factors. So, there's a great chance of presence of some skewed values i.e outliers if we talk in data science terms.

Yes, you may need to do pre-processing. Most probably, you will need to remove the outliers to make your distribution near-to-normal."
ai,What methods for solving linear regression do you know?,Linear Regression,"To solve linear regression, you need to find the coefficients  which minimize the sum of squared errors.

Matrix Algebra method: Let's say you have X, a matrix of features, and y, a vector with the values you want to predict. After going through the matrix algebra and minimization problem, you get this solution: .

But solving this requires you to find an inverse, which can be time-consuming, if not impossible. Luckily, there are methods like Singular Value Decomposition (SVD) or QR Decomposition that can reliably calculate this part  (called the pseudo-inverse) without actually needing to find an inverse. The popular python ML library sklearn uses SVD to solve least squares."
ai,What is gradient descent? How does it work?,Neural Network,"Gradient descent is an algorithm that uses calculus concept of gradient to try and reach local or global minima. It works by taking the negative of the gradient in a point of a given function, and updating that point repeatedly using the calculated negative gradient, until the algorithm reaches a local or global minimum, which will cause future iterations of the algorithm to return values that are equal or too close to the current point. It is widely used in machine learning applications."
ai,What is the normal equation?,Statistics ,Normal equations are equations obtained by setting equal to zero the partial derivatives of the sum of squared errors (least squares); normal equations allow one to estimate the parameters of a multiple linear regression.
ai,What is SGD  —  stochastic gradient descent? What’s the difference with the usual gradient descent?,Methodology,"In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function.

While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET of training sample from your training set to do the update for a parameter in a particular iteration. If you use SUBSET, it is called Minibatch Stochastic gradient Descent.
"
ai,Which metrics for evaluating regression models do you know?,Methodology,"Mean Squared Error(MSE)
Root Mean Squared Error(RMSE)
Mean Absolute Error(MAE)
R² or Coefficient of Determination
Adjusted R²"
ai,What are MSE and RMSE?,Statistics ,MSE stands for Mean Square Error while RMSE stands for Root Mean Square Error. They are metrics with which we can evaluate models.
ai,What is the bias-variance trade-off?,Statistics ,"Bias is the error introduced by approximating the true underlying function, which can be quite complex, by a simpler model. Variance is a model sensitivity to changes in the training dataset.

Bias-variance trade-off is a relationship between the expected test error and the variance and the bias - both contribute to the level of the test error and ideally should be as small as possible:

ExpectedTestError = Variance + Bias² + IrreducibleError
But as a model complexity increases, the bias decreases and the variance increases which leads to overfitting. And vice versa, model simplification helps to decrease the variance but it increases the bias which leads to underfitting."
ai,What is K-fold cross-validation? ,Methodology,"K fold cross validation is a method of cross validation where we select a hyperparameter k. The dataset is now divided into k parts. Now, we take the 1st part as validation set and remaining k-1 as training set. Then we take the 2nd part as validation set and remaining k-1 parts as training set. Like this, each part is used as validation set once and the remaining k-1 parts are taken together and used as training set. It should not be used in a time series data."
ai,How do we choose K in K-fold cross-validation? What’s your favorite K?,Methodology,"There are two things to consider while deciding K: the number of models we get and the size of validation set. We do not want the number of models to be too less, like 2 or 3. At least 4 models give a less biased decision on the metrics. On the other hand, we would want the dataset to be at least 20-25% of the entire data. So that at least a ratio of 3:1 between training and validation set is maintained.
I tend to use 4 for small datasets and 5 for large ones as K."
ai,Is logistic regression a linear model? Why?,Logistic Regression,"Yes, Logistic Regression is considered a generalized linear model because the outcome always depends on the sum of the inputs and parameters. Or in other words, the output cannot depend on the product (or quotient, etc.) of its parameters."
ai,What is logistic regression? When do we need to use it?,Logistic Regression,"Logistic regression is a Machine Learning algorithm that is used for binary classification. You should use logistic regression when your Y variable takes only two values, e.g. True and False, ""spam"" and ""not spam"", ""churn"" and ""not churn"" and so on. The variable is said to be a ""binary"" or ""dichotomous"".
"
ai,What is sigmoid? What does it do?,Neural Network,"A sigmoid function is a type of activation function, and more specifically defined as a squashing function. Squashing functions limit the output to a range between 0 and 1, making these functions useful in the prediction of probabilities.

Sigmod(x) = 1/(1+e^{-x})"
ai,Precision-recall trade-off,Statistics ,"Tradeoff means increasing one parameter would lead to decreasing of other. Precision-recall tradeoff occur due to increasing one of the parameter(precision or recall) while keeping the model same.

In an ideal scenario where there is a perfectly separable data, both precision and recall can get maximum value of 1.0. But in most of the practical situations, there is noise in the dataset and the dataset is not perfectly separable. There might be some points of positive class closer to the negative class and vice versa. In such cases, shifting the decision boundary can either increase the precision or recall but not both. Increasing one parameter leads to decreasing of the other."
ai,What is the ROC curve? When to use it?,Statistics ,ROC stands for Receiver Operating Characteristics. The diagrammatic representation that shows the contrast between true positive rate vs false positive rate. It is used when we need to predict the probability of the binary outcome.
ai,What is AUC (AU ROC)? When to use it?,Statistics ,"AUC stands for Area Under the ROC Curve. ROC is a probability curve and AUC represents degree or measure of separability. It's used when we need to value how much model is capable of distinguishing between classes. The value is between 0 and 1, the higher the better."
ai,How to interpret the AU ROC score?,Statistics ,"AUC score is the value of Area Under the ROC Curve.

An excellent model has AUC near to the 1 which means it has good measure of separability. A poor model has AUC near to the 0 which means it has worst measure of separability. When AUC score is 0.5, it means model has no class separation capacity whatsoever."
ai,What is the PR (precision-recall) curve?,Statistics ,A precision-recall curve (or PR Curve) is a plot of the precision (y-axis) and the recall (x-axis) for different probability thresholds. Precision-recall curves (PR curves) are recommended for highly skewed domains where ROC curves may provide an excessively optimistic view of the performance.
ai,What is the area under the PR curve? Is it a useful metric?,Statistics ,"The Precision-Recall AUC is just like the ROC AUC, in that it summarizes the curve with a range of threshold values as a single score.

A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate."
ai,In which cases AU PR is better than AU ROC?,Statistics ,"What is different however is that AU ROC looks at a true positive rate TPR and false positive rate FPR while AU PR looks at positive predictive value PPV and true positive rate TPR.

Typically, if true negatives are not meaningful to the problem or you care more about the positive class, AU PR is typically going to be more useful; otherwise, If you care equally about the positive and negative class or your dataset is quite balanced, then going with AU ROC is a good idea."
ai,What do we do with categorical variables?,EDA,"Categorical variables must be encoded before they can be used as features to train a machine learning model. There are various encoding techniques, including:

One-hot encoding
Label encoding
Ordinal encoding
Target encoding"
ai,What kind of regularization techniques are applicable to linear models?,Linear Regression,"AIC/BIC, Ridge regression, Lasso, Elastic Net, Basis pursuit denoising, Rudin–Osher–Fatemi model (TV), Potts model, RLAD, Dantzig Selector,SLOPE"
ai,What’s the effect of L2 regularization on the weights of a linear model?,Linear Regression,"L2 regularization penalizes larger weights more severely (due to the squared penalty term), which encourages weight values to decay toward zero."
ai,How L1 regularization looks like in a linear model?,Linear Regression,L1 regularization adds a penalty term to our cost function which is equal to the sum of modules of models coefficients multiplied by a lambda hyperparameter.
ai,What’s the difference between L2 and L1 regularization?,Linear Regression,"Penalty terms: L1 regularization uses the sum of the absolute values of the weights, while L2 regularization uses the sum of the weights squared.
Feature selection: L1 performs feature selection by reducing the coefficients of some predictors to 0, while L2 does not.
Computational efficiency: L2 has an analytical solution, while L1 does not.
Multicollinearity: L2 addresses multicollinearity by constraining the coefficient norm."
ai,Can we have both L1 and L2 regularization components in a linear model?,Linear Regression,"Yes, elastic net regularization combines L1 and L2 regularization."
ai,What’s the interpretation of the bias term in linear models?,Linear Regression,"Bias is simply, a difference between predicted value and actual/true value. It can be interpreted as the distance from the average prediction and true value i.e. true value minus mean(predictions). But dont get confused between accuracy and bias."
ai,How do we interpret weights in linear models?,Linear Regression,"Without normalizing weights or variables, if you increase the corresponding predictor by one unit, the coefficient represents on average how much the output changes. By the way, this interpretation still works for logistic regression - if you increase the corresponding predictor by one unit, the weight represents the change in the log of the odds.

If the variables are normalized, we can interpret weights in linear models like the importance of this variable in the predicted result."
ai,If a weight for one variable is higher than for another  —  can we say that this variable is more important?,Linear Regression,"Yes - if your predictor variables are normalized.

Without normalization, the weight represents the change in the output per unit change in the predictor. If you have a predictor with a huge range and scale that is used to predict an output with a very small range - for example, using each nation's GDP to predict maternal mortality rates - your coefficient should be very small. That does not necessarily mean that this predictor variable is not important compared to the others."
ai,When do we need to perform feature normalization for linear models? When it’s okay not to do it?,Linear Regression,"Feature normalization is necessary for L1 and L2 regularizations. The idea of both methods is to penalize all the features relatively equally. This can't be done effectively if every feature is scaled differently.

Linear regression without regularization techniques can be used without feature normalization. Also, regularization can help to make the analytical solution more stable, — it adds the regularization matrix to the feature matrix before inverting it."
ai,Which feature selection techniques do you know?,EDA,"Here are some of the feature selections:

Principal Component Analysis
Neighborhood Component Analysis
ReliefF Algorithm"
ai,Can we use L1 regularization for feature selection?,EDA,"Yes, because the nature of L1 regularization will lead to sparse coefficients of features. Feature selection can be done by keeping only features with non-zero coefficients."
ai,What are the benefits of a single decision tree compared to more complex models?,Decision Trees,"easy to implement
fast training
fast inference
good explainability"
ai,How can we know which features are more important for the decision tree model?,Decision Trees,"Often, we want to find a split such that it minimizes the sum of the node impurities. The impurity criterion is a parameter of decision trees. Popular methods to measure the impurity are the Gini impurity and the entropy describing the information gain."
ai,Why do we need randomization in random forest?,Random Forest,"Random forest in an extention of the bagging algorithm which takes random data samples from the training dataset (with replacement), trains several models and averages predictions. In addition to that, each time a split in a tree is considered, random forest takes a random sample of m features from full set of n features (with replacement) and uses this subset of features as candidates for the split (for example, m = sqrt(n)).

Training decision trees on random data samples from the training dataset reduces variance. Sampling features for each split in a decision tree decorrelates trees."
ai,How do we select the depth of the trees in random forest?,Random Forest,"The greater the depth, the greater amount of information is extracted from the tree, however, there is a limit to this, and the algorithm even if defensive against overfitting may learn complex features of noise present in data and as a result, may overfit on noise. Hence, there is no hard thumb rule in deciding the depth, but literature suggests a few tips on tuning the depth of the tree to prevent overfitting:

limit the maximum depth of a tree
limit the number of test nodes
limit the minimum number of objects at a node required to split
do not split a node when, at least, one of the resulting subsample sizes is below a given threshold
stop developing a node if it does not sufficiently improve the fit."
ai,How do we know how many trees we need in random forest?,Random Forest,"The number of trees in random forest is worked by n_estimators, and a random forest reduces overfitting by increasing the number of trees. There is no fixed thumb rule to decide the number of trees in a random forest, it is rather fine tuned with the data, typically starting off by taking the square of the number of features (n) present in the data followed by tuning until we get the optimal results."
ai,What happens when we have correlated features in our data?,EDA,"In random forest, since random forest samples some features to build each tree, the information contained in correlated features is twice as much likely to be picked than any other information contained in other features.

In general, when you are adding correlated features, it means that they linearly contains the same information and thus it will reduce the robustness of your model. Each time you train your model, your model might pick one feature or the other to ""do the same job"" i.e. explain some variance, reduce entropy, etc.
"
ai,What is gradient boosting trees?,Gradient Boosting,"Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees."
ai,What’s the difference between random forest and gradient boosting?,"Random Forest, Gradient Boosting","Random Forests builds each tree independently while Gradient Boosting builds one tree at a time.
Random Forests combine results at the end of the process (by averaging or ""majority rules"") while Gradient Boosting combines results along the way."
ai,Is it possible to parallelize training of a gradient boosting model? How to do it?,Gradient Boosting,"Yes, different frameworks provide different options to make training faster, using GPUs to speed up the process by making it highly parallelizable.For example, for XGBoost tree_method = 'gpu_hist' option makes training faster by use of GPUs."
ai,How do you approach tuning parameters in XGBoost or LightGBM?,"XGBoost, Gradient Boosting","Depending upon the dataset, parameter tuning can be done manually or using hyperparameter optimization frameworks such as optuna and hyperopt. In manual parameter tuning, we need to be aware of max-depth, min_samples_leaf and min_samples_split so that our model does not overfit the data but try to predict generalized characteristics of data (basically keeping variance and bias low for our model)."
ai,How do you select the number of trees in the gradient boosting model?,Gradient Boosting,"Most implementations of gradient boosting are configured by default with a relatively small number of trees, such as hundreds or thousands. Using scikit-learn we can perform a grid search of the n_estimators model parameter"
ai,Which hyper-parameter tuning strategies (in general) do you know? What’s the difference between grid search parameter tuning strategy and random search? When to use one or another?,Methodology,"There are several strategies for hyper-tuning but I would argue that the three most popular nowadays are the following:

Grid Search is an exhaustive approach such that for each hyper-parameter, the user needs to manually give a list of values for the algorithm to try. After these values are selected, grid search then evaluates the algorithm using each and every combination of hyper-parameters and returns the combination that gives the optimal result (i.e. lowest MAE). Because grid search evaluates the given algorithm using all combinations, it's easy to see that this can be quite computationally expensive and can lead to sub-optimal results specifically since the user needs to specify specific values for these hyper-parameters, which is prone for error and requires domain knowledge.

Random Search is similar to grid search but differs in the sense that rather than specifying which values to try for each hyper-parameter, an upper and lower bound of values for each hyper-parameter is given instead. With uniform probability, random values within these bounds are then chosen and similarly, the best combination is returned to the user. Although this seems less intuitive, no domain knowledge is necessary and theoretically much more of the parameter space can be explored.

In a completely different framework, Bayesian Optimization is thought of as a more statistical way of optimization and is commonly used when using neural networks, specifically since one evaluation of a neural network can be computationally costly. In numerous research papers, this method heavily outperforms Grid Search and Random Search and is currently used on the Google Cloud Platform as well as AWS. Because an in-depth explanation requires a heavy background in bayesian statistics and gaussian processes (and maybe even some game theory), a ""simple"" explanation is that a much simpler/faster acquisition function intelligently chooses (using a surrogate function such as probability of improvement or GP-UCB) which hyper-parameter values to try on the computationally expensive, original algorithm. Using the result of the initial combination of values on the expensive/original function, the acquisition function takes the result of the expensive/original algorithm into account and uses it as its prior knowledge to again come up with another set of hyper-parameters to choose during the next iteration. This process continues either for a specified number of iterations or for a specified amount of time and similarly the combination of hyper-parameters that performs the best on the expensive/original algorithm is chosen.
"
ai,What kind of problems neural nets can solve?,Neural Network,"Neural nets are good at solving non-linear problems. Some good examples are problems that are relatively easy for humans (because of experience, intuition, understanding, etc), but difficult for traditional regression models: speech recognition, handwriting recognition, image identification, etc."
ai,How does a usual fully-connected feed-forward neural network work?,Neural Network,"In a usual fully-connected feed-forward network, each neuron receives input from every element of the previous layer and thus the receptive field of a neuron is the entire previous layer. They are usually used to represent feature vectors for input data in classification problems but can be expensive to train because of the number of computations involved."
ai,Why do we need activation functions?,Neural Network,"The main idea of using neural networks is to learn complex nonlinear functions. If we are not using an activation function in between different layers of a neural network, we are just stacking up multiple linear layers one on top of another and this leads to learning a linear function. The Nonlinearity comes only with the activation function, this is the reason we need activation functions."
ai,What are the problems with sigmoid as an activation function?,Neural Network,The derivative of the sigmoid function for large positive or negative numbers is almost zero. From this comes the problem of vanishing gradient — during the backpropagation our net will not learn (or will learn drastically slow). One possible way to solve this problem is to use ReLU activation function.
ai,What is ReLU? How is it better than sigmoid or tanh?,Neural Network,"ReLU is an abbreviation for Rectified Linear Unit. It is an activation function which has the value 0 for all negative values and the value f(x) = x for all positive values. The ReLU has a simple activation function which makes it fast to compute and while the sigmoid and tanh activation functions saturate at higher values, the ReLU has a potentially infinite activation, which addresses the problem of vanishing gradients."
ai,How we can initialize the weights of a neural network?,Neural Network,"Proper initialization of weight matrix in neural network is very necessary. Simply we can say there are two ways for initializtions.

Initializing weights with zeroes. Setting weights to zero makes your network no better than a linear model. It is important to note that setting biases to 0 will not create any troubles as non zero weights take care of breaking the symmetry and even if bias is 0, the values in every neuron are still different.
Initializing weights randomly. Assigning random values to weights is better than just 0 assignment.
a) If weights are initialized with very high values the term np.dot(W,X)+b becomes significantly higher and if an activation function like sigmoid() is applied, the function maps its value near to 1 where the slope of gradient changes slowly and learning takes a lot of time.
b) If weights are initialized with low values it gets mapped to 0, where the case is the same as above. This problem is often referred to as the vanishing gradient."
ai,What if we set all the weights of a neural network to 0?,Neural Network,"If all the weights of a neural network are set to zero, the output of each connection is same (W*x = 0). This means the gradients which are backpropagated to each connection in a layer is same. This means all the connections/weights learn the same thing, and the model never converges."
ai,What regularization techniques for neural nets do you know?,Neural Network,"L1 Regularization - Defined as the sum of absolute values of the individual parameters. The L1 penalty causes a subset of the weights to become zero, suggesting that the corresponding features may safely be discarded.
L2 Regularization - Defined as the sum of square of individual parameters. Often supported by regularization hyperparameter alpha. It results in weight decay.
Data Augmentation - This requires some fake data to be created as a part of training set.
Drop Out : This is most effective regularization technique for newral nets. Few randome nodes in each layer is deactivated in forward pass. This allows the algorithm to train on different set of nodes in each iterations."
ai,What is dropout? Why is it useful? How does it work?,Neural Network,"Dropout is a technique that at each training step turns off each neuron with a certain probability of p. This way at each iteration we train only 1-p of neurons, which forces the network not to rely only on the subset of neurons for feature representation. This leads to regularizing effects that are controlled by the hyperparameter p.
"
ai,What is backpropagation? How does it work? Why do we need it?,Neural Network,"The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.

We need backpropogation because,

Calculate the error – How far is your model output from the actual output.
Minimum Error – Check whether the error is minimized or not.
Update the parameters – If the error is huge then, update the parameters (weights and biases). After that again check the error.
Repeat the process until the error becomes minimum.
Model is ready to make a prediction – Once the error becomes minimum, you can feed some inputs to your model and it will produce the output."
ai,Which optimization techniques for training neural nets do you know?,Neural Network,"Gradient Descent
Stochastic Gradient Descent
Mini-Batch Gradient Descent(best among gradient descents)
Nesterov Accelerated Gradient
Momentum
Adagrad
AdaDelta
Adam(best one. less time, more efficient)"
ai,How do we use SGD (stochastic gradient descent) for training a neural net?,Neural Network,"SGD approximates the expectation with few randomly selected samples (instead of the full data). In comparison to batch gradient descent, we can efficiently approximate the expectation in large data sets using SGD. For neural networks this reduces the training time a lot even considering that it will converge later as the random sampling adds noise to the gradient descent."
ai,What’s the learning rate?,Neural Network,"The learning rate is an important hyperparameter that controls how quickly the model is adapted to the problem during the training. It can be seen as the ""step width"" during the parameter updates, i.e. how far the weights are moved into the direction of the minimum of our optimization problem."
ai,How to set the learning rate?,Neural Network,There is no straightforward way of finding an optimum learning rate for a model. It involves a lot of hit and trial. Usually starting with a small values such as 0.01 is a good starting point for setting a learning rate and further tweaking it so that it doesn't overshoot or converge too slowly.
ai,What is Adam? What’s the main difference between Adam and SGD?,Neural Network,"Adam (Adaptive Moment Estimation) is a optimization technique for training neural networks. on an average, it is the best optimizer .It works with momentums of first and second order. The intuition behind the Adam is that we don’t want to roll so fast just because we can jump over the minimum, we want to decrease the velocity a little bit for a careful search.

Adam tends to converge faster, while SGD often converges to more optimal solutions. SGD's high variance disadvantages gets rectified by Adam (as advantage for Adam)."
ai,When would you use Adam and when SGD?,Neural Network,"Adam tends to converge faster, while SGD often converges to more optimal solutions."
ai,How do we decide when to stop training a neural net?,Neural Network,Simply stop training when the validation error is the minimum.
ai,What is model checkpointing?,Neural Network,Saving the weights learned by a model mid training for long running processes is known as model checkpointing so that you can resume your training from a certain checkpoint.
ai,What’s a convolutional layer?,Neural Network,"The idea of the convolutional layer is the assumption that the information needed for making a decision often is spatially close and thus, it only takes the weighted sum over nearby inputs. It also assumes that the networks’ kernels can be reused for all nodes, hence the number of weights can be drastically reduced. To counteract only one feature being learnt per layer, multiple kernels are applied to the input which creates parallel channels in the output. Consecutive layers can also be stacked to allow the network to find more high-level features."
ai,Why do we actually need convolutions? Can’t we use fully-connected layers for that?,Neural Network,"A fully-connected layer needs one weight per inter-layer connection, which means the number of weights which needs to be computed quickly balloons as the number of layers and nodes per layer is increased."
ai,What’s pooling in CNN? Why do we need it?,Neural Network,"Pooling is a technique to downsample the feature map. It allows layers which receive relatively undistorted versions of the input to learn low level features such as lines, while layers deeper in the model can learn more abstract features such as texture.
"
ai,How does max pooling work? Are there other pooling techniques?,Neural Network,"Max pooling is a technique where the maximum value of a receptive field is passed on in the next feature map. The most commonly used receptive field is 2 x 2 with a stride of 2, which means the feature map is downsampled from N x N to N/2 x N/2. Receptive fields larger than 3 x 3 are rarely employed as too much information is lost.

Other pooling techniques include:

Average pooling, the output is the average value of the receptive field.
Min pooling, the output is the minimum value of the receptive field.
Global pooling, where the receptive field is set to be equal to the input size, this means the output is equal to a scalar and can be used to reduce the dimensionality of the feature map."
ai,Are CNNs resistant to rotations? What happens to the predictions of a CNN if an image is rotated?,Neural Network,"CNNs are not resistant to rotation by design. However, we can make our models resistant by augmenting our datasets with different rotations of the raw data. The predictions of a CNN will change if an image is rotated and we did not augment our dataset accordingly."
ai,What are augmentations? Why do we need them? ,Neural Network,"Augmentations are an artifical way of expanding the existing datasets by performing some transformations, color shifts or many other things on the data. It helps in diversifying the data and even increasing the data when there is scarcity of data for a model to train on."
ai,What kind of augmentations do you know?,Neural Network,"There are many kinds of augmentations which can be used according to the type of data you are working on some of which are geometric and numerical transformation, PCA, cropping, padding, shifting, noise injection etc."
ai,How to choose which augmentations to use?,Neural Network,"Augmentations really depend on the type of output classes and the features you want your model to learn. For eg. if you have mostly properly illuminated images in your dataset and want your model to predict poorly illuminated images too, you can apply channel shifting on your data and include the resultant images in your dataset for better results."
ai,What kind of CNN architectures for classification do you know?,Neural Network,"Image Classification

Inception v3
Xception
DenseNet
AlexNet
VGG16
ResNet
SqueezeNet
EfficientNet
MobileNet
The last three are designed so they use smaller number of parameters which is helpful for edge AI."
ai,What is transfer learning? How does it work?,Neural Network,"Given a source domain D_S and learning task T_S, a target domain D_T and learning task T_T, transfer learning aims to help improve the learning of the target predictive function f_T in D_T using the knowledge in D_S and T_S, where D_S ≠ D_T,or T_S ≠ T_T. In other words, transfer learning enables to reuse knowledge coming from other domains or learning tasks.

In the context of CNNs, we can use networks that were pre-trained on popular datasets such as ImageNet. We then can use the weights of the layers that learn to represent features and combine them with a new set of layers that learns to map the feature representations to the given classes. Two popular strategies are either to freeze the layers that learn the feature representations completely, or to give them a smaller learning rate."
ai,What is bag of words? How we can use it for text classification?,Methodology,"Bag of Words is a representation of text that describes the occurrence of words within a document. The order or structure of the words is not considered. For text classification, we look at the histogram of the words within the text and consider each word count as a feature."
ai,What are the advantages and disadvantages of bag of words?,Methodology,"Advantages:

Simple to understand and implement.
Disadvantages:

The vocabulary requires careful design, most specifically in order to manage the size, which impacts the sparsity of the document representations.
Sparse representations are harder to model both for computational reasons (space and time complexity) and also for information reasons
Discarding word order ignores the context, and in turn meaning of words in the document. Context and meaning can offer a lot to the model, that if modeled could tell the difference between the same words differently arranged (“this is interesting” vs “is this interesting”), synonyms (“old bike” vs “used bike”)."
ai,What are N-grams? How can we use them?,Methodology,The function to tokenize into consecutive sequences of words is called n-grams. It can be used to find out N most co-occurring words (how often word X is followed by word Y) in a given sentence.
ai,What is TF-IDF? How is it useful for text classification?,Methodology,"Term Frequency (TF) is a scoring of the frequency of the word in the current document. Inverse Document Frequency(IDF) is a scoring of how rare the word is across documents. It is used in scenario where highly recurring words may not contain as much informational content as the domain specific words. For example, words like “the” that are frequent across all documents therefore need to be less weighted. The TF-IDF score highlights words that are distinct (contain useful information) in a given document."
ai,Would you prefer gradient boosting trees model or logistic regression when doing text classification with bag of words?,"Gradient Boosting, Logistic Regression",Usually logistic regression is better because bag of words creates a matrix with large number of columns. For a huge number of columns logistic regression is usually faster than gradient boosting trees.
ai,"If you have a sentence with multiple words, you may need to combine multiple word embeddings into one. How would you do it?",Methodology,"Approaches ranked from simple to more complex:

Take an average over all words
Take a weighted average over all words. Weighting can be done by inverse document frequency (idf part of tf-idf).
Use ML model like LSTM or Transformer."
ai,Do you know how K-means works?,KMeans,"Partition points into k subsets.
Compute the seed points as the new centroids of the clusters of the current partitioning.
Assign each point to the cluster with the nearest seed point.
Go back to step 2 or stop when the assignment does not change."
ai,How to select K for K-means?,KMeans,"Domain knowledge, i.e. an expert knows the value of k
Elbow method: compute the clusters for different values of k, for each k, calculate the total within-cluster sum of square, plot the sum according to the number of clusters and use the band as the number of clusters.
Average silhouette method: compute the clusters for different values of k, for each k, calculate the average silhouette of observations, plot the silhouette according to the number of clusters and select the maximum as the number of clusters."
ai,What are the other clustering algorithms do you know?,Methodology,"k-medoids: Takes the most central point instead of the mean value as the center of the cluster. This makes it more robust to noise.
Agglomerative Hierarchical Clustering (AHC): hierarchical clusters combining the nearest clusters starting with each point as its own cluster.
DIvisive ANAlysis Clustering (DIANA): hierarchical clustering starting with one cluster containing all points and splitting the clusters until each point describes its own cluster.
Density-Based Spatial Clustering of Applications with Noise (DBSCAN): Cluster defined as maximum set of density-connected points."
ai,Do you know how DBScan works?,Methodology,"Two input parameters epsilon (neighborhood radius) and minPts (minimum number of points in an epsilon-neighborhood)
Cluster defined as maximum set of density-connected points.
Points p_j and p_i are density-connected w.r.t. epsilon and minPts if there is a point o such that both, i and j are density-reachable from o w.r.t. epsilon and minPts.
p_j is density-reachable from p_i w.r.t. epsilon, minPts if there is a chain of points p_i -> p_i+1 -> p_i+x = p_j such that p_i+x is directly density-reachable from p_i+x-1.
p_j is a directly density-reachable point of the neighborhood of p_i if dist(p_i,p_j) <= epsilon."
ai,When would you choose K-means and when DBScan?,"KMeans, Methodology","DBScan is more robust to noise.
DBScan is better when the amount of clusters is difficult to guess.
K-means has a lower complexity, i.e. it will be much faster, especially with a larger amount of points."
ai,What is the curse of dimensionality? Why do we care about it?,EDA,"Data in only one dimension is relatively tightly packed. Adding a dimension stretches the points across that dimension, pushing them further apart. Additional dimensions spread the data even further making high dimensional data extremely sparse. We care about it, because it is difficult to use machine learning in sparse spaces."
ai,Do you know any dimensionality reduction techniques?,Methodology,"Singular Value Decomposition (SVD)
Principal Component Analysis (PCA)
Linear Discriminant Analysis (LDA)
T-distributed Stochastic Neighbor Embedding (t-SNE)
Autoencoders
Fourier and Wavelet Transforms"
ai,What’s singular value decomposition? How is it typically used for machine learning?,Methodology,"Singular Value Decomposition (SVD) is a general matrix decomposition method that factors a matrix X into three matrices L (left singular values), Σ (diagonal matrix) and R^T (right singular values).
For machine learning, Principal Component Analysis (PCA) is typically used. It is a special type of SVD where the singular values correspond to the eigenvectors and the values of the diagonal matrix are the squares of the eigenvalues. We use these features as they are statistically descriptive.
Having calculated the eigenvectors and eigenvalues, we can use the Kaiser-Guttman criterion, a scree plot or the proportion of explained variance to determine the principal components (i.e. the final dimensionality) that are useful for dimensionality reduction."
ai,What is precision and recall at k?,Statistics ,"Precision at k and recall at k are evaluation metrics for ranking algorithms. Precision at k shows the share of relevant items in the first k results of the ranking algorithm. And Recall at k indicates the share of relevant items returned in top k results out of all correct answers for a given query.

Example: For a search query ""Car"" there are 3 relevant products in your shop. Your search algorithm returns 2 of those relevant products in the first 5 search results. Precision at 5 = # num of relevant products in search result / k = 2/5 = 40% Recall at 5 = # num of relevant products in search result / # num of all relevant products = 2/3 = 66.6%"
ai,What are good baselines when building a recommender system?,Methodology,"A good recommer system should give relevant and personalized information.
It should not recommend items the user knows well or finds easily.
It should make diverse suggestions.
A user should explore new items."
ai,What is collaborative filtering?,Methodology,"Collaborative filtering is the most prominent approach to generate recommendations.
It uses the wisdom of the crowd, i.e. it gives recommendations based on the experience of others.
A recommendation is calculated as the average of other experiences.
Say we want to give a score that indicates how much user u will like an item i. Then we can calculate it with the experience of N other users U as r_ui = 1/N * sum(v in U) r_vi.
In order to rate similar experiences with a higher weight, we can introduce a similarity between users that we use as a multiplier for each rating.
Also, as users have an individual profile, one user may have an average rating much larger than another user, so we use normalization techniques (e.g. centering or Z-score normalization) to remove the users' biases.
Collaborative filtering does only need a rating matrix as input and improves over time. However, it does not work well on sparse data, does not work for cold starts (see below) and usually tends to overfit."
ai,"How we can incorporate implicit feedback (clicks, etc) into our recommender systems?",Methodology,"In comparison to explicit feedback, implicit feedback datasets lack negative examples. For example, explicit feedback can be a positive or a negative rating, but implicit feedback may be the number of purchases or clicks. One popular approach to solve this problem is named weighted alternating least squares (wALS) [Hu, Y., Koren, Y., & Volinsky, C. (2008, December). Collaborative filtering for implicit feedback datasets. In Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on (pp. 263-272). IEEE.]. Instead of modeling the rating matrix directly, the numbers (e.g. amount of clicks) describe the strength in observations of user actions. The model tries to find latent factors that can be used to predict the expected preference of a user for an item.
"
ai,What is the cold start problem?,Methodology,"Collaborative filterung incorporates crowd knowledge to give recommendations for certain items. Say we want to recommend how much a user will like an item, we then will calculate the score using the recommendations of other users for this certain item. We can distinguish between two different ways of a cold start problem now. First, if there is a new item that has not been rated yet, we cannot give any recommendation. Also, when there is a new user, we cannot calculate a similarity to any other user."
ai,Possible approaches to solving the cold start problem?,Methodology,"Content-based filtering incorporates features about items to calculate a similarity between them. In this way, we can recommend items that have a high similarity to items that a user liked already. In this way, we are not dependant on the ratings of other users for a given item anymore and solve the cold start problem for new items.
Demographic filtering incorporates user profiles to calculate a similarity between them and solves the cold start problem for new users."
ai,How is time series different from the usual regression problem?,Time Series,"The principle behind causal forecasting is that the value that has to be predicted is dependant on the input features (causal factors). In time series forecasting, the to be predicted value is expected to follow a certain pattern over time."
ai,Which models do you know for solving time series problems?,Time Series,"Simple Exponential Smoothing: approximate the time series with an exponentional function
Trend-Corrected Exponential Smoothing (Holt‘s Method): exponential smoothing that also models the trend
Trend- and Seasonality-Corrected Exponential Smoothing (Holt-Winter‘s Method): exponential smoothing that also models trend and seasonality
Time Series Decomposition: decomposed a time series into the four components trend, seasonal variation, cycling varation and irregular component
Autoregressive models: similar to multiple linear regression, except that the dependent variable y_t depends on its own previous values rather than other independent variables.
Deep learning approaches (RNN, LSTM, etc.)"
ai,"If there’s a trend in our series, how we can remove it? And why would we want to do it?",Methodology,"We can explicitly model the trend (and/or seasonality) with approaches such as Holt's Method or Holt-Winter's Method. We want to explicitly model the trend to reach the stationarity property for the data. Many time series approaches require stationarity. Without stationarity,the interpretation of the results of these analyses is problematic [Manuca, Radu & Savit, Robert. (1996). Stationarity and nonstationarity in time series analysis. Physica D: Nonlinear Phenomena. 99. 134-161. 10.1016/S0167-2789(96)00139-X. ]."
ai,You have a series with only one variable “y” measured at time t. How do predict “y” at time t+1? Which approaches would you use?,Methodology,We want to look at the correlation between different observations of y. This measure of correlation is called autocorrelation. Autoregressive models are multiple regression models where the time-lag series of the original time series are treated like multiple independent variables.
ai,You have a series with a variable “y” and a set of features. How do you predict “y” at t+1? Which approaches would you use?,Methodology,"Given the assumption that the set of features gives a meaningful causation to y, a causal forecasting approach such as linear regression or multiple nonlinear regression might be useful. In case there is a lot of data and the explanability of the results is not a high priority, we can also consider deep learning approaches."
ai,What are the problems with using trees for solving time series problems?,"Decision Trees, Time Series","Random Forest models are not able to extrapolate time series data and understand increasing/decreasing trends. It will provide us with average data points if the validation data has values greater than the training data points.
"
ai,What are the most common algorithms for supervised learning and unsupervised learning?,Methodology,"Supervised learning algorithms:

Linear regression
Logistic regression
Decision trees
Random forests
Naive Bayes
Neural networks

Examples of unsupervised algorithms:

Clustering: k-Means
Visualization and dimensionality reduction
Principal component analysis (PCA), t-distributed
Stochastic neighbor embedding (t-SNE)
Association rule learning (Apriori)"
ai,How do you choose a classifier based on a training set size?,Methodology,"For a small training set, a model with high bias and low variance models is better, as it is less likely overfit. An example is Naive Bayes.

For a large training set, a model with low bias and high variance models is better, as it expresses more complex relationships. An example is Logistic Regression.
"
ai,Explain LDA for unsupervised learning.,Methodology,"Latent Dirichlet Allocation (LDA) is a common method for topic modeling. It is a generative model for representing documents as a combination of topics, each with their own probability distribution.

LDA aims to project the features of higher dimensional space onto a lower-dimensional space. This helps to avoid the curse of dimensionality."
ai,How do you fix high variance in a model?,Methodology,"If the model has low variance and high bias, we use a bagging algorithm, which divides a data set into subsets using randomized sampling. We use those samples to generate a set of models with a single learning algorithm.

Additionally, we can use the regularization technique, in which higher model coefficients are penalized to lower the complexity overall."
ai,You are working on a dataset. How do you select important variables?,EDA,"Remove correlated variables before selecting important variables
Use Random Forest and a plot variable importance chart
Use Lasso Regression
Use linear regression to select variables based on p values
Use Forward Selection, Stepwise Selection, and Backward Selection"
ai,What are advantages and disadvantages of using neural networks?,Neural Network,"Advantages:

Store data on the entire network rather than a database
Parallel processing
Distributed memory
Provides great accuracy even with limited information

Disadvantages:

Requires complex processors
Duration of a network is somewhat unknown
We rely on error value too heavily
Black-box nature
"
ai,What is the default method for splitting in decision trees?,Decision Trees,"The default method is the Gini Index, which is the measure of impurity of a particular node. Essentially, it calculates the probability of a specific feature that is classified incorrectly. When the elements are linked by a single class, we call this “pure”.

You could also use Random Forest, but the Gini Index is preferred because it isn’t computationally intensive and doesn’t involve logarithm functions."
ai,Why does XGBoost perform better than SVM?,"XGBoost, SVM","XGBoos is an ensemble method that uses many trees. This means it improves as it repeats itself.

SVM is a linear separator. So, if our data is not linearly separable, SVM requires a Kernel to get the data to a state where it can be separated. This can limit us, as there is not a perfect Kernel for every given dataset."
ai,"For NLP, what’s the main purpose of using an encoder-decoder model?",Neural Network,"We use the encoder-decoder model to generate an output sequence based on an input sequence.

What makes an encoder-decoder model so powerful is that the decoder uses the final state of the encoder as its initial state. This gives the decoder access to the information that the encoder extracted from the input sequence."
ai,"When using scikit-learn, is it true that we need to scale our feature values when they vary greatly?",EDA,"Yes. Most of the machine learning algorithms use Euclidean distance as the metrics to measure the distance between two data points. If the range of values is different greatly, the result of the same change in the different features will be very different."
ai,What's the trade-off between bias and variance?,ML,If our model is too simple and has very few parameters then it may have high bias and low variance. On the other hand if our model has large number of parameters then it’s going to have high variance and low bias. So we need to find the right/good balance without overfitting and underfitting the data.  
ai,What is gradient descent?,ML,Gradient descent is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost). Gradient descent is best used when the parameters cannot be calculated analytically (e.g. using linear algebra) and must be searched for by an optimization algorithm. 
ai,Explain over- and under-fitting and how to combat them?,ML,"ML/DL models essentially learn a relationship between its given inputs(called training features) and objective outputs(called labels). Regardless of the quality of the learned relation(function), its performance on a test set(a collection of data different from the training input) is subject to investigation. Most ML/DL models have trainable parameters which will be learned to build that input-output relationship. Based on the number of parameters each model has, they can be sorted into more flexible(more parameters) to less flexible(less parameters). The problem of Underfitting arises when the flexibility of a model(its number of parameters) is not adequate to capture the underlying pattern in a training dataset. Overfitting, on the other hand, arises when the model is too flexible to the underlying pattern. In the later case it is said that the model has “memorized” the training data. An example of underfitting is estimating a second order polynomial(quadratic function) with a first order polynomial(a simple line). Similarly, estimating a line with a 10th order polynomial would be an example of overfitting. "
ai,How do you combat the curse of dimensionality?,ML, - Feature Selection(manual or via statistical methods)  - Principal Component Analysis (PCA)  - Multidimensional Scaling  - Locally linear embedding   
ai,"What is regularization, why do we use it, and give some examples of common methods?",ML,"A technique that discourages learning a more complex or flexible model, so as to avoid the risk of overfitting.  Examples  - Ridge (L2 norm)  - Lasso (L1 norm)   The obvious *disadvantage* of **ridge** regression, is model interpretability. It will shrink the coefficients for least important predictors, very close to zero. But it will never make them exactly zero. In other words, the *final model will include all predictors*. However, in the case of the **lasso**, the L1 penalty has the effect of forcing some of the coefficient estimates to be *exactly equal* to zero when the tuning parameter λ is sufficiently large. Therefore, the lasso method also performs variable selection and is said to yield sparse models. "
ai,Explain Principal Component Analysis (PCA)?,ML,"Principal Component Analysis (PCA) is a dimensionality reduction technique used in machine learning to reduce the number of features in a dataset while retaining as much information as possible. It works by identifying the directions (principal components) in which the data varies the most, and projecting the data onto a lower-dimensional subspace along these directions. "
ai,Why is ReLU better and more often used than Sigmoid in Neural Networks?,ML,* Computation Efficiency:   As ReLU is a simple threshold the forward and backward path will be faster. * Reduced Likelihood of Vanishing Gradient:   Gradient of ReLU is 1 for positive values and 0 for negative values while Sigmoid activation saturates (gradients close to 0) quickly with slightly higher or lower inputs leading to vanishing gradients. * Sparsity:   Sparsity happens when the input of ReLU is negative. This means fewer neurons are firing ( sparse activation ) and the network is lighter.  
ai,"Given stride S and kernel sizes  for each layer of a (1-dimensional) CNN, create a function to compute the [receptive field] of a particular node in the network. This is just finding how many input nodes actually connect through to a neuron in a CNN.",ML,"The receptive field are defined portion of space within an inputs that will be used during an operation to generate an output. Considering a CNN filter of size k, the receptive field of a peculiar layer is only the number of input used by the filter, in this case k, multiplied by the dimension of the input that is not being reduced by the convolutionnal filter a. This results in a receptive field of k*a. More visually, in the case of an image of size 32x32x3, with a CNN with a filter size of 5x5, the corresponding recpetive field will be the the filter size, 5 multiplied by the depth of the input volume (the RGB colors) which is the color dimensio. This thus gives us a recpetive field of dimension 5x5x3. "
ai,How would you remove outliers when trying to estimate a flat plane from noisy samples?,ML,"Random sample consensus (RANSAC) is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers, when outliers are to be accorded no influence on the values of the estimates. "
ai,How does [CBIR] work?,ML,"Content-based image retrieval is the concept of using images to gather metadata on their content. Compared to the current image retrieval approach based on the keywords associated to the images, this technique generates its metadata from computer vision techniques to extract the relevant informations that will be used during the querying step. Many approach are possible from feature detection to retrieve keywords to the usage of CNN to extract dense features that will be associated to a known distribution of keywords.  With this last approach, we care less about what is shown on the image but more about the similarity between the metadata generated by a known image and a list of known label and or tags projected into this metadata space. "
ai,Describe how convolution works. What about if your inputs are grayscale vs RGB imagery? What determines the shape of the next layer?,ML,"In a convolutional neural network (CNN), the convolution operation is applied to the input image using a small matrix called a kernel or filter. The kernel slides over the image in small steps, called strides, and performs element-wise multiplications with the corresponding elements of the image and then sums up the results. The output of this operation is called a feature map. When the input is RGB(or more than 3 channels) the sliding window will be a sliding cube. The shape of the next layer is determined by Kernel size, number of kernels, stride, padding, and dialation. "
ai,Talk me through how you would create a 3D model of an object from imagery and depth sensor measurements taken at all angles around the object.,ML,There are two popular methods for 3D reconstruction: * Structure from Motion (SfM)  * Multi-View Stereo (MVS)  SfM is better suited for creating models of large scenes while MVS is better suited for creating models of small objects. 
ai,"Implement SQRT(const double & x) without using any special functions, just fundamental arithmetic.",ML,The taylor series can be used for this step by providing an approximation of sqrt(x): 
ai,Reverse a bitstring.,ML,If you are using python3 : ``` data = b'\xAD\xDE\xDE\xC0' my_data = bytearray(data) my_data.reverse() ``` 
ai,Implement non maximal suppression as efficiently as you can.,ML,"Non-Maximum Suppression (NMS) is a technique used to eliminate multiple detections of the same object in a given image. To solve that first sort bounding boxes based on their scores(N LogN). Starting with the box with the highest score, remove boxes whose overlapping metric(IoU) is greater than a certain threshold.(N^2) To optimize this solution you can use special data structures to query for overlapping boxes such as R-tree or KD-tree. (N LogN) "
ai,What is data normalization and why do we need it?,ML,"Data normalization is very important preprocessing step, used to rescale values to fit in a specific range to assure better convergence during backpropagation. In general, it boils down to subtracting the mean of each data point and dividing by its standard deviation. If we don't do this then some of the features (those with high magnitude) will be weighted more in the cost function (if a higher-magnitude feature changes by 1%, then that change is pretty big, but for smaller features it's quite insignificant). The data normalization makes all features weighted equally. "
ai,Why do we use convolutions for images rather than just FC layers?,ML,"Firstly, convolutions preserve, encode, and actually use the spatial information from the image. If we used only FC layers we would have no relative spatial information. Secondly, Convolutional Neural Networks (CNNs) have a partially built-in translation in-variance, since each convolution kernel acts as it's own filter/feature detector. "
ai,What makes CNNs translation invariant?,ML,"As explained above, each convolution kernel acts as it's own filter/feature detector. So let's say you're doing object detection, it doesn't matter where in the image the object is since we're going to apply the convolution in a sliding window fashion across the entire image anyways. "
ai,Why do we have max-pooling in classification CNNs?,ML,for a role in Computer Vision. Max-pooling in a CNN allows you to reduce computation since your feature maps are smaller after the pooling. You don't lose too much semantic information since you're taking the maximum activation. There's also a theory that max-pooling contributes a bit to giving CNNs more translation in-variance. Check out this great video from Andrew Ng on the [benefits of max-pooling]. 
ai,Why do segmentation CNNs typically have an encoder-decoder style / structure?,ML,"The encoder CNN can basically be thought of as a feature extraction network, while the decoder uses that information to predict the image segments by ""decoding"" the features and upscaling to the original image size. "
ai,What is the significance of Residual Networks?,ML,"The main thing that residual connections did was allow for direct feature access from previous layers. This makes information propagation throughout the network much easier. One very interesting paper about this shows how using local skip connections gives the network a type of ensemble multi-path structure, giving features multiple paths to propagate throughout the network. "
ai,What is batch normalization and why does it work?,ML,"Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. The idea is then to normalize the inputs of each layer in such a way that they have a mean output activation of zero and standard deviation of one. This is done for each individual mini-batch at each layer i.e compute the mean and variance of that mini-batch alone, then normalize. This is analogous to how the inputs to networks are standardized. How does this help? We know that normalizing the inputs to a network helps it learn. But a network is just a series of layers, where the output of one layer becomes the input to the next. That means we can think of any layer in a neural network as the first layer of a smaller subsequent network. Thought of as a series of neural networks feeding into each other, we normalize the output of one layer before applying the activation function, and then feed it into the following layer (sub-network). "
ai,Why would you use many small convolutional kernels such as 3x3 rather than a few large ones?,ML,"This is very well explained in the [VGGNet paper]. There are 2 reasons: First, you can use several smaller kernels rather than few large ones to get the same receptive field and capture more spatial context, but with the smaller kernels you are using less parameters and computations. Secondly, because with smaller kernels you will be using more filters, you'll be able to use more activation functions and thus have a more discriminative mapping function being learned by your CNN. "
ai,Why do we need a validation set and test set? What is the difference between them?,ML,"When training a model, we divide the available data into three separate sets:  - The training dataset is used for fitting the model’s parameters. However, the accuracy that we achieve on the training set is not reliable for predicting if the model will be accurate on new samples.  - The validation dataset is used to measure how well the model does on examples that weren’t part of the training dataset. The metrics computed on the validation data can be used to tune the hyperparameters of the model. However, every time we evaluate the validation data and we make decisions based on those scores, we are leaking information from the validation data into our model. The more evaluations, the more information is leaked. So we can end up overfitting to the validation data, and once again the validation score won’t be reliable for predicting the behaviour of the model in the real world.  - The test dataset is used to measure how well the model does on previously unseen examples. It should only be used once we have tuned the parameters using the validation set. So if we omit the test set and only use a validation set, the validation score won’t be a good estimate of the generalization of the model. "
ai,What is stratified cross-validation and when should we use it?,ML,"Cross-validation is a technique for dividing data between training and validation sets. On typical cross-validation this split is done randomly. But in stratified cross-validation, the split preserves the ratio of the categories on both the training and validation datasets. For example, if we have a dataset with 10% of category A and 90% of category B, and we use stratified cross-validation, we will have the same proportions in training and validation. In contrast, if we use simple cross-validation, in the worst case we may find that there are no samples of category A in the validation set. Stratified cross-validation may be applied in the following scenarios:  - On a dataset with multiple categories. The smaller the dataset and the more imbalanced the categories, the more important it will be to use stratified cross-validation.  - On a dataset with data of different distributions. For example, in a dataset for autonomous driving, we may have images taken during the day and at night. If we do not ensure that both types are present in training and validation, we will have generalization problems. "
ai,Why do ensembles typically have higher scores than individual models?,ML,"An ensemble is the combination of multiple models to create a single prediction. The key idea for making better predictions is that the models should make different errors. That way the errors of one model will be compensated by the right guesses of the other models and thus the score of the ensemble will be higher. We need diverse models for creating an ensemble. Diversity can be achieved by:  - Using different ML algorithms. For example, you can combine logistic regression, k-nearest neighbors, and decision trees.  - Using different subsets of the data for training. This is called bagging.  - Giving a different weight to each of the samples of the training set. If this is done iteratively, weighting the samples according to the errors of the ensemble, it’s called boosting. Many winning solutions to data science competitions are ensembles. However, in real-life machine learning projects, engineers need to find a balance between execution time and accuracy. "
ai,What is an imbalanced dataset? Can you list some ways to deal with it?,ML,"An imbalanced dataset is one that has different proportions of target categories. For example, a dataset with medical images where we have to detect some illness will typically have many more negative samples than positive samples—say, 98% of images are without the illness and 2% of images are with the illness. There are different options to deal with imbalanced datasets:  - Oversampling or undersampling. Instead of sampling with a uniform distribution from the training dataset, we can use other distributions so the model sees a more balanced dataset.  - Data augmentation. We can add data in the less frequent categories by modifying existing data in a controlled way. In the example dataset, we could flip the images with illnesses, or add noise to copies of the images in such a way that the illness remains visible.  - Using appropriate metrics. In the example dataset, if we had a model that always made negative predictions, it would achieve a precision of 98%. There are other metrics such as precision, recall, and F-score that describe the accuracy of the model better when using an imbalanced dataset. "
ai,"Can you explain the differences between supervised, unsupervised, and reinforcement learning?",ML,"In supervised learning, we train a model to learn the relationship between input data and output data. We need to have labeled data to be able to do supervised learning. With unsupervised learning, we only have unlabeled data. The model learns a representation of the data. Unsupervised learning is frequently used to initialize the parameters of the model when we have a lot of unlabeled data and a small fraction of labeled data. We first train an unsupervised model and, after that, we use the weights of the model to train a supervised model. In reinforcement learning, the model has some input data and a reward depending on the output of the model. The model learns a policy that maximizes the reward. Reinforcement learning has been applied successfully to strategic games such as Go and even classic Atari video games. "
ai,What is data augmentation? Can you give some examples?,ML,"Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way. Computer vision is one of fields where data augmentation is very useful. There are many modifications that we can do to images:  - Resize  - Horizontal or vertical flip  - Rotate  - Add noise  - Deform  - Modify colors Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help. "
ai,What is Turing test?,ML,"The Turing test is a method to test the machine’s ability to match the human level intelligence. A machine is used to challenge the human intelligence that when it passes the test, it is considered as intelligent. Yet a machine could be viewed as intelligent without sufficiently knowing about people to mimic a human. "
ai,What is Precision?,ML,Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances   Precision = true positive / (true positive + false positive)   
ai,What is Recall?,ML,Recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. Recall = true positive / (true positive + false negative)   
ai,Define F1-score.,ML,It is the weighted average of precision and recall. It considers both false positive and false negative into account. It is used to measure the model’s performance.   F1-Score = 2 * (precision * recall) / (precision + recall) 
ai,What is cost function?,ML,"Cost function is a scalar functions which Quantifies the error factor of the Neural Network. Lower the cost function better the Neural network. Eg: MNIST Data set to classify the image, input image is digit 2 and the Neural network wrongly predicts it to be 3 "
ai,List different activation neurons or functions.,ML, - Linear Neuron  - Binary Threshold Neuron  - Stochastic Binary Neuron  - Sigmoid Neuron  - Tanh function  - Rectified Linear Unit (ReLU) 
ai,Define Learning Rate.,ML,Learning rate is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient.  
ai,What is Momentum (w.r.t NN optimization)?,ML,"Momentum lets the optimization algorithm remembers its last step, and adds some proportion of it to the current step. This way, even if the algorithm is stuck in a flat region, or a small local minimum, it can get out and continue towards the true minimum.  "
ai,What is the difference between Batch Gradient Descent and Stochastic Gradient Descent?,ML,"Batch gradient descent computes the gradient using the whole dataset. This is great for convex, or relatively smooth error manifolds. In this case, we move somewhat directly towards an optimum solution, either local or global. Additionally, batch gradient descent, given an annealed learning rate, will eventually find the minimum located in it's basin of attraction. Stochastic gradient descent (SGD) computes the gradient using a single sample. SGD works well (Not well, I suppose, but better than batch gradient descent) for error manifolds that have lots of local maxima/minima. In this case, the somewhat noisier gradient calculated using the reduced number of samples tends to jerk the model out of local minima into a region that hopefully is more optimal.  "
ai,Epoch vs. Batch vs. Iteration.,ML, - **Epoch**: one forward pass and one backward pass of **all** the training examples    - **Batch**: examples processed together in one pass (forward and backward)    - **Iteration**: number of training examples / Batch size   
ai,What is vanishing gradient?,ML,"As we add more and more hidden layers, back propagation becomes less and less useful in passing information to the lower layers. In effect, as information is passed back, the gradients begin to vanish and become small relative to the weights of the networks. "
ai,What are dropouts?,ML,"Dropout is a simple way to prevent a neural network from overfitting. It is the dropping out of some of the units in a neural network. It is similar to the natural reproduction process, where the nature produces offsprings by combining distinct genes (dropping out others) rather than strengthening the co-adapting of them. "
ai,Define LSTM.,ML,"Long Short Term Memory – are explicitly designed to address the long term dependency problem, by maintaining a state what to remember and what to forget. "
ai,List the key components of LSTM.,ML," - Gates (forget, Memory, update & Read)  - tanh(x) (values between -1 to 1)  - Sigmoid(x) (values between 0 to 1) "
ai,List the variants of RNN.,ML, - LSTM: Long Short Term Memory  - GRU: Gated Recurrent Unit  - End to End Network  - Memory Network 
ai,"What is Autoencoder, name few applications.",ML,Auto encoder is basically used to learn a compressed form of given data. Few applications include  - Data denoising  - Dimensionality reduction  - Image reconstruction  - Image colorization 
ai,What are the components of GAN?,ML, - Generator  - Discriminator 
ai,What's the difference between boosting and bagging?,ML,"Boosting and bagging are similar, in that they are both ensembling techniques, where a number of weak learners (classifiers/regressors that are barely better than guessing) combine (through averaging or max vote) to create a strong learner that can make accurate predictions. Bagging means that you take bootstrap samples (with replacement) of your data set and each sample trains a (potentially) weak learner. Boosting, on the other hand, uses all data to train each learner, but instances that were misclassified by the previous learners are given more weight so that subsequent learners give more focus to them during training.  "
ai,Explain how a ROC curve works.,ML,The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives). 
ai,What’s the difference between Type I and Type II error?,ML,"Type I error is a false positive, while Type II error is a false negative. Briefly stated, Type I error means claiming something has happened when it hasn’t, while Type II error means that you claim nothing is happening when in fact something is. A clever way to think about this is to think of Type I error as telling a man he is pregnant, while Type II error means you tell a pregnant woman she isn’t carrying a baby. "
ai,What’s the difference between a generative and discriminative model?,ML,A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks. 
ai,Instance-Based Versus Model-Based Learning.,ML," - **Instance-based Learning**: The system learns the examples by heart, then generalizes to new cases using a similarity measure.  - **Model-based Learning**: Another way to generalize from a set of examples is to build a model of these examples, then use that model to make predictions. This is called model-based learning. "
ai,When to use a Label Encoding vs. One Hot Encoding?,ML,"This question generally depends on your dataset and the model which you wish to apply. But still, a few points to note before choosing the right encoding technique for your model: We apply One-Hot Encoding when: - The categorical feature is not ordinal (like the countries above) - The number of categorical features is less so one-hot encoding can be effectively applied We apply Label Encoding when: - The categorical feature is ordinal (like Jr. kg, Sr. kg, Primary school, high school) - The number of categories is quite large as one-hot encoding can lead to high memory consumption "
ai,What is the difference between LDA and PCA for dimensionality reduction?,ML,"Both LDA and PCA are linear transformation techniques: LDA is a supervised whereas PCA is unsupervised – PCA ignores class labels. We can picture PCA as a technique that finds the directions of maximal variance. In contrast to PCA, LDA attempts to find a feature subspace that maximizes class separability. "
ai,What is t-SNE?,ML,"t-Distributed Stochastic Neighbor Embedding (t-SNE) is an unsupervised, non-linear technique primarily used for data exploration and visualizing high-dimensional data. In simpler terms, t-SNE gives you a feel or intuition of how the data is arranged in a high-dimensional space.  "
ai,What is the difference between t-SNE and PCA for dimensionality reduction?,ML,"The first thing to note is that PCA was developed in 1933 while t-SNE was developed in 2008. A lot has changed in the world of data science since 1933 mainly in the realm of compute and size of data. Second, PCA is a linear dimension reduction technique that seeks to maximize variance and preserves large pairwise distances. In other words, things that are different end up far apart. This can lead to poor visualization especially when dealing with non-linear manifold structures. Think of a manifold structure as any geometric shape like: cylinder, ball, curve, etc. t-SNE differs from PCA by preserving only small pairwise distances or local similarities whereas PCA is concerned with preserving large pairwise distances to maximize variance. "
ai,What is UMAP?,ML,UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. 
ai,What is the difference between t-SNE and UMAP for dimensionality reduction?,ML,"The biggest difference between the output of UMAP when compared with t-SNE is this balance between local and global structure - UMAP is often better at preserving global structure in the final projection. This means that the inter-cluster relations are potentially more meaningful than in t-SNE. However, it's important to note that, because UMAP and t-SNE both necessarily warp the high-dimensional shape of the data when projecting to lower dimensions, any given axis or distance in lower dimensions still isn’t directly interpretable in the way of techniques such as PCA. "
ai,"How Random Number Generator Works, e.g. rand() function in python works?",ML,"It generates a pseudo random number based on the seed and there are some famous algorithm, please see below link for further information on this. "
ai,"Given that we want to evaluate the performance of 'n' different machine learning models on the same data, why would the following splitting mechanism be incorrect :",ML,"``` def get_splits():     df = pd.DataFrame(...)     rnd = np.random.rand(len(df))     train = df[ rnd < 0.8 ]     valid = df[ rnd >= 0.8 & rnd < 0.9 ]     test = df[ rnd >= 0.9 ]     return train, valid, test #Model 1 from sklearn.tree import DecisionTreeClassifier train, valid, test = get_splits() ... #Model 2 from sklearn.linear_model import LogisticRegression train, valid, test = get_splits() ... ``` The rand() function orders the data differently each time it is run, so if we run the splitting mechanism again, the 80% of the rows we get will be different from the ones we got the first time it was run. This presents an issue as we need to compare the performance of our models on the same test set. In order to ensure reproducible and consistent sampling we would have to set the random seed in advance or store the data once it is split. Alternatively, we could simply set the 'random_state' parameter in sklearn's train_test_split() function in order to get the same train, validation and test sets across different executions.  "
ai,What is the difference between Bayesian vs frequentist statistics?,ML,"Frequentist statistics is a framework that focuses on estimating population parameters using sample statistics, and providing point estimates and confidence intervals. Bayesian statistics, on the other hand, is a framework that uses prior knowledge and information to update beliefs about a parameter or hypothesis, and provides probability distributions for parameters. The main difference is that Bayesian statistics incorporates prior knowledge and beliefs into the analysis, while frequentist statistics doesn't. ## Contributions Contributions are most welcomed.  1. Fork the repository.  2. Commit your *questions* or *answers*.  3. Open **pull request**. ## Preparation Resources 1. [All of Statistics: A Concise Course in Statistical Inference] by Larry Wasserman 2. [Machine Learning] by Tom Mitchell 3. [Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications] by Chip Huyen"
ai,What is the difference between stemming and lemmatization?,NLP,"Stemming and lemmatization are both techniques used in natural language processing to reduce words to their base form. The main difference between the two is that stemming is a crude heuristic process that chops off the ends of words, while lemmatization is a more sophisticated process that uses vocabulary and morphological analysis to determine the base form of a word. Lemmatization is more accurate but also more computationally expensive. Example: The word ""better"" * Stemming: The stem of the word ""better"" is likely to be ""better"" (e.g. by using Porter stemmer) * Lemmatization: The base form of the word ""better"" is ""good"" (e.g. by using WordNetLemmatizer with POS tagger)"
ai,What do you know about Latent Semantic Indexing (LSI)?,NLP,Latent Semantic Indexing (LSI) is a technique used in NLP and information retrieval to extract the underlying meaning or concepts from a collection of text documents. LSI uses mathematical techniques such as Singular Value Decomposition (SVD) to identify patterns and relationships in the co-occurrence of words within a corpus of text. LSI is based on the idea that words that are used in similar context tend to have similar meanings.
ai,What do you know about Dependency Parsing?,NLP,"Dependency parsing is a technique used in natural language processing to analyze the grammatical structure of a sentence, and to identify the relationships between its words. It is used to build a directed graph where words are represented as nodes, and grammatical relationships between words are represented as edges. Each node has one parent and can have multiple children, representing the grammatical relations between the words. There are different algorithms for dependency parsing, such as the Earley parser, the CYK parser, and the shift-reduce parser. "
ai,Name different approaches for text summarization.,NLP,"There are several different approaches to text summarization, including: * Extractive summarization: Selects the most important sentences or phrases from the original text. * Abstractive summarization: Generates new sentences that capture the key concepts and themes of the original text. * Latent Semantic Analysis (LSA) based summarization: Uses LSA to identify the key concepts in a text. * Latent Dirichlet Allocation (LDA) based summarization: Uses LDA to identify the topics in a text. Each approach has its own strengths and weaknesses and the choice of the approach will depend on the specific use case and the quality of the summary desired.
* Neural-based summarization: Uses deep neural networks to generate a summary."
ai,What approach would you use for part of speech tagging?,NLP,"There are a few different approaches that can be used for part-of-speech (POS) tagging, such as: * Rule-based tagging: using pre-defined rules to tag text * Statistical tagging: using statistical models to tag text * Hybrid tagging: Combining rule-based and statistical methods * Neural-based tagging: using deep neural networks to tag text"
ai,Explain what is a n-gram model.,NLP,"An n-gram model is a type of statistical language model used in NLP. It is based on the idea that the probability of a word in a sentence is dependent on the probability of the n-1 preceding words, where n is the number of words in the gram. The model represents the text as a sequence of n-grams, where each n-gram is a sequence of n words. The model uses the frequency of each n-gram in a large corpus of text to estimate the probability of each word in a sentence, based on the n-1 preceding words."
ai,Explain how TF-IDF measures word importance.,NLP,"TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used to evaluate the importance of a word in a document or collection of documents. It is calculated as the product of the term frequency (TF) and the inverse document frequency (IDF) of a word. The term frequency (TF) of a word is the number of times the word appears in a document, normalized by the total number of words in the document.The inverse document frequency (IDF) of a word is the logarithm of the total number of documents in the corpus divided by the number of documents in which the word appears."
ai,What is perplexity used for?,NLP,"Perplexity is a statistical measure used to evaluate the quality of a probability model, particularly language models. It is used to quantify the uncertainty of a model when predicting the next word in a sequence of words. The lower the perplexity, the better the model is at predicting the sequence of words. Sure, here's the formula for perplexity in LaTeX format: Perplexity = $2^{H(D)}$ $H(D) = - \frac{1}{N} {\sum}_{i=1}^{N} {log_2^{ P(w_i) }}$ $w_i$ = the i-th word in the sequence $N$ = the number of words in the sequence $P(w_i)$ = the probability of the i-th word according to the model"
ai,What is Bag-of-Worrds model?,NLP,"The bag-of-words model is a representation of text data where a text is represented as a bag (multiset) of its words, disregarding grammar and word order but keeping track of the frequency of each word. It is simple to implement and computationally efficient, but it discards grammatical information and word order, which can be important for some NLP tasks."
ai,Explain how the Markov assumption affects the bi-gram model?,NLP,"The Markov assumption is an important concept in the bi-gram model, it states that the probability of a word in a sentence depends only on the preceding word. The Markov assumption simplifies the bi-gram model by reducing the number of variables that need to be considered, making the model computationally efficient, but it also limits the context that the model takes into account, which can lead to errors in the probability estimates. In practice, increasing the order of the n-gram model can be used to increase the context taken into account, thus increasing the model's accuracy."
ai,What are the most common word embedding methods? explain each briefly.,NLP,Common word embedding methods include: * Count-based methods: Create embeddings by counting the co-occurrence of words in a corpus. Example: Latent Semantic Analysis (LSA) * Prediction-based methods: Create embeddings by training a model to predict a target word based on its surrounding context. Example: Continuous Bag-of-Words (CBOW) and Word2Vec * Hybrid methods: Combine both co-occurrence and context to generate embeddings. Example: GloVe (Global Vectors for Word Representation) * Neural Language Model based methods: Create embeddings by training a neural network-based language model on a large corpus of text. Example: BERT (Bidirectional Encoder Representations from Transformers)
ai,What are the first few steps that you will take before applying an NLP algorithm to a given corpus?,NLP,"* Text pre-processing: Clean and transform the text into a format that can be processed by the model. Specific methods include: Removing special characters, lowercasing, removing stop words. * Tokenization: Break the text into individual words or phrases that can be used as input. Specific methods include: word tokenization, sentence tokenization, and n-gram tokenization. * Text normalization: Transform the text into a consistent format. Specific methods include: stemming, lemmatization. * Feature extraction: Select relevant features from the text to be used as input. Specific methods include: creating a vocabulary of the most common words in the corpus, creating a term-document matrix. * Splitting the data: Divide the data into training, validation and testing sets. * Annotating the data: Manually tag the data with relevant information. Specific methods include: POS tagging, NER tagging, and so on."
ai,List a few types of linguistic ambiguities.,NLP,"* Lexical ambiguity: A word has multiple meanings. Example: ""bass"" can refer to a type of fish or a low-frequency sound. * Syntactic ambiguity: A sentence can be parsed in more than one way. Example: ""I saw the man with the telescope"" can mean that the speaker saw a man who had a telescope or the speaker saw a man through a telescope. * Semantic ambiguity: A word or phrase can have more than one meaning in a given context. Example: ""bank"" can refer to a financial institution or the edge of a river. * Pragmatic ambiguity: A sentence can have different interpretations depending on the speaker's intended meaning. Example: ""I'm fine"" can mean that the speaker is feeling well or that the speaker does not want to talk about their feelings. * Anaphora resolution: A pronoun or noun phrase refers to an antecedent with multiple possible referents. * Homonymy: Words that are written and pronounced the same but have different meanings. Example: ""bass"" as a type of fish and a low-frequency sound * Polysemy: words that have multiple meanings but are related in some way. Example: ""bass"" as a low-frequency sound and the bass guitar."
mobile,What is Flutter?,Flutter,"Flutter is an open-source UI toolkit from Google for crafting beautiful, natively compiled applications for desktop, web, and mobile from a single codebase. Flutter apps are built using the Dart programming language."
mobile,What is the difference between Expanded and Flexible widgets?,Flutter,"Expanded is just a shorthand for Flexible Using expanded this way:
Expanded(
	child: Foo(),
);
is strictly equivalent to:
Flexible(
	fit: FlexFit.tight,
	child: Foo(),
);
You may want to use Flexible over Expanded when you want a different fit, useful in some responsive layouts.
The difference between FlexFit.tight and FlexFit.loose is that loose will allow its child to have a maximum size while tight forces that child to fill all the available space."
mobile,What is the pubspec.yaml file and what does it do?,Flutter,"The pubspec.yaml file allows you to define the packages your app relies on, declare your assets like images, audio, video, etc. It allows you to set constraints for your app. For Android developers, this is roughly similar to a build.gradle file."
mobile,Does Flutter work like a browser? How is it different from a WebView based application?,Flutter,"To answer this question simply: Code you write for a WebView or an app that runs similarly has to go through multiple layers to finally get executed. In essence, Flutter leapfrogs that by compiling down to native ARM code to execute on both platforms. “Hybrid” apps are slow, sluggish and look different from the platform they run on. Flutter apps run much, much faster than their hybrid counterparts. Also, it’s much easier to access native components and sensors using plugins rather than using WebViews which can’t take full use of their platform."
mobile,When should you use WidgetsBindingObserver?,Flutter, WidgetsBindingObserver should be used when we want to listen to the AppLifecycleState and call stop/start on our services.
mobile,What is the difference between main() and runApp() functions in Flutter?,Flutter,"main () function came from Java-like languages so it's where all program started, without it, you can't write any program on Flutter even without UI. runApp() function should return Widget that would be attached to the screen as a root of the Widget Tree that will be rendered."
mobile,What is an App state?,Flutter,"State that is not ephemeral, that you want to share across many parts of your app, and that you want to keep between user sessions, is what we call application state (sometimes also called shared state). Examples of application state: - User preferences - Login info - Notifications in a social networking app - The shopping cart in an e-commerce app - Read/unread state of articles in a news app"
mobile,What are the different build modes in Flutter?,Flutter,"The Flutter tooling supports three modes when compiling your app, and a headless mode for testing.
You choose a compilation mode depending on where you are in the development cycle.
The modes are: - Debug - Profile - Release"
mobile,What is Dart and why does Flutter use it?,Flutter,"Dart is an object-oriented, garbage-collected programming language that you use to develop Flutter apps. It was also created by Google, but is open-source, and has community inside and outside Google. Dart was chosen as the language of Flutter for the following reason:
Dart is AOT (Ahead Of Time) compiled to fast, predictable, native code, which allows almost all of Flutter to be written in Dart. This not only makes Flutter fast, virtually everything (including all the widgets) can be customized.
Dart can also be JIT (Just In Time) compiled for exceptionally fast development cycles and game-changing workflow (including Flutter’s popular sub-second stateful hot reload).
Dart allows Flutter to avoid the need for a separate declarative layout language like JSX or XML, or separate visual interface builders, because Dart’s declarative, programmatic layout is easy to read and visualize. And with all the layout in one language and in one place, it is easy for Flutter to provide advanced tooling that makes layout a snap."
mobile,How many types of widgets are there in Flutter?,Flutter,There are two types of widgets: 1. StatelessWidget : A widget that does not require mutable state. 2. StatefulWidget: A widget that has mutable state.
mobile,How is Flutter different from a WebView based application?,Flutter,"Code you write for a WebView or an app that runs similarly has to go through multiple layers to finally get executed (like Cordova for Ionic). In essence, Flutter leapfrogs that by compiling down to native ARM code to execute on both platforms.
“Hybrid” apps are slow, sluggish and look different from the platform they run on. Flutter apps run much, much faster than their hybrid counterparts.
It’s much easier to access native components and sensors using plugins rather than using WebView which can’t take full use of their platform."
mobile,What is a widget? Mention its importance in Flutter.,Flutter,"Widgets are basically the UI components in Flutter.
It is a way to describe the configuration of an Element.
They are inspired from components in React.
Widgets are important in Flutter because everything within a Flutter application is a Widget , from a simple “Text” to “Buttons” to “Screen Layouts”."
mobile,What is Fat Arrow Notationn in Dart and when do you use it?,Flutter,"The fat arrow syntax is simply a short hand for returning an expression and is similar to (){ return expression; }.
The fat arrow is for returning a single line, braces are for returning a code block.
Only an expression—not a statement—can appear between the arrow (=>) and the semicolon (;). For example, you can’t put an if statement there, but you can use a conditional expression
// Normal function
void function1(int a) {
  if (a == 3) {
    print('arg was 3');
  } else {
    print('arg was not 3');
  }
}

// Arrow Function
void function2(int a) => print('arg was ${a == 3 ? '' : 'not '}3');"
mobile,What is .NET Core?,.NET,"The .NET Core platform is a new .NET stack that is optimized for open source development and agile delivery on NuGet.
.NET Core has two major components. It includes a small runtime that is built from the same codebase as the .NET Framework CLR. The .NET Core runtime includes the same GC and JIT (RyuJIT), but doesn’t include features like Application Domains or Code Access Security. The runtime is delivered via NuGet, as part of the ASP.NET Core package.
.NET Core also includes the base class libraries. These libraries are largely the same code as the .NET Framework class libraries, but have been factored (removal of dependencies) to enable to ship a smaller set of libraries. These libraries are shipped as System.* NuGet packages on NuGet.org."
mobile,What is the difference between String and string in C#?,.NET,"string is an alias in C# for System.String. So technically, there is no difference. It's like int vs. System.Int32.
As far as guidelines, it's generally recommended to use string any time you're referring to an object.
string place = ""world"";
Likewise, it's generally recommended to use String if you need to refer specifically to the class.
string greet = String.Format(""Hello {0}!"", place);"
mobile,What is .NET Standard?,.NET,The .NET Standard is a formal specification of .NET APIs that are intended to be available on all .NET implementations.
mobile,What is the .NET Framework?,.NET,"The .NET is a Framework, which is a collection of classes of reusable libraries given by Microsoft to be used in other .NET applications and to develop, build and deploy many types of applications on the Windows platform including the following:
Console Applications
Windows Forms Applications
Windows Presentation Foundation (WPF) Applications
Web Applications
Web Services
Windows Services
Services-oriented applications using Windows Communications Foundation (WCF)
Workflow-enabled applications using Windows Workflow Foundation(WF)"
mobile,What is Boxing and Unboxing?,.NET,"Boxing and Unboxing both are used for type conversion but have some difference:
Boxing - Boxing is the process of converting a value type data type to the object or to any interface data type which is implemented by this value type. When the CLR boxes a value means when CLR is converting a value type to Object Type, it wraps the value inside a System.Object and stores it on the heap area in application domain.
Unboxing - Unboxing is also a process which is used to extract the value type from the object or any implemented interface type. Boxing may be done implicitly, but unboxing have to be explicit by code.
The concept of boxing and unboxing underlines the C# unified view of the type system in which a value of any type can be treated as an object."
mobile,What you understand by Value types and Reference types in .NET? Provide some comparison.,.NET,"In C# data types can be of two types: Value Types and Reference Types. For a value type, the value is the information itself. For a reference type, the value is a reference which may be null or may be a way of navigating to an object containing the information.
Value types - Holds some value not memory addresses. Example - Struct. A variable's value is stored wherever it is decleared. Local variables live on the stack for example, but when declared inside a class as a member it lives on the heap tightly coupled with the class it is declared in.
Advantages: A value type does not need extra garbage collection. It gets garbage collected together with the instance it lives in. Local variables in methods get cleaned up upon method leave.
Drawbacks:

When large set of values are passed to a method the receiving variable actually copies so there are two redundant values in memory.
As classes are missed out.it losses all the oop benifits
Reference type - Holds a memory address of a value not value. Example - Class. Stored on heap
Advantages:

When you pass a reference variable to a method and it changes it indeed changes the original value whereas in value types a copy of the given variable is taken and that's value is changed.
When the size of variable is bigger reference type is good
As classes come as a reference type variables, they give reusability, thus benefitting Object-oriented programming
Drawbacks: More work referencing when allocating and dereferences when reading the value.extra overload for garbage collector"
mobile,What is the difference between .NET Core and Mono?,.NET,"Mono is third party implementation of .Net Framework for Linux/Android/iOs
.Net Core is Microsoft's own implementation for same."
mobile,What are some characteristics of .NET Core?,.NET,"Flexible deployment: Can be included in your app or installed side-by-side user- or machine-wide.
Cross-platform: Runs on Windows, macOS and Linux; can be ported to other OSes. The supported Operating Systems (OS), CPUs and application scenarios will grow over time, provided by Microsoft, other companies, and individuals.
Command-line tools: All product scenarios can be exercised at the command-line.
Compatible: .NET Core is compatible with .NET Framework, Xamarin and Mono, via the .NET Standard Library.
Open source: The .NET Core platform is open source, using MIT and Apache 2 licenses. Documentation is licensed under CC-BY. .NET Core is a .NET Foundation project.
Supported by Microsoft: .NET Core is supported by Microsoft, per .NET Core Support"
mobile,"What is the difference between decimal, float and double in .NET?",.NET,"Precision is the main difference.
Float - 7 digits (32 bit)
Double -15-16 digits (64 bit)
Decimal -28-29 significant digits (128 bit)
As for what to use when:
For values which are ""naturally exact decimals"" it's good to use decimal. This is usually suitable for any concepts invented by humans: financial values are the most obvious example, but there are others too. Consider the score given to divers or ice skaters, for example.
For values which are more artefacts of nature which can't really be measured exactly anyway, float/double are more appropriate. For example, scientific data would usually be represented in this form. Here, the original values won't be ""decimally accurate"" to start with, so it's not important for the expected results to maintain the ""decimal accuracy"". Floating binary point types are much faster to work with than decimals."
mobile,What's the difference between SDK and Runtime in .NET Core?,.NET,"The SDK is all of the stuff that is needed/makes developing a .NET Core application easier, such as the CLI and a compiler.
The runtime is the ""virtual machine"" that hosts/runs the application and abstracts all the interaction with the base operating system."
mobile,Name some CLR services.,.NET,"Assembly Resolver, Assembly Loader, Type Checker, COM marshalled, Debug Manager, Thread Support, IL to Native compiler, Exception Manager, Garbage Collector"
mobile,What is MSIL?,.NET,When we compile our .NET code then it is not directly converted to native/binary code; it is first converted into intermediate code known as MSIL code which is then interpreted by the CLR. MSIL is independent of hardware and the operating system. Cross language relationships are possible since MSIL is the same for all .NET languages. MSIL is further converted into native code.
mobile,What is .NET Standard and why we need to consider it?,.NET,".NET Standard solves the code sharing problem for .NET developers across all platforms by bringing all the APIs that you expect and love across the environments that you need: desktop applications, mobile apps & games, and cloud services:
.NET Standard is a set of APIs that all .NET platforms have to implement. This unifies the .NET platforms and prevents future fragmentation.
.NET Standard 2.0 will be implemented by .NET Framework, .NET Core, and Xamarin. For .NET Core, this will add many of the existing APIs that have been requested.
.NET Standard 2.0 includes a compatibility shim for .NET Framework binaries, significantly increasing the set of libraries that you can reference from your .NET Standard libraries.
.NET Standard will replace Portable Class Libraries (PCLs) as the tooling story for building multi-platform .NET libraries."
mobile,What is CTS?,.NET,"The Common Type System (CTS) standardizes the data types of all programming languages using .NET under the umbrella of .NET to a common data type for easy and smooth communication among these .NET languages.
CTS is designed as a singly rooted object hierarchy with System.Object as the base type from which all other types are derived. CTS supports two different kinds of types:
Value Types: Contain the values that need to be stored directly on the stack or allocated inline in a structure. They can be built-in (standard primitive types), user-defined (defined in source code) or enumerations (sets of enumerated values that are represented by labels but stored as a numeric type).
Reference Types: Store a reference to the value‘s memory address and are allocated on the heap. Reference types can be any of the pointer types, interface types or self-describing types (arrays and class types such as user-defined classes, boxed value types and delegates)."
mobile,What is a .NET application domain?,.NET,"It is an isolation layer provided by the .NET runtime. As such, App domains live with in a process (1 process can have many app domains) and have their own virtual address space.
App domains are useful because:
They are less expensive than full processes
They are multithreaded
You can stop one without killing everything in the process
Segregation of resources/config/etc
Each app domain runs on its own security level"
mobile,What is an unmanaged resoure in .NET?,.NET,"Use that rule of thumb:
If you found it in the Microsoft .NET Framework: it's managed.
If you went poking around MSDN yourself, it's unmanaged.
Anything you've used P/Invoke calls to get outside of the nice comfy world of everything available to you in the .NET Framwork is unmanaged – and you're now responsible for cleaning it up."
mobile,What is CLR?,.NET,The CLR stands for Common Language Runtime and it is an Execution Environment. It works as a layer between Operating Systems and the applications written in .NET languages that conforms to the Common Language Specification (CLS). The main function of Common Language Runtime (CLR) is to convert the Managed Code into native code and then execute the program.
mobile,What is IoC(DI) Container?,.NET,"A Dependency Injection container, sometimes, referred to as DI container or IoC container, is a framework that helps with DI. It
creates and
injects
dependencies for us automatically."
mobile,What is Generic Host in .NET Core?,.NET,"The .NET Generic Host is a feature which sets up some convenient patterns for an application including those for dependency injection (DI), logging, and configuration. It was originally named Web Host and intended for Web scenarios like ASP.NET Core applications but has since been generalized (hence the rename to Generic Host) to support other scenarios, such as Windows services, Linux daemon services, or even a console app.
A host is an object that encapsulates an app’s resources, such as:
Dependency injection (DI)
Logging
Configuration
IHostedService implementations"
mobile,What is ADO.NET?,ADO.NET,"ADO stands for Active Data Object and ADO.NET is a set of .NET libraries for ADO. NET is a collection of managed libraries used by .NET applications for data source communication using a driver or provider:
Enterprise applications handle a large amount of data. This data is primarily stored in relational databases, such as Oracle, SQL Server, and Access and so on. These databases use Structured Query Language (SQL) for retrieval of data.
To access enterprise data from a .NET application, an interface was needed. This interface acts as a bridge between an RDBMS system and a .NET application. ADO.NET is such an interface that is created to connect .NET applications to RDBMS systems.
In the .NET framework, Microsoft introduced a new version of Active X Data Objects (ADO) called ADO.NET. Any .NET application, either Windows based or web based, can interact with the database using a rich set of classes of the ADO.NET library. Data can be accessed from any database using connected or disconnected architecture."
mobile,What is the basic difference between ADO.NET and Entity Framework?,ADO.NET,"ADO.NET Entity Framework is an ORM (object-relational mapping) which creates a higher abstract object model over ADO.NET components. ADO.NET is a layer closer to the database (datatables, datasets and etc...). The main and the only benefit of EF is it auto-generates code for the Model (middle layer), Data Access Layer, and mapping code, thus reducing a lot of development time."
mobile,What is the SqlCommandBuilder?,ADO.NET,"CommandBuilder helps you to generate update, delete, and insert commands on a single database table for a data adapter. Similar to other objects, each data provider has a command builder class. The OleDbCommandBuilder, SqlCommonBuilder, and OdbcCommandBuilder classes represent the CommonBuilder object in the OleDb, Sql, and ODBC data providers."
mobile,What is exactly meaning of disconnected and connected approach in ADO.NET?,ADO.NET,"Disconnected - Make Connection , Fetch Data , Close Connection
Connected - Make Connection , Keep Connection alive , Close Connection when close is called.
The ADO.NET architecture, in which connection must be kept open till the end to retrieve and access data from database is called as connected architecture. Connected architecture is built on the these types - connection, command, datareader

The ADO.NET architecture, in which connection will be kept open only till the data retrieved from database, and later can be accessed even when connection to database is closed is called as disconnected architecture. Disconnected architecture of ADO.net is built on these types - connection, dataadapter, commandbuilder and dataset and dataview."
mobile,What is the DataAdapter object in ADO.NET?,ADO.NET,"A DataAdapter is used to retrieve data from a data source and populate tables within a DataSet. Data Adapters form the bridge between a data source and a dataset. The DataAdapter also resolves changes made to the DataSet back to the data source. The DataAdapter uses the Connection object of the .NET Framework data provider to connect to a data source, and it uses Command objects to retrieve data from and resolve changes to the data source.
A DataAdapter supports mainly the following two methods:
Fill(): The Fill method populates a dataset or a data table object with data from the database. It retrieves rows from the data source using the SELECT statement specified by an associated select command property. The Fill method leaves the connection in the same state as it encountered before populating the data.
Update(): The Update method commits the changes back to the database. It also analyzes the RowState of each record in the DataSet and calls the appropriate INSERT, UPDATE, and DELETE statements."
mobile,How can you define the DataSet structure?,ADO.NET,"A DataSet object falls in disconnected components series. The DataSet consists of a collection of tables, rows, columns and relationships.
DataSet contains a collection of DataTables and the DataTable contains a collection of DataRows, DataRelations, and DataColumns. A DataTable maps to a table in the database."
mobile,What do you understand by DataRelation class?,ADO.NET,The DataRelation is a class of disconnected architecture in the .NET framework. It is found in the System.Data namespace. It represents a relationship between database tables and correlates tables on the basis of matching column.
mobile,What are the ADO.NET components?,ADO.NET,"ADO.NET components categorized in three modes:
disconnected,
common or shared and
the .NET data providers.
The disconnected components build the basic ADO.NET architecture. You can use these components (or classes) with or without data providers. For example, you can use a DataTable object with or without providers and shared or common components are the base classes for data providers. Shared or common components are the base classes for data providers and shared by all data providers. The data provider components are specifically designed to work with different kinds of data sources. For example, ODBC data providers work with ODBC data sources and OleDb data providers work with OLE-DB data sources."
mobile,What is SqlCommand Object?,ADO.NET,"The SqlCommand carries the SQL statement that needs to be executed on the database. SqlCommand carries the command in the CommandText property and this property will be used when the SqlCommand calls any of its execute methods.
The Command Object uses the connection object to execute SQL queries.
The queries can be in the form of Inline text, Stored Procedures or direct Table access.
An important feature of Command object is that it can be used to execute queries and Stored Procedures with Parameters.
If a select query is issued, the result set it returns is usually stored in either a DataSet or a DataReader object.
The three important methods exposed by the SqlCommand object is shown below:
ExecuteScalar
ExecuteNonQuery
ExecuteReader"
mobile,What is Connection Pooling in ADO.NET?,ADO.NET,"ADO.NET uses a technique called connection pooling, which minimizes the cost of repeatedly opening and closing connections.
Connection pooling reuses existing active connections with the same connection string instead of creating new connections when a request is made to the database.
It involves the use of a connection manager that is responsible for maintaining a list, or pool, of available connections for a given connection string. Several pools exist if different connection strings ask for connection pooling."
mobile,Describe when you would use the DataView in ADO.NET.,ADO.NET,"A DataView enables you to create different views of the data stored in a DataTable, a capability that is often used in data binding applications.
Using a DataView, you can expose the data in a table with different sort orders, and you can filter the data by row state or based on a filter expression. A DataView provides a dynamic view of data whose content, ordering, and membership reflect changes to the underlying DataTable as they occur.
This is different from the Select method of the DataTable, which returns a DataRow array from a table per particular filter and/or sort order and whose content reflects changes to the underlying table, but whose membership and ordering remain static. The dynamic capabilities of the DataView make it ideal for data-binding."
mobile,What is ViewData?,ASP.NET,"ViewData contains the key, value pairs as dictionary and this is derived from class  ViewDataDictionary. In action method we are setting the value for viewdata and in view the value will be fetched by typecasting."
mobile,What is the difference between ASP.NET and ASP.NET MVC?,ASP.NET,"ASP.NET, at its most basic level, provides a means for you to provide general HTML markup combined with server side ""controls"" within the event-driven programming model that can be leveraged with VB, C#, and so on. You define the page(s) of a site, drop in the controls, and provide the programmatic plumbing to make it all work.
ASP.NET MVC is an application framework based on the Model-View-Controller architectural pattern. This is what might be considered a ""canned"" framework for a specific way of implementing a web site, with a page acting as the ""controller"" and dispatching requests to the appropriate pages in the application. The idea is to ""partition"" the various elements of the application, eg business rules, presentation rules, and so on.
Think of the former as the ""blank slate"" for implementing a site architecture you've designed more or less from the ground up. MVC provides a mechanism for designing a site around a pre-determined ""pattern"" of application access, if that makes sense. There's more technical detail to it than that, to be sure, but that's the nickel tour for the purposes of the question."
mobile,What is a postback?,ASP.NET,"A postback originates from the client browser. Usually one of the controls on the page will be manipulated by the user (a button clicked or dropdown changed, etc), and this control will initiate a postback. The state of this control, plus all other controls on the page (known as the View State) is Posted Back to the web server."
mobile,What exactly is an application pool? What is its purpose?,ASP.NET,"Application pools allow you to isolate your applications from one another, even if they are running on the same server. This way, if there is an error in one app, it won't take down other applications.
Additionally, applications pools allow you to separate different apps which require different levels of security."
mobile,Explain startup process I ASP.NET Core.,ASP.NET,"Everything starts from Program.cs
public static void Main(string[] args)
{
    BuildWebHost(args).Run();
}
 
public static IWebHost BuildWebHost(string[] args) =>
    WebHost.CreateDefaultBuilder(args)
        .UseStartup<Startup>()
        .Build();
CreateDefaultBuilder extension method will create a default configuration which will look first into appsettings.json files then will look for Environment variables and at the end, it will use command line arguments.
This part will also set up default logger sources (debug and console) and load the settings for logging from appsettings.json.
After the CreateDefaultBuilder finishes, then Startup class is executed. First, the constructor code is executed. After that, services are added to DI container via AddServices method that lives in Startup class. After that, an order of middleware that will handle every incoming request is set up."
mobile,What is ViewState?,ASP.NET,"View State is the method to preserve the Value of the Page and Controls between round trips. It is a Page-Level State Management technique. View State is turned on by default and normally serializes the data in every control on the page regardless of whether it is actually used during a post-back.
A web application is stateless. That means that a new instance of a page is created every time when we make a request to the server to get the page and after the round trip our page has been lost immediately"
mobile,Can ASP.NET Core work with the .NET framework?,ASP.NET,"Yes. This might surprise many, but ASP.NET Core works with .NET framework and this is officially supported by Microsoft.
ASP.NET Core works with:
.NET Core framework
.NET framework"
mobile,What is ASP.NET Core?,ASP.NET,"ASP.NET Core is a brand new cross-platform web framework built with .NET Core framework. It is not an update to existing ASP.NET framework. It is a complete rewrite of the ASP.NET framework. It works with both .NET Core and .NET Framework.
Main characterestics of ASP.NET Core:
DI Container which is quite simple and built-in. You can extend it with other popular DI containers
Built-in and extensible structured logging. You can redirect output to as many sources as you want (file, Azure, AWS, console)
Extensible strongly typed configuration, which can also be used to reload at run-time
Kestrel – new, cross-platform and super fast web server which can stand alone without IIS, Nginx or Apache
New, fully async pipeline. It is easily configured via middleware
ASP.NET All meta package which improves development speed, and enables you to reference all Microsoft packages for ASP.NET Core and it will deploy only those that are being used by your code
There is no web.config. We now use appsettings.json file in combination with other sources of configuration (command line args, environment variables, etc.)
There is no Global._asax – We have _Startup.cs which is used to set up Middleware and services for DI Container."
mobile,Talk about Loggin in ASP.NET Core.,ASP.NET,"Logging is built-in and you get access to structured logs from the ASP.NET Core host itself to your application. With tools like Serilog, you can extend your logging easily and save your logs to file, Azure, Amazon or any other output provider. You can configure verbosity and log levels via configuration (appsettings.json by default), and you can configure log levels by different categories."
mobile,What is Generic Host in .NET Core?,ASP.NET,"The .NET Generic Host is a feature which sets up some convenient patterns for an application including those for dependency injection (DI), logging, and configuration. It was originally named Web Host and intended for Web scenarios like ASP.NET Core applications but has since been generalized (hence the rename to Generic Host) to support other scenarios, such as Windows services, Linux daemon services, or even a console app.
A host is an object that encapsulates an app’s resources, such as:
Dependency injection (DI)
Logging
Configuration
IHostedService implementations"
mobile,How does React work?,React,"React creates a virtual DOM. When state changes in a component it firstly runs a ""diffing"" algorithm, which identifies what has changed in the virtual DOM. The second step is reconciliation, where it updates the DOM with the results of diff."
mobile,What is Context API in React JS?,React,"Context provides a way to pass data through the component tree without having to pass props down manually at every level. Context is designed to share data that can be considered “global” for a tree of React components, such as the current authenticated user, theme, or preferred language. Using context, we can avoid passing props through intermediate elements."
mobile,What are props in React?,React,"Props are inputs to a React component. They are single values or objects containing a set of values that are passed to React Components on creation using a naming convention similar to HTML-tag attributes. i.e, They are data passed down from a parent component to a child component.

The primary purpose of props in React is to provide following component functionality:
Pass custom data to your React component.
Trigger state changes.
Use via this.props.reactProp inside component's render() method.
For example, let us create an element with reactProp property,
 <Element reactProp = ""1"" />
This reactProp (or whatever you came up with) name then becomes a property attached to React's native props object which originally already exists on all components created using React library.
 props.reactProp;"
mobile,What is the use of refs?,React,"Refs provide a way to access DOM nodes or React elements created in the render method. They should be avoided in most cases, however, they can be useful when we need direct access to DOM element or an instance of a component.
There are a few good use cases for refs:
Managing focus, text selection, or media playback.
Triggering imperative animations.
Integrating with third-party DOM libraries.
Refs are created using React.createRef() and attached to React elements via the ref attribute. Refs are commonly assigned to an instance property when a component is constructed so they can be referenced throughout the component.
class MyComponent extends React.Component {
  constructor(props) {
    super(props);
    this.myRef = React.createRef();  }
  render() {
    return <div ref={this.myRef} />;  }
}"
mobile,What are the advantages of ReactJS?,React,"Below are the advantages of ReactJS:
Increases the application’s performance with Virtual DOM
JSX makes code is easy to read and write
It renders both on client and server side
Easy to integrate with other frameworks (Angular, BackboneJS) since it is only a view library
Easy to write UI Test cases and integration with tools such as JEST."
mobile,What are React Hooks?,React,"Hooks are a new addition in React 16.8. They let you use state and other React features without writing a class. With Hooks, you can extract stateful logic from a component so it can be tested independently and reused. Hooks allow you to reuse stateful logic without changing your component hierarchy. This makes it easy to share Hooks among many components or with the community."
mobile,How would you write an inline style in React?,React,"For example:
<div style={{ height: 10 }}>"
mobile,What is React?,React,"React is an open-source JavaScript library created by Facebook for building complex, interactive UIs in web and mobile applications. React’s core purpose is to build UI components; it is often referred to as just the “V” (View) in an “MVC” architecture."
mobile,What are the major features of ReactJS?,React,"The major features of ReactJS are as follows,
It uses VirtualDOM instead RealDOM considering that RealDOM manipulations are expensive.
Supports server-side rendering
Follows Unidirectional data flow or data binding
Uses reusable/composable UI components to develop the view"
mobile,What are the differences between a Class component and Functional component?,React,"Class Components

Class-based Components uses ES6 class syntax. It can make use of the lifecycle methods.
Class components extend from React.Component.
In here you have to use this keyword to access the props and functions that you declare inside the class components.
Functional Components

Functional Components are simpler comparing to class-based functions.
Functional Components mainly focuses on the UI of the application, not on the behavior.
To be more precise these are basically render function in the class component.
Functional Components can have state and mimic lifecycle events using Reach Hooks"
mobile,What are the advantages of using React?,React,"It is easy to know how a component is rendered, you just need to look at the render function.
JSX makes it easy to read the code of your components. It is also really easy to see the layout, or how components are plugged/combined with each other.
You can render React on the server-side. This enables improves SEO and performance.
It is easy to test.
You can use React with any framework (Backbone.js, Angular.js) as it is only a view layer."
mobile,What is the difference between state and props?,React,"The state is a data structure that starts with a default value when a Component mounts. It may be mutated across time, mostly as a result of user events.
Props (short for properties) are a Component's configuration. They are received from above and immutable as far as the Component receiving them is concerned. A Component cannot change its props, but it is responsible for putting together the props of its child Components. Props do not have to just be data - callback functions may be passed in as props."
mobile,What is the difference between a Presentational component and a Container component?,React,"Presentational components are concerned with how things look. They generally receive data and callbacks exclusively via props. These components rarely have their own state, but when they do it generally concerns UI state, as opposed to data state.
Container components are more concerned with how things work. These components provide the data and behavior to presentational or other container components. They call Flux actions and provide these as callbacks to the presentational components. They are also often stateful as they serve as data sources."
mobile,What are refs used for in React?,React,"Refs are an escape hatch which allow you to get direct access to a DOM element or an instance of a component. In order to use them you add a ref attribute to your component whose value is a callback function which will receive the underlying DOM element or the mounted instance of the component as its first argument.
class UnControlledForm extends Component {
  handleSubmit = () => {
    console.log(""Input Value: "", this.input.value)
  }
  render () {
    return (
      <form onSubmit={this.handleSubmit}>
        <input
          type='text'
          ref={(input) => this.input = input} />
        <button type='submit'>Submit</button>
      </form>
    )
  }
}
Above notice that our input field has a ref attribute whose value is a function. That function receives the actual DOM element of input which we then put on the instance in order to have access to it inside of the handleSubmit function.
It’s often misconstrued that you need to use a class component in order to use refs, but refs can also be used with functional components by leveraging closures in JavaScript.
function CustomForm ({handleSubmit}) {
  let inputElement
  return (
    <form onSubmit={() => handleSubmit(inputElement.value)}>
      <input
        type='text'
        ref={(input) => inputElement = input} />
      <button type='submit'>Submit</button>
    </form>
  )
}"
mobile,What's the difference between a Controlled component and an Uncontrolled one in React?,React,"This relates to stateful DOM components (form elements) and the React docs explain the difference:
A Controlled Component is one that takes its current value through props and notifies changes through callbacks like onChange. A parent component ""controls"" it by handling the callback and managing its own state and passing the new values as props to the controlled component. You could also call this a ""dumb component"".
A Uncontrolled Component is one that stores its own state internally, and you query the DOM using a ref to find its current value when you need it. This is a bit more like traditional HTML.
Most native React form components support both controlled and uncontrolled usage:
// Controlled:
<input type=""text"" value={value} onChange={handleChange} />

// Uncontrolled:
<input type=""text"" defaultValue=""foo"" ref={inputRef} />
// Use `inputRef.current.value` to read the current value of <input>
In most (or all) cases you should use controlled components."
mobile,What are Controlled coomponents in ReactJS?,React,"A Controlled Component is one that takes its current value through props and notifies changes through callbacks like onChange. A parent component ""controls"" it by handling the callback and managing its own state and passing the new values as props to the controlled component. You could also call this a ""dumb component"".
// Controlled:
<input type=""text"" value={value} onChange={handleChange} />"
mobile,What is state in React?,React,"State of a component is an object that holds some information that may change over the lifetime of the component. We should always try to make our state as simple as possible and minimize the number of stateful components.
Consider:
class User extends React.Component {
   constructor(props) {
      super(props);

      this.state = {
         message: ""Welcome to React world"",
      }
   }
   render() {
      return (
         <div>
            <h1>{this.state.message}</h1>
         </div>
      );
   }
}"
mobile,What does it mean for a component to be mounted in React?,React,It has a corresponding element created in the DOM and is connected to that.
mobile,What are Fragments in React?,React,"It's common pattern in React which is used for a component to return multiple elements. Fragments let you group a list of children without adding extra nodes to the DOM.
render() {
  return (
    <React.Fragment>
      <ChildA />
      <ChildB />
      <ChildC />
    </React.Fragment>
  );
}
There is also a shorter syntax:
render() {
    return (
      <>
         <ChildA />
         <ChildB />
         <ChildC />
      </>
    );
  }"
mobile,When rendering a list what is a key and what is it's purpose?,React,"Keys help React identify which items have changed, are added, or are removed. Keys should be given to the elements inside the array to give the elements a stable identity. The best way to pick a key is to use a string that uniquely identifies a list item among its siblings.
render () {
  return (
    <ul>
      {this.state.todoItems.map(({task, uid}) => {
        return <li key={uid}>{task}</li>
      })}
    </ul>
  )
}
Most often you would use IDs from your data as keys. When you don't have stable IDs for rendered items, you may use the item index as a key as a last resort. It is not recommend to use indexes for keys if the items can reorder, as that would be slow."
mobile,How to create refs in React?,React,"Refs are created using React.createRef() method and attached to React elements via the ref attribute. In order to use refs throughout the component, just assign the ref to the instance property with in constructor.
class MyComponent extends React.Component {
  constructor(props) {
    super(props);
    this.myRef = React.createRef();
  }
  render() {
    return <div ref={this.myRef} />;
  }
}
And:
class UserForm extends Component {
  handleSubmit = () => {
    console.log(""Input Value is: "", this.input.value)
  }
  render () {
    return (
      <form onSubmit={this.handleSubmit}>
        <input
          type='text'
          ref={(input) => this.input = input} /> // Access DOM input in handle submit
        <button type='submit'>Submit</button>
      </form>
    )
  }
}
We can also use it in functional components with the help of closures."
mobile,"Explain what is the use of useState(0) there:
...
const [count, setCounter] = useState(0);
const [moreStuff, setMoreStuff] = useState(...);
...

const setCount = () => {
    setCounter(count + 1);
    setMoreStuff(...);
    ...
};",React,"useState is one of build-in react hooks. useState(0) returns a tuple where the first parameter count is the current state of the counter and setCounter is the method that will allow us to update the counter's state.
We can use the setCounter method to update the state of count anywhere - In this case we are using it inside of the setCount function where we can do more things; the idea with hooks is that we are able to keep our code more functional and avoid class based components if not desired/needed."
mobile,What are Stateful components in React?,React,"If the behaviour of a component is dependent on the state of the component then it can be termed as stateful component. These Stateful components are always class components and have a state that gets initialized in the constructor.
class App extends Component {
 constructor(props) {
  super(props);
  this.state = { count: 0 };
 }

 render() {
    // omitted for brevity
  }
}"
mobile,What is JSX?,React,"JSX is a syntax notation for JavaScript XML (XML-like syntax extension to ECMAScript). It stands for JavaScript XML. It provides expressiveness of JavaScript along with HTML like template syntax. For example, the below text inside h1 tag return as javascript function to the render function,
   render(){
    	return(
         <div>
            <h1> Welcome to React world!!</h1>
         </div>
    	);
     }"
mobile,What are the limitations of React?,React,"React is just a view library, not a full-blown framework
There is a learning curve for beginners who are new to web development.
Integrating React.js into a traditional MVC framework requires some additional configuration
The code complexity increases with inline templating and JSX.
Too many smaller components leading to over-engineering or boilerplate"
mobile,What are Stateless components in React?,React,"If the behaviour is independent of its state then it can be a stateless component. You can use either a function or a class for creating stateless components. But unless you need to use a lifecycle hook in your components, you should go for stateless functional components.
Stateful/Container/Smart component:
class Main extends Component {
 constructor() {
   super()
   this.state = {
     books: []
   }
 }
 render() {
   <BooksList books={this.state.books} />
 }
}
Stateless/Presentational/Dumb component:

const BooksList = ({books}) => {
 return (
   <ul>
     {books.map(book => {
       return <li>book</li>
     })}
   </ul>
 )
}
There are a lot of benefits if you decide to use stateless functional components here; they are:
easy to write, understand, and test, and
you can avoid the this keyword altogether."
mobile,How is React different from AngularJS(1.x)?,React,"For example, AngularJS (1.x) approaches building an application by extending HTML markup and injecting various constructs (e.g. Directives, Controllers, Services) at runtime. As a result, AngularJS is very opinionated about the greater architecture of your application — these abstractions are certainly useful in some cases, but they come at the cost of flexibility.
By contrast, React focuses exclusively on the creation of components, and has few (if any) opinions about an application’s architecture. This allows a developer an incredible amount of flexibility in choosing the architecture they deem “best” — though it also places the responsibility of choosing (or building) those parts on the developer."
mobile,What is the difference between state and props?,React,"Both props and state are plain JavaScript objects. While both of them hold information that influences the output of render, they are different in their functionality with respect to component. i.e,
Props get passed to the component similar to function parameters
State is managed within the component similar to variables declared within a function."
mobile,What are two types of components in ReactJS?,React,"There are two possible ways to create ReactJS Components.
Functional components: This is the simplest way to create ReactJS components. It accepts props as an Object and returns ReactJS elements. We call it as “functional” because those are pure JavaScript functions.
	function Greeting(props) {
   	   return <h1> Hello, {props.message}</h1>_x000B_
	}
Class components: You can also use Es6 class to define component. The above functional component can be written as below,
      class Greeting extends React.Component {
  	    render() {
    		    return <h1>Hello, {this.props.message}</h1>;
  	        }
	    }"
mobile,What is the purpose of callback function as an argument of setState?,React,"The callback function is invoked when setState finished and the component gets rendered. Since setState is asynchronous the callback function is used for any post action.
Note: It is recommended to use lifecycle method rather this callback function.
setState({name: 'sudheer'}, () => console.log('The name has updated and component re-rendered'));"
mobile,What are portals in React and when do we need them?,React,"Portals provide a first-class way to render children into a DOM node that exists outside the DOM hierarchy of the parent component.
Sometimes it’s useful to insert a child into a different location in the DOM:
render() {
  // React does *not* create a new div. It renders the children into `domNode`.
  // `domNode` is any valid DOM node, regardless of its location in the DOM.
  return ReactDOM.createPortal(
    this.props.children,
    domNode  );
}
A typical use case for portals is when a parent component has an overflow: hidden or z-index style, but you need the child to visually “break out” of its container."
mobile,What are advantages of using React Hooks?,React,"Primarily, hooks in general enable the extraction and reuse of stateful logic that is common across multiple components without the burden of higher order components or render props. Hooks allow to easily manipulate the state of our functional component without needing to convert them into class components.
Hooks don’t work inside classes (because they let you use React without classes). By using them, we can totally avoid using lifecycle methods, such as componentDidMount, componentDidUpdate, componentWillUnmount. Instead, we will use built-in hooks like useEffect ."
mobile,What is the difference between Component and Container in Redux?,React,"Component is part of the React API. A Component is a class or function that describes part of a React UI.
Container is an informal term for a React component that is connected to a redux store. Containers receive Redux state updates and dispatch actions, and they usually don't render DOM elements; they delegate rendering to presentational child components."
mobile,What are inline conditional expression in ReactJS?,React,"You can use either if statements or ternary expressions which are available from JS to conditionally render expressions. Apart from these approaches, you can also embed any expressions in JSX by wrapping them in curly braces and then followed by JS logical operator(&&).
if(this.state.mode === 'view') {
  return (
      <button onClick={this.handleEdit}>
        Edit
      </button>
  );
} else {
  return (
      <button onClick={this.handleSave}>
        Save
      </button>
  );
}
// or 
 {
   view
  ? null
  : (
    <p>
      <input
        onChange={this.handleChange}
        value={this.state.inputText} />
    </p>
  )
}"
mobile,What is Reconciliation in ReactJS?,React,"When a component’s props or state change, React decides whether an actual DOM update is necessary by comparing the newly returned element with the previously rendered one. When they are not equal, React will update the DOM. This process is called reconciliation."
mobile,What is the purpose of using super constructor with props argument in React?,React,"A child class constructor cannot make use of this reference until super() method has been called. The same applies for ES6 sub-classes as well. The main reason of passing props parameter to super() call is to access this.props in your child constructors.
Passing props:

class MyComponent extends React.Component {
    constructor(props) {
        super(props);
        console.log(this.props);  // Prints { name: 'sudheer',age: 30 }
    }
}
Not passing props:

class MyComponent extends React.Component {
    constructor(props) {
        super();
        console.log(this.props); // Prints undefined
        // But Props parameter is still available
        console.log(props); // Prints { name: 'sudheer',age: 30 }
    }

    render() {
        // No difference outside constructor
        console.log(this.props) // Prints { name: 'sudheer',age: 30 }
    }
}
The above code snippets reveals that this.props behavior is different only with in the constructor. It would be same outside the constructor."
mobile,What happens when you all setState?,React,"The first thing React will do when setState is called is merge the object you passed into setState into the current state of the component. This will kick off a process called reconciliation. The end goal of reconciliation is to, in the most efficient way possible, update the UI based on this new state.
To do this, React will construct a new tree of React elements (which you can think of as an object representation of your UI). Once it has this tree, in order to figure out how the UI should change in response to the new state, React will diff this new tree against the previous element tree.
By doing this, React will then know the exact changes which occurred, and by knowing exactly what changes occurred, will able to minimize its footprint on the UI by only making updates where absolutely necessary."
mobile,What is the difference between Element and Component in ReactJS?,React,"An element is a plain object describing what you want to appear on the screen in terms of the DOM nodes or other components. Elements can contain other elements in their props. Creating a React element is cheap. Once an element is created, it is never mutated. The object representation of React element would be as follows,
const element = React.createElement(
  'div',
  {id: 'login-btn'},
  'Login'
)
The above createElement returns as object as below,
{
  type: 'div',
  props: {
    children: 'Login',
    id: 'login-btn'
  }
}
And finally it renders to the DOM using ReactDOM.render as below,
<div id='login-btn'>Login</div>
Whereas a component can be declared in several different ways. It can be a class with a render() method. Alternatively, in simple cases, it can be defined as a function. In either case, it takes props as an input, and returns an element tree as the output. JSX transpiled as createElement at the end.
function Button ({ onLogin }) {
  return React.createElement(
    'div',
    {id: 'login-btn', onClick: onLogin},
    'Login'
  )
}"
mobile,What are Higher-Order Components(HOC) in React?,React,"A higher-order component (HOC) is a function that takes a component and returns a new component. Basically, it’s a pattern that is derived from React’s compositional nature We call them as “pure’ components” because they can accept any dynamically provided child component but they won’t modify or copy any behavior from their input components.
const EnhancedComponent = higherOrderComponent(WrappedComponent);
HOC can be used for many use cases as below,
Code reuse, logic and bootstrap abstraction
Render High jacking
State abstraction and manipulation
Props manipulation"
mobile,How to call loading function with React useEffect only once?,React,"If you only want to run the function given to useEffect after the initial render, you can give it an empty array [] as the second argument.
For example:
function MyComponent(){
    useEffect(() => {
        loadDataOnlyOnce();
    }, []);

    return <div> { /*...*/} </div>;
}"
mobile,How to access DOM elements in React?,React,"One of the useful application of the useRef() hook is to access DOM elements. This is performed in 3 steps:
Define the reference to access the element const elementRef = useRef();
Assign the reference to ref attribute of the element: <div ref={elementRef}></div>;
After mounting, elementRef.current points to the DOM element.
Consider:
import { useRef, useEffect } from 'react';

function AccessingElement() {

  const elementRef = useRef();

  useEffect(() => {
    const divElement = elementRef.current;
    console.log(divElement); // logs <div>I'm an element</div>
  }, []);

  return (
    <div ref={elementRef}>
      I'm an element
    </div>
  );
}"
mobile,What is CoreData?,iOS,"Core Data is an object graph management framework. It manages a potentially very large graph of object instances, allowing an app to work with a graph that would not entirely fit into memory by faulting objects in and out of memory as necessary. Core Data also manages constraints on properties and relationships and maintains reference integrity (e.g. keeping forward and backward links consistent when objects are added/removed to/from a relationship). Core Data is thus an ideal framework for building the ""model"" component of an MVC architecture.
To implement its graph management, Core Data happens to use SQLite as a disk store. It could have been implemented using a different relational database or even a non-relational database such as CouchDB. Core Data isn't so much a database engine as it is an API that abstracts over the actual data store. You can tell Core Data to save as an sqlite database, a plist, a binary file, or even a custom data store type."
mobile,Explain what is NSUserDefaults.,iOS,"NSUserDefaults is the easiest way to store data without a database using key-value pair. This approach is the ideal way to store small amounts of data. In most cases, NSUserDefaults is best used to save user’s settings and data that is not critical. The following types are supported by NSUserDefaults:
NSString
NSNumber
NSDate
NSDictionary
NSData
Pros

Relatively easy to store and retrieve data
Perfect for storing small size data (example: User’s Settings)
Easy to learn and implement
Cons

Not ideal to store large amount of data
Performance will decrease when storing large amount of data
Not ideal to store sensitive data"
mobile,"On a UITableViewCell constructor:
- (id)initWithStyle:(UITableViewCellStyle)style reuseIdentifier:(NSString *)reuseIdentifier
What is the reuseIdentifier used for?",iOS,"The reuseIdentifier is used to indicate that a cell can be re-used in a UITableView. For example when the cell looks the same, but has different content. The UITableView will maintain an internal cache of UITableViewCell’s with the reuseIdentifier and allow them to be re-used when dequeueReusableCellWithIdentifier: is called. By re-using table cell’s the scroll performance of the tableview is better because new views do not need to be created."
mobile,What is the difference between viewDidLoad and viewDidAppear?,iOS,"viewDidLoad is called when the view is loaded, whether from a Xib file, storyboard or programmatically created in loadView. viewDidAppear is called every time the view is presented on the device. Which to use depends on the use case for your data. If the data is fairly static and not likely to change then it can be loaded in viewDidLoad and cached. However if the data changes regularly then using viewDidAppear to load it is better. In both situations, the data should be loaded asynchronously on a background thread to avoid blocking the UI."
mobile,"What's your preference when writing UI's? Xib files, Storyboards or programmatic UIView?",iOS,"Storyboard's and Xib's are great for quickly producing UI's that match a design spec. They are also really easy for product managers to visually see how far along a screen is.
Storyboard's are also great at representing a flow through an application and allowing a high-level visualization of an entire application.
Storyboard's drawbacks are that in a team environment they are difficult to work on collaboratively because they're a single file and merge's become difficult to manage.
Storyboards and Xib files can also suffer from duplication and become difficult to update. For example if all button's need to look identical and suddenly need a color change, then it can be a long/difficult process to do this across storyboards and xibs.
Programmatically constructing UIView's can be verbose and tedious, but it can allow for greater control and also easier separation and sharing of code. They can also be more easily unit tested.
Most developers will propose a combination of all 3 where it makes sense to share code, then re-usable UIViews or Xib files."
mobile,What are different ways that you can specify the layout of elements in a UIView?,iOS,"Here are a few common ways to specify the layout of elements in a UIView:
Using InterfaceBuilder, you can add a XIB file to your project, layout elements within it, and then load the XIB in your application code (either automatically, based on naming conventions, or manually). Also, using InterfaceBuilder you can create a storyboard for your application.
You can your own code to use NSLayoutConstraints to have elements in a view arranged by Auto Layout.
You can create CGRects describing the exact coordinates for each element and pass them to UIView’s - (id)initWithFrame:(CGRect)frame method."
mobile,Mention the difference between RelativeLayout and LinearLayout.,Android,"Linear Layout — Arranges elements either vertically or horizontally. i.e. in a row or column.
Relative Layout — Arranges elements relative to parent or other elements."
mobile,What is the difference between Bitmap and Drawable in Android?,Android,"A Bitmap is a representation of a bitmap image (something like java.awt.Image).
A Drawable is an abstraction of ""something that can be drawn"". It could be a Bitmap (wrapped up as a BitmapDrawable), but it could also be a solid color, a collection of other Drawable objects, or any number of other structures."
mobile,What is a difference between Spannable and String?,Android,"A Spannable allows to attach formatting information like bold, italic, ... to sub-sequences (""spans"", thus the name) of the characters. It can be used whenever you want to represent rich text."
mobile,What is an Activity?,Android,"An Activity provides the window in which the app draws its UI.
This window typically fills the screen, but may be smaller than the screen and float on top of other windows. Generally, one activity implements one screen in an app. For instance, one of an app’s activities may implement a Preferences screen, while another activity implements a Select Photo screen."
mobile,Why is it recommended to use only the default constructor to create a Fragment?,Android,"In short, Fragments need to have a no-args constructor for the Android system to instantiate them. Your Fragment subclasses need a public empty constructor as this is what's being called by the framework.
It is used in the case when device has to restore the state of a fragment. No data will be passed and a default fragment will be created and then the state will be restored. Since the system has no way to know what you passed in your constructor or your newInstance, default constructor will be used and saved bundle should be passed via onCreate after the fragment is actually instantiated with the default constructor."
mobile,How to persist data in an Android app?,Android,"There are basically four different ways to store data in an Android app:
Shared Preferences - to save primitive data in key-value pairs
Internal Storage - you need to store data to the device filesystem, but you do not want any other app (even the user) to read this data
External Storage - you might want the user to view the files and data saved by your app
SQLite database"
mobile,Explain briefly all the Android application components.,Android,"App components are the essential building blocks of an Android app. Each component is an entry point through which the system or a user can enter your app.
There are four different types of app components:
Activities - An activity is the entry point for interacting with the user. It represents a single screen with a user interface.
Services - A service is a general-purpose entry point for keeping an app running in the background for all kinds of reasons. It is a component that runs in the background to perform long-running operations or to perform work for remote processes.
Broadcast receivers - A broadcast receiver is a component that enables the system to deliver events to the app outside of a regular user flow, allowing the app to respond to system-wide broadcast announcements.
Content providers - A content provider manages a shared set of app data that you can store in the file system, in a SQLite database, on the web, or on any other persistent storage location that your app can access."
mobile,"How do I pass data between Activities in Android application? I have a scenario where, after logging in through a login page, there will be a sign-out button on each activity. Can you guide me on how to keep session id available to all activities?",Android,"The easiest way to do this would be to pass the session id to the signout activity in the Intent you're using to start the activity:
Intent intent = new Intent(getBaseContext(), SignoutActivity.class);
intent.putExtra(""EXTRA_SESSION_ID"", sessionId);
startActivity(intent);
Access that intent on next activity:
String sessionId = getIntent().getStringExtra(""EXTRA_SESSION_ID"");"
mobile,What is Dalvik?,Android,"Dalvik is a Just In Time (JIT) compiler.
By the term JIT, we mean to say that whenever you run your app in your mobile device then that part of your code that is needed for execution of your app will only be compiled at that moment and rest of the code will be compiled in the future when needed. The JIT or Just In Time compiles only a part of your code and it has a smaller memory footprint and due to this, it uses very less physical space on your device."
mobile,Explain activity lifecycle.,Android,"As a user navigates through, out of, and back to your app, the Activity instances in your app transition through different states in their lifecycle.
To navigate transitions between stages of the activity lifecycle, the Activity class provides a core set of six callbacks: onCreate(), onStart(), onResume(), onPause(), onStop(), and onDestroy(). The system invokes each of these callbacks as an activity enters a new state."
mobile,What is an AsyncTask?,Android,"AsyncTask is one of the easiest ways to implement parallelism in Android without having to deal with more complex methods like Threads. Though it offers a basic level of parallelism with the UI thread, it should not be used for longer operations (of, say, not more than 2 seconds).
AsyncTask has four methods
onPreExecute()
doInBackground()
onProgressUpdate()
onPostExecute()
where doInBackground() is the most important as it is where background computations are performed."
mobile,Explain the build process in Android.,Android,"First step involves compiling the resources folder (/res) using the aapt (android asset packaging tool) tool. These are compiled to a single class file called R.java. This is a class that just contains constants.
Second step involves the java source code being compiled to .class files by javac, and then the class files are converted to Dalvik bytecode by the “dx” tool, which is included in the sdk ‘tools’. The output is classes.dex.
The final step involves the android apkbuilder which takes all the input and builds the apk (android packaging key) file."
mobile,What is ADB and what is it used for?,Android,"ADB is the acronym for Android Debug Bridge, which is part of the Android SDK (Software Development Kit). It uses a client-server-model (i.e. adbd, the ADB daemon, is running on the device and can be connected to), and in most cases is used via an USB connection. It is also possible to use it via WiFi (wireless adb).
There's nothing you need to install on your Android device, as the ADB daemon (adbd) is already integrated into the Android OS. It is usually accessed via a command line interface from the PC, where either the full Android SDK is installed (several 30 MB download archive currently), or a massively stripped-down version for ""non-developers"", sometimes referred to as ""Mini ADB"" or ""ADB essentials"" (for Linux, this is only the adb executable; for Windows it's adb.exe plus two or three .dll files)."
mobile,What's the difference between onCreate() and onStart()?,Android,"The onCreate() method is called once during the Activity lifecycle, either when the application starts, or when the Activity has been destroyed and then recreated, for example during a configuration change.
The onStart() method is called whenever the Activity becomes visible to the user, typically after onCreate() or onRestart()."
mobile,In what situation should one use RecyclerView over ListView?,Android,"RecyclerView was created as a ListView improvement, so yes, you can create an attached list with ListView control, but using RecyclerView is easier as it:
Reuses cells while scrolling up/down - this is possible with implementing View Holder in the ListView adapter, but it was an optional thing, while in the RecycleView it's the default way of writing adapter.
Decouples list from its container - so you can put list items easily at run time in the different containers (linearLayout, gridLayout) with setting LayoutManager.
To conclude, RecyclerView is a more flexible control for handling ""list data"" that follows patterns of delegation of concerns and leaves for itself only one task - recycling items."
mobile,What is View Group? How are they different from Views?,Android,"View: View objects are the basic building blocks of User Interface(UI) elements in Android. View is a simple rectangle box which responds to the user’s actions. Examples are EditText, Button, CheckBox etc. View refers to the android.view.View class, which is the base class of all UI classes.
ViewGroup: ViewGroup is the invisible container. It holds View and ViewGroup. For example, LinearLayout is the ViewGroup that contains Button (View), and other Layouts also. ViewGroup is the base class for Layouts."
mobile,How can I get the context in a Fragment?,Android,"You can use getActivity(), which returns the activity associated with a fragment. The activity is a context (since Activity extends Context). You can also override the onAttach() method of fragment:
public static class DummySectionFragment extends Fragment{
...
    @Override
    public void onAttach(Activity activity) {
        super.onAttach(activity);
        DBHelper = new DatabaseHelper(activity);
    }
}"
mobile,What is Armv7?,Android,"There are 3 CPU architectures in Android:
ARMv7 is the most common as it is optimised for battery consumption.
ARM64 is an evolved version of that that supports 64-bit processing for more powerful computing.
ARMx86, is the least used for these three, since it is not battery friendly. It is more powerful than the other two."
mobile,What is the Dalvik Virtual Machine?,Android,"The Dalvik Virtual Machine (DVM) is an android virtual machine optimized for mobile devices. It optimizes the virtual machine for memory, battery life and performance.
The Dex compiler converts the class files into the .dex file that run on the Dalvik VM. Multiple class files are converted into one dex file."
mobile,How does the OutOfMemory happens?,Android,"Out of memory error is very common error when you are developing for a application that deals with multiple images sets or large bitmaps or some Animation stuff. In Android, every application runs in a Linux Process. Each Linux Process has a Virtual Machine (Dalvik Virtual Machine) running inside it. There is a limit on the memory a process can demand and it is different for different devices and also differs for phones and tablets. When some process demands a higher memory than its limit it causes a error i.e Out of memory error.
There are number of reasons why we get a Out of memory errors. Some of those are:
You are doing some operation that continuously demands a lot of memory and at some point it goes beyond the max heap memory limit of a process.
You are leaking some memory i.e you didn’t make the previous objects you allocated eligible for Garbage Collection (GC). This is called Memory leak.
You are dealing with large bitmaps and loading all of them at run time. You have to deal very carefully with large bitmaps by loading the size that you need not the whole bitmap at once and then do scaling."
mobile,What is an Intent in Android?,Android,"An Intent is basically a message that is passed between components (such as Activities, Services, Broadcast Receivers, and Content Providers).So, it is almost equivalent to parameters passed to API calls. The fundamental differences between API calls and invoking components via intents are:
API calls are synchronous while intent-based invocations are asynchronous.
API calls are compile-time binding while intent-based calls are run-time binding.
To listen for an broadcast intent (like the phone ringing, or an SMS is received), you implement a broadcast receiver, which will be passed the intent. To declare that you can handle another's app intent like ""take picture"", you declare an intent filter in your app's manifest file.
If you want to fire off an intent to do something, like pop up the dialer, you fire off an intent saying you will.
An Intent provides a facility for performing late runtime binding between the code in different applications."
mobile,Tell about Constraint Layout.,Android,"ConstraintLayout allows you to create large and complex layouts with a flat view hierarchy (no nested view groups). It's similar to RelativeLayout in that all views are laid out according to relationships between sibling views and the parent layout, but it's more flexible than RelativeLayout and easier to use with Android Studio's Layout Editor.
Intention of ConstraintLayout is to optimize and flatten the view hierarchy of your layouts by applying some rules to each view to avoid nesting."
mobile,What is a ContentProvider and what is it typically used for?,Android,"A content provider manages access to a central repository of data. A provider is part of an Android application, which often provides its own UI for working with the data. However, content providers are primarily intended to be used by other applications, which access the provider using a provider client object.
Typically you work with content providers in one of two scenarios;
you may want to implement code to access an existing content provider in another application, or
you may want to create a new content provider in your application to share data with other applications."
mobile,What types of Context do you know?,Android,"The are mainly two types of context:
Application Context: It is an instance that is the singleton and can be accessed in activity via getApplicationContext(). This context is tied to the lifecycle of an application. The application context can be used where you need a context whose lifecycle is separate from the current context or when you are passing a context beyond the scope of activity.
Activity Context: This context is tied to the lifecycle of an activity. The activity context should be used when you are passing the context in the scope of an activity or you need the context whose lifecycle is attached to the current context."
mobile,Explain Android notification system.,Android,"A notification is a message that Android displays outside your app's UI to provide the user with reminders, communication from other people, or other timely information from your app. Users can tap the notification to open your app or take an action directly from the notification.
Notifications appear to users in different locations and formats, such as an icon in the status bar, a more detailed entry in the notification drawer, as a badge on the app's icon, and on paired wearables automatically. Beginning with Android 5.0, notifications can appear on the lock screen.
Starting in Android 8.0 (API level 26), all notifications must be assigned to a channel or it will not appear. By categorizing notifications into channels, users can disable specific notification channels for your app (instead of disabling all your notifications), and users can control the visual and auditory options for each channel—all from the Android system settings."
mobile,What is the most appropriate way to store user settings in Android application?,Android,"In general SharedPreferences are your best bet for storing preferences, so in general I'd recommend that approach for saving application and user settings.
The only area of concern here is what you're saving. Passwords are always a tricky thing to store, and I'd be particularly wary of storing them as clear text. The Android architecture is such that your application's SharedPreferences are sandboxed to prevent other applications from being able to access the values so there's some security there, but physical access to a phone could potentially allow access to the values."
mobile,What is Context on Android?,Android,"The documentation itself provides a rather straightforward explanation: The Context class is an Interface to global information about an application environment.
We may assume a Context is a handle to the system; it provides services like resolving resources, obtaining access to databases and preferences, and so on. An Android app has activities. Context is like a handle to the environment your application is currently running in. The activity object inherits the Context object."
mobile,Is it possible to implement the Model-View-Controller pattern in Java for Android?,Android,"In Android you don't have MVC, but you have the following:
You define your user interface in various XML files by resolution, hardware, etc.
You define your resources in various XML files by locale, etc.
You extend clases like ListActivity, TabActivity and make use of the XML file by inflaters.
You can create as many classes as you wish for your business logic.
A lot of Utils have been already written for you - DatabaseUtils, Html."
mobile,What are native apps?,React Native,"Native mobile apps are the most common type of app.
They are built for specific platforms and are written in languages that the platform accepts. For example, Swift and Objective-C for native iOS apps and Java or Kotlin for native Android apps.
Native apps are also built using the specific Integrated Development Environment (IDE) for the selected operating systems"
mobile,List some benefits of using React Native for building mobile apps.,React Native,"Some benefits of React Native are:
Known for Optimal Performance
Can Reuse the Codes and Pre-Developed Components
Large Community of Developers
Advantage of Live and Hot Reloading
Cost Effective Solution
Offers Simple User Interface
Support for Third-Party Plugins
Modular Architecture
Providing Handy Solutions and Libraries"
mobile,Why do we use curly brace while importing some library?,React Native,"Curly braces are used to import small pieces of library. In above example we just want to make use of Text and StyleSheet component from react-native, so they are put in curly braces."
mobile,What are the advantages of hybrid apps over native apps?,React Native,"Works across multiple platforms.
Unified development.
Faster build and lower cost of development.
Easier to make changes and update."
mobile,What are hybrid apps?,React Native,"Hybrid mobile apps are applications that are installed on a device, just like any other app.
Hybrid apps are deployed in a native container that uses a mobile WebView object. When the app is used, this object displays web content thanks to the use of web technologies (CSS, JavaScript, HTML)."
mobile,What is React Native?,React Native,"React Native is a mobile app development framework that enables the development of multi-platform Android and iOS apps using native UI elements.
It is based on the JavaScriptCore runtime and Babel transformers. With this setup react native supports new JavaScript (ES6+) features, e.g. arrow functions, async/await etc.
This famous framework for mobile app development started in the summer of 2013 as Facebook’s internal hackathon project.
Its first public preview was released in January of 2015 at Reactjs Conference and in March of 2015, Facebook made React Native open and available on GitHub."
mobile,How do you dismiss the keyboard in react native?,React Native,"Using Keyboard.dismiss()

import { Keyboard } from 'react-native'

// Hiding the keyboard
Keyboard.dismiss()"
mobile,What is JSX?,React Native,"JSX is an XML/HTML-like syntax used by React that extends ECMAScript so that XML/HTML-like text can co-exist with JavaScript/React code.
The syntax is intended to be used by preprocessors (i.e., transpilers like Babel) to transform HTML-like text found in JavaScript files into standard JavaScript objects that a JavaScript engine will parse.
const nav = (
    <ul id=""nav"">
      <li><a href=""#"">Home</a></li>
      <li><a href=""#"">About</a></li>
      <li><a href=""#"">Clients</a></li>
      <li><a href=""#"">Contact Us</a></li>
    </ul>
);"
mobile,Tell us some options of storing persisting data in a react native app?,React Native,"Some popular options are:
Async Storage (""built-in"" to React Native), SQLite, Realm, Firebase, MongoDB"
mobile,"Will this piece of code work? <View>
  <Text>Hey there!</Text>
  <Text style={{ fontsize: 40 }} >Example of inline style</Text>;
</View>",React Native,"No. An error will be thrown as Text strings must be rendered within Text component. Because here semi-colon in third line will be treated as text, and in React native all texts needs to be rendered inside Text tag."
mobile,What are the advantages of native apps over hybrid apps?,React Native,"They work efficiently as they are built for that specific platforms
Native apps are responsive on all the platform-specific devices
They are very fast and the best in the app performance
Native apps better integrate with mobile hardware
They have interactive and intuitive User Interface (UI) and User Experience (UX) as per the user expectations based on specific platforms
Some of the Native mobile apps work even without the Internet connection
Native apps are secured and reliable
They can easily access or utilize the other device-specific capabilities like GPS, Camera, Contacts, etc."
mobile,What are Refs used for in React Native?,React Native,Refs provide you direct access to a DOM element or a components instance.
mobile,What are the types of data that control a component?,React Native,"There are two types of data that control a component: props and state.
props are set by the parent and they are fixed throughout the lifetime of a component. For data that is going to change, we have to use state."
mobile,What does the Gesture Responder System do?,React Native,The gesture responder system manages the lifecycle of gestures in an app.
mobile,What determines the size of a component and what are the ways?,React Native,"The height and width determine the size of component on the screen.
Two different ways to set height and width. - Fixed Dimensions - Flex Dimensions"
mobile,What are some ways of styling a react native component?,React Native,"We can use: Inline styling, StyleSheet, Styled Components"
mobile,What are components?,React Native,"Components are the building blocks of any React application.
Components let you split the UI into independent, reusable pieces, and think about each piece in isolation.
React Native provides a number of built-in components. Some are:- - Basic Components - User Interface - List Views - iOS-specific - Android-specific"
mobile,When would you use ScrollView over FlatList or vice-versa?,React Native,"Do you need to render a list of similar items from an array or the data is very big? Use FlatList
Do you need to render generic content in a scrollable container and the data is small? Use ScrollView"
mobile,How is React Native different from ReactJs?,React Native,"ReactJS React has as its main focus Web Development.

React’s virtual DOM is faster than the conventional full refresh model, since the virtual DOM refreshes only parts of the page.
We use div, p, span, etc. HTML tags to build the UI of the web application.
You can reuse code components in React, saving you a lot of time. (You can in React Native too.)
As a business: The rendering of your pages completely, from the server to the browser will improve the SEO of your web app.
It improves the debugging speed making your developer’s life easier.
You can use hybrid mobile app development, like Cordova or Ionic, to build mobile apps with React, but is more efficiently building mobile apps with React Native from many points.
React Native An extension of React, niched on Mobile Development.

Its main focus is all about Mobile User Interfaces.
iOS & Android are covered.
Reusable React Native UI components & modules allow hybrid apps to render natively.
We use View, Text imported from React Native library.
No need to overhaul your old app. All you have to do is add React Native UI components into your existing app’s code, without having to rewrite.
Doesn't use HTML to render the app. Provides alternative components that work in a similar way, so it wouldn't be hard to understand them.
Because your code doesn’t get rendered in an HTML page, this also means you won’t be able to reuse any libraries you previously used with React that renders any kind of HTML, SVG or Canvas.
React Native is not made from web elements and can’t be styled in the same way."
mobile,What is a data class in Kotlin?,Kotlin,"We frequently create classes whose main purpose is to hold data. In Kotlin, this is called a data class and is marked as data:
data class User(val name: String, val age: Int)
To ensure consistency and meaningful behavior of the generated code, data classes have to fulfill the following requirements:
The primary constructor needs to have at least one parameter;
All primary constructor parameters need to be marked as val or var;
Data classes cannot be abstract, open, sealed or inner;"
mobile,How to initialize an array in Kotlin with values?,Kotlin,"In Java an array can be initialized such as:
 int numbers[] = new int[] {10, 20, 30, 40, 50}
How does Kotlin's array initialization look like?
Answer
val numbers: IntArray = intArrayOf(10, 20, 30, 40, 50)"
mobile,What is the idiomatic way to remove duplicate strings from array? How to remove duplicates from an Array<String?> in Kotlin?,Kotlin,"Use the distinct extension function:
val a = arrayOf(""a"", ""a"", ""b"", ""c"", ""c"")
val b = a.distinct() // [""a"", ""b"", ""c""]
You can also use:
toSet, toMutableSet
toHashSet - if you don't need the original ordering to be preserved
These functions produce a Set instead of a List and should be a little bit more efficient than distinct."
mobile,Where should I use var and where val?,Kotlin,"Use var where value is changing frequently. For example while getting location of android device:
var integerVariable : Int? = null
Use val where there is no change in value in whole class. For example you want set textview or button's text programmatically.
val stringVariables : String = ""Button's Constant or final Text"""
mobile,What is basic differene between fold and reduce in Kotlin? When to use which?,Kotlin,"fold takes an initial value, and the first invocation of the lambda you pass to it will receive that initial value and the first element of the collection as parameters.
listOf(1, 2, 3).fold(0) { sum, element -> sum + element }
The first call to the lambda will be with parameters 0 and 1.
Having the ability to pass in an initial value is useful if you have to provide some sort of default value or parameter for your operation.
reduce doesn't take an initial value, but instead starts with the first element of the collection as the accumulator (called sum in the following example)
listOf(1, 2, 3).reduce { sum, element -> sum + element }
The first call to the lambda here will be with parameters 1 and 2."
mobile,What is a primary constructor in Kotlin?,Kotlin,"The primary constructor is part of the class header. Unlike Java, you don't need to declare a constructor in the body of the class. Here's an example:
class Person(val firstName: String, var age: Int) {
    // class body
}
The main idea is by removing the constructor keyword, our code gets simplified and easy to understand."
mobile,How to correctly concatenate a String in Kotlin?,Kotlin,"var is like general variable and it's known as a mutable variable in kotlin and can be assigned multiple times.
val is like Final variable and it's known as immutable in Kotlin and can be initialized only single time."
mobile,What is the difference between var and val in Kotlin?,Kotlin,"var is like general variable and it's known as a mutable variable in kotlin and can be assigned multiple times.
val is like Final variable and it's known as immutable in Kotlin and can be initialized only single time."
mobile,What npm is used for?,Node.js,"npm stands for Node Package Manager. npm provides the following two main functionalities:
Online repositories for Node.js packages/modules which are searchable on search.nodejs.org
Command-line utility to install packages, do version management and dependency management of Node.js packages.
Another important use for npm is dependency management. When you have a node project with a package.json file, you can run npm install from the project root and npm will install all the dependencies listed in the package.json."
mobile,Why does Node.js prefer Error-First Callback?,Node.js,"The usual pattern is that the callback is invoked as callback(err, result), where only one of err and result is non-null, depending on whether the operation succeeded or failed. Without this convention, developers would have to maintain different signatures and APIs, without knowing where to place the error in the arguments array.
fs.readFile(filePath, function(err, data) {
  if (err) {
    //handle the error
  }
  // use the data object
});"
mobile,What is Callback Hell and what is the main cause of it?,Node.js,"Asynchronous JavaScript, or JavaScript that uses callbacks, is hard to get right intuitively. A lot of code ends up looking like this:
fs.readdir(source, function (err, files) {
  if (err) {
    console.log('Error finding files: ' + err)
  } else {
    files.forEach(function (filename, fileIndex) {
      console.log(filename)
      gm(source + filename).size(function (err, values) {
        if (err) {
          console.log('Error identifying file size: ' + err)
        } else {
          console.log(filename + ' : ' + values)
          aspect = (values.width / values.height)
          widths.forEach(function (width, widthIndex) {
            height = Math.round(width / aspect)
            console.log('resizing ' + filename + 'to ' + height + 'x' + height)
            this.resize(width, height).write(dest + 'w' + width + '_' + filename, function(err) {
              if (err) console.log('Error writing file: ' + err)
            })
          }.bind(this))
        }
      })
    })
  }
})
See the pyramid shape and all the }) at the end? This is affectionately known as callback hell.
The cause of callback hell is when people try to write JavaScript in a way where execution happens visually from top to bottom. Lots of people make this mistake! In other languages like C, Ruby or Python there is the expectation that whatever happens on line 1 will finish before the code on line 2 starts running and so on down the file."
mobile,What is Callback?,Node.js,"A callback is a function called at the completion of a given task; this prevents any blocking, and allows other code to be run in the meantime. Callbacks are the foundation of Node.js. Callbacks give you an interface with which to say, ""and when you're done doing that, do all this.""
var myCallback = function(data) {
  console.log('got data: '+data);
};

var usingItNow = function(callback) {
  callback('get it?');
};"
mobile,What are the key features of Node.js?,Node.js,"Let’s look at some of the key features of Node.js.
Asynchronous event driven IO helps concurrent request handling – All APIs of Node.js are asynchronous. This feature means that if a Node receives a request for some Input/Output operation, it will execute that operation in the background and continue with the processing of other requests. Thus it will not wait for the response from the previous requests.
Fast in Code execution – Node.js uses the V8 JavaScript Runtime engine, the one which is used by Google Chrome. Node has a wrapper over the JavaScript engine which makes the runtime engine much faster and hence processing of requests within Node.js also become faster.
Single Threaded but Highly Scalable – Node.js uses a single thread model for event looping. The response from these events may or may not reach the server immediately. However, this does not block other operations. Thus making Node.js highly scalable. Traditional servers create limited threads to handle requests while Node.js creates a single thread that provides service to much larger numbers of such requests.
Node.js library uses JavaScript – This is another important aspect of Node.js from the developer’s point of view. The majority of developers are already well-versed in JavaScript. Hence, development in Node.js becomes easier for a developer who knows JavaScript.
There is an Active and vibrant community for the Node.js framework – The active community always keeps the framework updated with the latest trends in the web development.
No Buffering – Node.js applications never buffer any data. They simply output the data in chunks."
mobile,Explain the difference between local and global npm packages installation.,Node.js,"local packages are installed in the directory where you run npm install <package-name>, and they are put in the node_modules folder under this directory
global packages are all put in a single place in your system (exactly where depends on your setup), regardless of where you run npm install -g <package-name>
In general, all packages should be installed locally.
This makes sure you can have dozens of applications in your computer, all running a different version of each package if needed.
Updating a global package would make all your projects use the new release, and as you can imagine this might cause nightmares in terms of maintenance, as some packages might break compatibility with further dependencies, and so on."
mobile,What do you mean by Asynchronous API?,Node.js,All APIs of Node.js library are aynchronous that is non-blocking. It essentially means a Node.js based server never waits for a API to return data. Server moves to next API after calling it and a notification mechanism of Events of Node.js helps server to get response from the previous API call.
mobile,What are the benefits of using Node.js?,Node.js,"Aynchronous and Event Driven - All APIs of Node.js library are aynchronous that is non-blocking. It essentially means a Node.js based server never waits for a API to return data. Server moves to next API after calling it and a notification mechanism of Events of Node.js helps server to get response from the previous API call.
Very Fast - Being built on Google Chrome's V8 JavaScript Engine, Node.js library is very fast in code execution.
Single Threaded but highly Scalable - Node.js uses a single threaded model with event looping. Event mechanism helps server to respond in a non-bloking ways and makes server highly scalable as opposed to traditional servers which create limited threads to handle requests. Node.js uses a single threaded program and same program can services much larger number of requests than traditional server like Apache HTTP Server.
No Buffering - Node.js applications never buffer any data. These applications simply output the data in chunks."
mobile,What is libuv?,Node.js,"libuv is a C library that is used to abstract non-blocking I/O operations to a consistent interface across all supported platforms. It provides mechanisms to handle file system, DNS, network, child processes, pipes, signal handling, polling and streaming. It also includes a thread pool for offloading work for some things that can't be done asynchronously at the operating system level."
mobile,What is V8?,Node.js,"The V8 library provides Node.js with a JavaScript engine (a program that converts Javascript code into lower level or machine code that microprocessors can understand), which Node.js controls via the V8 C++ API. V8 is maintained by Google, for use in Chrome.
The Chrome V8 engine :
The V8 engine is written in C++ and used in Chrome and Nodejs.
It implements ECMAScript as specified in ECMA-262.
The V8 engine can run standalone we can embed it with our own C++ program."
mobile,What is the difference between returning a callback and just calling a callback?,Node.js,"return callback();
//some more lines of code; -  won't be executed

callback();
//some more lines of code; - will be executed
Of course returning will help the context calling async function get the value returned by callback.
function do2(callback) {
    log.trace('Execute function: do2');
    return callback('do2 callback param');
}

var do2Result = do2((param) => {
    log.trace(`print ${param}`);
    return `return from callback(${param})`; // we could use that return
});

log.trace(`print ${do2Result}`);
Output:
C:\Work\Node>node --use-strict main.js
[0] Execute function: do2
[0] print do2 callback param
[0] print return from callback(do2 callback param)"
mobile,What is the file package.json?,Node.js,"All npm packages contain a file, usually in the project root, called package.json - this file holds various metadata relevant to the project. This file is used to give information to npm that allows it to identify the project as well as handle the project's dependencies. It can also contain other metadata such as a project description, the version of the project in a particular distribution, license information, even configuration data - all of which can be vital to both npm and to the end users of the package. The package.json file is normally located at the root directory of a Node.js project.
Here is a minimal package.json:
{
  ""name"" : ""barebones"",
  ""version"" : ""0.0.0"",
}"
mobile,Name some Built-in Globals in Node.js.,Node.js,"Node.js has a number of built-in global identifiers that every Node.js developer should have some familiarity with. Some of these are true globals, being visible everywhere; others exist at the module level, but are inherent to every module, thus being pseudo-globals.
The list of true globals:
global - The global namespace. Setting a property to this namespace makes it globally visible within the running process.
process - The Node.js built-in process module, which provides interaction with the current Node.js process. Read More
console - The Node.js built-in console module, which wraps various STDIO functionality in a browser-like way. Read More
setTimeout(), clearTimeout(), setInterval(), clearInterval() - The built-in timer functions are globals. Read More
The pseudo-globals included at the module level in every module:
module, module.exports, exports - These objects all pertain to the Node.js module system. Read More
__filename - The __filename keyword contains the path of the currently executing file. Note that this is not defined while running the Node.js REPL.
__dirname - Like __filename, the __dirname keyword contains the path to the root directory of the currently executing script. Also not present in the Node.js REPL.
require() - The require() function is a built-in function, exposed per-module, that allows other valid modules to be included."
mobile,What does Promisifying technique mean in Node.js?,Node.js,"This technique is a way to be able to use a classic Javascript function that takes a callback, and have it return a promise:
For example:
const fs = require('fs')

const getFile = (fileName) => {
    return new Promise((resolve, reject) => {
        fs.readFile(fileName, (err, data) => {
            if (err) {
                reject(err)
                return
            }
            resolve(data)
        })
    })
}

getFile('/etc/passwd')
.then(data => console.log(data))
.catch(err => console.log(err))"
mobile,What's the difference between process.cwd() vs __dirname?,Node.js,"cwd is a method of global object process, returns a string value which is the current working directory of the Node.js process.
__dirname is the directory name of the current script as a string value. __dirname is not actually global but rather local to each module.
Consider the project structure:
Project 
├── main.js
└──lib
   └── script.js
Suppose we have a file script.js files inside a sub directory of project, i.e. C:/Project/lib/script.js and running node main.js which require script.js

main.js

require('./lib/script.js')
console.log(process.cwd())
// C:\Project
console.log(__dirname)
// C:\Project
console.log(__dirname === process.cwd())
// true
script.js

console.log(process.cwd())
// C:\Project
console.log(__dirname)
// C:\Project\lib
console.log(__dirname === process.cwd())
// false"
mobile,Why we always require modules at the top of a file? Can we require modules inside of functions?,Node.js,"Yes, we can but we shall never do it.
Node.js always runs require synchronously. If you require an external module from within functions your module will be synchronously loaded when those functions run and this can cause two problems:
If that module is only needed in one route handler function it might take some time for the module to load synchronously. As a result, several users would be unable to get any access to your server and requests will queue up.
If the module you require causes an error and crashes the server you may not know about the error."
mobile,What are Extensions used for in Swift?,Swift,"Extensions add new functionality to an existing class, structure, enumeration, or protocol type. This includes the ability to extend types for which you do not have access to the original source code. Extensions are similar to categories in Objective-C
Extensions in Swift can:
Add computed instance properties and computed type properties
Define instance methods and type methods
Provide new initializers
Define subscripts
Define and use new nested types
Make an existing type conform to a protocol"
mobile,What is the difference between Upcast and Downcast in Swift?,Swift,"The upcast, going from a derived class to a base class, can be checked at compile time and will never fail.
However, downcasts can fail since you can’t always be sure about the specific class. If you have a UIView, it’s possible it’s a UITableView or maybe a UIButton.
downcasts must be either optional with as? or
“forced failable” with as! when sure about the type"
mobile,What's the difference between == and ===?,Swift,"==' operator checks if the values are the same, comparing value types. ""equal to""
'===' operator checks if the references point the same instance (both point to the same memory address), comparing reference types. ""identical to"""
mobile,What is a Serial Queue?,Swift,"A Serial Queue allows us to perform only one task at a time, no matter the way of execution, i.e. Synchronous or Asynchronous. In short, the code executed by Serial DispatchQueue is not parallel and has to wait for the first task to complete. This way of execution is also known as First In, First Out (FIFO).
All the queues need to wait for the completion of the previous queue. By default, DispatchQueue is a serial queue.
Consider:
let queue = DispatchQueue(label: ""com.swiftpal.dispatch.serial"")

queue.async() {
    Thread.sleep(forTimeInterval: 3) // Wait for 3 seconds
    print(""Task 1 Done"")
}

queue.async() {
    Thread.sleep(forTimeInterval: 1) // Wait for 1 second.
    print(""Task 2 Done"")
}

/* Output:
 Task 1 Done
 Task 2 Done
*/"
mobile,What is Xamarin?,Xamarin,"Xamarin is a Cross Platform Mobile Development technology by Microsoft where we can develop the native app using the same code base across all platforms (iOS, Android, UWP) using the C# language. Xamarin uses two approaches for the app development:
Xamarin.Forms and
Xamarin Native.
Xamarin.Forms uses MVVM & XAML while Xamarin Native uses native UI technology and MVC or MVVMCross Architecture."
mobile,How to display static HTML string in Xamarin.Forms?,Xamarin,"We can use WebView control to display static HTML string. WebView can be used to display Websites, HTML string, Documents, Local Files depending on the platform support."
mobile,Name few widely used Layout Controls.,Xamarin,"Frame: It contains a single element as a child having a default padding of 20.
Grid: It is used when UI components are to be arranged into Rows & Columns.
StackLayout: It is used when UI components are to be arranged either horizontally or vertically.
ScrollView: It enables the scrolling for a child element if required. It has one child only.
There are other Layout Controls too like AbsoluteLayout, RelativeLayout, ContentView, ContentPresenter, etc."
mobile,What are Pages in Xamarin.Forms?,Xamarin,"Pages are Xamarin Forms generic representation of Cross Mobil Application Screens. A Page occupies most or all of a screen and contains a single child.
On IOS, the Page is mapped to ViewController, on Android, it is mapped to somewhat like Activity and on Universal Windows Platform, it is mapped to  Page. Pages can be of several types, viz. Master /Detail Page, navigational Page, Carousel Page, Tabbed Page, Template Page, etc."
mobile,What is the difference between ListView & TableView?,Xamarin,"The ListView and TableView controls are so similar, you can think of them as a single control. The major difference between the two is the manner in which they lay out their items, and it’s easy to change the layout so each control emulates the other.
The ListView control displays its data stacked vertically, much like a standard listbox. Use this control to display an ordered list of data, especially long lists that require scrolling like a list of email messages, a list of contacts, or search results.
The TableView control displays its data stacked horizontally in rows (although you can alter this behavior and have it displayed in columns first, as well). You use this control when you need more space for rich visualization of each item to be displayed.
One of the big differences is ListView provides you a ItemsSource and a Itemtemplate and TableView does not. So items must be added as children manually."
mobile,What are the various flavors of Xamarin Applications that can be made?,Xamarin,"Xamarin allows two different ways of creating applications, based on the amount of code reusability and customization:
The first approach is the Traditional Native Approach wherein platform-specific apps using Xamarin.iOSiOS and Xamarin.Android can be made. This way of creating apps is generally used when there is a lot of customization specific to the platform is required as it allows direct access to platform-specific APIs. Xamarin.iOS is used for iOS applications and Xamarin.Android is used to create Android applications.
The second approach is creating apps through Xamarin.Forms approach. Xamarin.Forms are used when there is a possibility of reuse of a lot of platform-independent code and the focus is less on custom UI. The platform-independent code is separated and kept in Shared Project or PCL or .NET Standard Library and Platform Specific projects consume this common code by including it."
mobile,What is the basic architecture of Xamarin.Forms project?,Xamarin,"Xamarin.Forms can consists of four (this varies based on requirements) projects under one solution.
.NET Standard, PCL or Shared Project
iOS Project
Android Project
UWP Project
Here, .NET Standard, PCL or Shared Project contains all UI & Business logic inside it.
iOS, Android, UWP contains platform specific code containing Renderers or Dependency Services Implementations."
mobile,What is the difference between Margin and Padding properties?,Xamarin,"Margin property represents the distance between the element and its adjacent elements and is used to control the element's rendering position, and the rendering position of its neighbors. Margin can be specified on Layout and View classes.
Padding property represents the distance between an Element and the child elements of it and thus it is used to separate the control from its own content. Padding values can be specified on Layout classes.
Suppose, two adjacent elements have a margin of value 20 pixels assigned, what will be the distance between these two elements? Why?
The distance between two elements will be 40 pixels in this case, because, Margin property values are Additive. In addition to this, if Margin and Padding both are applied, then the distance between element and its content will be Margin + Padding."
mobile,Explain Lifecycle methods of Xamarin.Forms app.,Xamarin,"Lifecycle methods are set of methods which get executed when application enters into a specific state. Following are such methods:
OnStart: Executes when application starts from the beginning
OnSleep: Executes each time when application goes into the background
OnResume: Executes when application comes into the foreground from the Sleeping state"
mobile,What is Xamarin.Forms and what are the benefits of using it?,Xamarin,"Xamarin.Forms is a Cross-Platform Toolkit which helps share Business Logic as well as UI using XAML across all supported platforms.
It uses MVVM pattern along with Binding into the XAML UI to accomplish this. It produces pure native controls for each individual platforms. Using Xamarin.Forms, we can share the whole business logic as well as UI among all supporting platforms like iOS, Android and UWP. It also provides a way for platform specific customization of any native controls using Renderers. Thus, we can almost share about 80-90% of code across platforms. We can say Xamarin is the King of Cross Platforms."
mobile,How to store simple Key-Value data?,Xamarin,Xamarin.Forms's Application class exposes the Application.Current.Properties Dictionary which is used to store the simple Key-Value pair data. The Properties dictionary uses a string key and stores an object value.
mobile,How will you navigate from one page to another?,Xamarin,"On some button click event of First Page, we can call the following method, which will navigate to the second page:
await Navigation.PushAsync (new MySecondPageXaml (), true);
We have to use the ""Navigation"" property which is available under ContentPage class (XAML Page's code behind). So this navigation can be written in the Page's code behind file."
mobile,What is the difference between Xamarin.Forms & Xamarin Native?,Xamarin,"Xamarin.Forms is used when:
Less platform-specific code is required
Code sharing is more important than custom UI
UI is not complex
Xamarin Native is used when:
Lot of platform specific code is required
Custom UI is more important then code sharing
Many platform-specific APIs are used"
mobile,What is App.cs class?,Xamarin,"App.cs is the main class of the app which offers features like:
MainPage: It helps to set the initial page for the app.
Properties Dictionary: It helps us store simple values across lifecycle states.
Static Current Property: It gives the instance of the current application object."
mobile,Which Language are supported for Xamarin deelopment?,Xamarin,C# & F#
mobile,"What is a Module, and what does it contain?",Angular,"An Angular module is set of Angular basic building blocks like component, directives, services etc. An app can have more than one module.
A module can be created using @NgModule decorator.
@NgModule({
  imports:      [ BrowserModule ],
  declarations: [ AppComponent ],
  bootstrap:    [ AppComponent ]
})
export class AppModule { }"
mobile,What is Routing Guard in Angular?,Angular,"Angular’s route guards are interfaces which can tell the router whether or not it should allow navigation to a requested route. They make this decision by looking for a true or false return value from a class which implements the given guard interface.
There are five different types of guards and each of them is called in a particular sequence. The router’s behavior is modified differently depending on which guard is used. The guards are:
CanActivate
CanActivateChild
CanDeactivate
CanLoad
Resolve
Consider:
import { Injectable } from '@angular/core';
import { Router, CanActivate } from '@angular/router';
import { AuthService } from './auth.service';

@Injectable()
export class AuthGuardService implements CanActivate {
  constructor(public auth: AuthService, public router: Router) {}
  canActivate(): boolean {
    if (!this.auth.isAuthenticated()) {
      this.router.navigate(['login']);
      return false;
    }
    return true;
  }
}"
mobile,How would you run unit test?,Angular,"The Angular CLI downloads and install everything you need to test an Angular application with the Jasmine test framework.
The project you create with the CLI is immediately ready to test. Just run this one CLI command:
ng test"
mobile,What is the equivalent of ngShow and ngHide in Angular?,Angular,"Just bind to the hidden property:
[hidden]=""!myVar"""
mobile,What is the difference between @component and @Directive in Angular?,Angular,"Directives add behaviour to an existing DOM element or an existing component instance.
A component, rather than adding/modifying behaviour, actually creates its own view (hierarchy of DOM elements) with attached behaviour.
Write a component when you want to create a reusable set of DOM elements of UI with custom behaviour. Write a directive when you want to write reusable behaviour to supplement existing DOM elements."
mobile,What is a bootstrapping module?,Angular,"Every application has at least one Angular module, the root module that you bootstrap to launch the application is called as bootstrapping module. It is commonly known as AppModule. The default structure of AppModule generated by AngularCLI would be as follows:
 /* JavaScript imports */
 import {
     BrowserModule
 } from '@angular/platform-browser';
 import {
     NgModule
 } from '@angular/core';
 import {
     FormsModule
 } from '@angular/forms';
 import {
     HttpClientModule
 } from '@angular/common/http';

 import {
     AppComponent
 } from './app.component';

 /* the AppModule class with the @NgModule decorator */
 @NgModule({
     declarations: [
         AppComponent
     ],
     imports: [
         BrowserModule,
         FormsModule,
         HttpClientModule
     ],
     providers: [],
     bootstrap: [AppComponent]
 })
 export class AppModule {}"
mobile,What is the minimum definition of a Component?,Angular,"The absolute minimal configuration for a @Component in Angular is a template. Both template properties are set to optional because you have to define either template or templateUrl.
When you don't define them, you will get an exception like this:
No template specified for component 'ComponentName'
A selector property is not required, as you can also use your components in a route."
mobile,What is a Component? Why would you use it?,Angular,"Components are the most basic building block of an UI in an Angular application. An Angular application is a tree of Angular components. Angular components are a subset of directives. Unlike directives, components always have a template and only one component can be instantiated per an element in a template.
A component must belong to an NgModule in order for it to be usable by another component or application. To specify that a component is a member of an NgModule, you should list it in the declarations field of that NgModule.
@Component({selector: 'greet', template: 'Hello {{name}}!'})
class Greet {
  name: string = 'World';
}"
mobile,What are the differences between Angular JS(angular 1.x) and Angular(Angular 2.x and beyond)?,Angular,"Angular and AngularJS is basically a different framework with the same name.
Angular is more ready for the current state of web standards and the future state of the web (ES6\7, immutiablity, components, shadow DOM, service workers, mobile compatibilty, modules, typescript and so on and so on... )
Angular killed many main features in AngularJS like - controllers, $scope, directives (replaced with @component annotations), the module definition, and much more, even simple things like ng-repeat has not left the same as it was.
Also: 1. They added an angular cli. 2. Your angular code is written in ES6 Typescript and it compiles at runtime to Javascript in the browser. 3. You bind to your HTML similarly like how you would if in an Angular 1 directive. So variable like $scope and $rootScope have been deprecated."
mobile,What is Interpolation?,Angular,"Interpolation is a special syntax that Angular converts into property binding. It’s a convenient alternative to property binding. It is represented by double curly braces({{}}). The text between the braces is often the name of a component property. Angular replaces that name with the string value of the corresponding component property.
Let's take an example,
<h3>
      {{title}}
      <img src=""{{url}}"" style=""height:30px"">
</h3>
In the example above, Angular evaluates the title and url properties and fills in the blanks, first displaying a bold application title and then a URL."
mobile,What is the difference between *ngIf vs [hidden]?,Angular,*ngIf effectively removes its content from the DOM while [hidden] modifies the display property and only instructs the browser to not show the content but the DOM still contains it.
mobile,What are Observables?,Angular,"Observables are declarative which provide support for passing messages between publishers and subscribers in your application.
They are mainly used for event handling, asynchronous programming, and handling multiple values. In this case, you define a function for publishing values, but it is not executed until a consumer subscribes to it. The subscribed consumer then receives notifications until the function completes, or until they unsubscribe."
mobile,What is the difference between Structural and Attribute directives in Angular?,Angular,"Structural directives are used to alter the DOM layout by removing and adding DOM elements. It is far better in changing the structure of the view. Examples of Structural directives are NgFor and Nglf.
Attribute Directives These are being used as characteristics of elements. For example, a directive such as built-in NgStyle in the template Syntax guide is an attribute directive."
mobile,"What is a Service, and when will you use it?",Angular,"Angular services are singleton objects which get instantiated only once during the lifetime of an application. They contain methods that maintain data throughout the life of an application, i.e. data does not get refreshed and is available all the time. The main objective of a service is to organize and share business logic, models, or data and functions with different components of an Angular application.
The separation of concerns is the main reason why Angular services came into existence. An Angular service is a stateless object and provides some very useful functions."
mobile,What's the difference between an Angular Component and Module?,Angular,"Components control views (html). They also communicate with other components and services to bring functionality to your app.
Modules consist of one or more components. They do not control any html. Your modules declare which components can be used by components belonging to other modules, which classes will be injected by the dependency injector and which component gets bootstrapped. Modules allow you to manage your components to bring modularity to your app."
mobile,How would you protect a component being activated through the router?,Angular,"The Angular router ships with a feature called guards. These provide us with ways to control the flow of our application. We can stop a user from visitng certain routes, stop a user from leaving routes, and more. The overall process for protecting Angular routes:
Create a guard service: ng g guard auth
Create canActivate() or canActivateChild() methods
Use the guard when defining routes
// import the newly created AuthGuard
const routes: Routes = [
  {
    path: 'account',
    canActivate: [AuthGuard]
  }
];
Some other available guards:
CanActivate: Check if a user has access
CanActivateChild: Check if a user has access to any of the child routes
CanDeactivate: Can a user leave a page? For example, they haven't finished editing a post
Resolve: Grab data before the route is instantiated
CanLoad: Check to see if we can load the routes assets"
mobile,You have an HTML response I want to display. How do I do that?,Angular,"The correct syntax is the following:
<div [innerHTML]=""theHtmlString""></div>
Working in 5.2.6"
mobile,What is Observer?,Angular,"Observer is an interface for a consumer of push-based notifications delivered by an Observable. It has below structure,
    interface Observer<T> {
      closed?: boolean;
      next: (value: T) => void;
      error: (err: any) => void;
      complete: () => void;
    }
A handler that implements the Observer interface for receiving observable notifications will be passed as a parameter for observable as below,
    myObservable.subscribe(myObserver);
Note: If you don't supply a handler for a notification type, the observer ignores notifications of that type."
mobile,What is an Observable?,Angular,"An Observable is a unique Object similar to a Promise that can help manage async code. Observables are not part of the JavaScript language so we need to rely on a popular Observable library called RxJS.
The observables are created using new keyword. Let see the simple example of observable,
    import { Observable } from 'rxjs';

    const observable = new Observable(observer => {
      setTimeout(() => {
        observer.next('Hello from a Observable!');
      }, 2000);
    });`"
mobile,What is the purpose of base href tag?,Angular,"The routing application should add element to the index.html as the first child in the tag inorder to indicate how to compose navigation URLs. If app folder is the application root then you can set the href value as below
    <base href=""/"">"
fe,What is CSS selector specificity and how does it work?,CSS,"The browser determines what styles to show on an element depending on the specificity of CSS rules. We assume that the browser has already determined the rules that match a particular element. Among the matching rules, the specificity, four comma-separate values, `a, b, c, d` are calculated for each rule based on the following:
 1. `a` is whether inline styles are being used. If the property declaration is an inline style on the element, `a` is 1, else 0.
 2. `b` is the number of ID selectors.
 3. `c` is the number of classes, attributes and pseudo-classes selectors.
 4. `d` is the number of tags and pseudo-elements selectors.
 The resulting specificity is not a score, but a matrix of values that can be compared column by column. When comparing selectors to determine which has the highest specificity, look from left to right, and compare the highest value in each column. So a value in column `b` will override values in columns `c` and `d`, no matter what they might be. As such, specificity of `0,1,0,0` would be greater than one of `0,0,10,10`.
 In the cases of equal specificity: the latest rule is the one that counts. If you have written the same rule into your stylesheet (regardless of internal or external) twice, then the lower rule in your style sheet is closer to the element to be styled, it is deemed to be more specific and therefore will be applied.
 I would write CSS rules with low specificity so that they can be easily overridden if necessary. When writing CSS UI component library code, it is important that they have low specificities so that users of the library can override them without using too complicated CSS rules just for the sake of increasing specificity or resorting to `!important`.
 "
fe,"What's the difference between ""resetting"" and ""normalizing"" CSS? Which would you choose, and why?",CSS,"- **Resetting** - Resetting is meant to strip all default browser styling on elements. For e.g. `margin`s, `padding`s, `font-size`s of all elements are reset to be the same. You will have to redeclare styling for common typographic elements.
 - **Normalizing** - Normalizing preserves useful default styles rather than ""unstyling"" everything. It also corrects bugs for common browser dependencies.
 I would choose resetting when I have a very customized or unconventional site design such that I need to do a lot of my own styling and do not need any default styling to be preserved.
 "
fe,Describe `float`s and how they work.,CSS,"Float is a CSS positioning property. Floated elements remain a part of the flow of the page, and will affect the positioning of other elements (e.g. text will flow around floated elements), unlike `position: absolute` elements, which are removed from the flow of the page.
 The CSS `clear` property can be used to be positioned below `left`/`right`/`both` floated elements.
 If a parent element contains nothing but floated elements, its height will be collapsed to nothing. It can be fixed by clearing the float after the floated elements in the container but before the close of the container.
 The `.clearfix` hack uses a clever CSS [pseudo selector](#describe-pseudo-elements-and-discuss-what-they-are-used-for) (`::after`) to clear floats. Rather than setting the overflow on the parent, you apply an additional class `clearfix` to it. Then apply this CSS:
 ```css
 .clearfix::after {
   content: ' ';
   visibility: hidden;
   display: block;
   height: 0;
   clear: both;
 }
 ```
 Alternatively, give `overflow: auto` or `overflow: hidden` property to the parent element which will establish a new block formatting context inside the children and it will expand to contain its children.
 "
fe,Describe `z-index` and how stacking context is formed.,CSS,"The `z-index` property in CSS controls the vertical stacking order of elements that overlap. `z-index` only affects elements that have a `position` value which is not `static`.
 Without any `z-index` value, elements stack in the order that they appear in the DOM (the lowest one down at the same hierarchy level appears on top). Elements with non-static positioning (and their children) will always appear on top of elements with default static positioning, regardless of HTML hierarchy.
 A stacking context is an element that contains a set of layers. Within a local stacking context, the `z-index` values of its children are set relative to that element rather than to the document root. Layers outside of that context — i.e. sibling elements of a local stacking context — can't sit between layers within it. If an element B sits on top of element A, a child element of element A, element C, can never be higher than element B even if element C has a higher `z-index` than element B.
 Each stacking context is self-contained - after the element's contents are stacked, the whole element is considered in the stacking order of the parent stacking context. A handful of CSS properties trigger a new stacking context, such as `opacity` less than 1, `filter` that is not `none`, and `transform` that is not`none`.
 _Note: What exactly qualifies an element to create a stacking context is listed in this long set of [rules](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context#The_stacking_context)._
 "
fe,Describe Block Formatting Context (BFC) and how it works.,CSS,"A Block Formatting Context (BFC) is part of the visual CSS rendering of a web page in which block boxes are laid out. Floats, absolutely positioned elements, `inline-blocks`, `table-cells`, `table-caption`s, and elements with `overflow` other than `visible` (except when that value has been propagated to the viewport) establish new block formatting contexts.
 Knowing how to establish a block formatting context is important, because without doing so, the containing box will not [contain floated children](https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Block_formatting_context#Make_float_content_and_alongside_content_the_same_height). This is similar to collapsing margins, but more insidious as you will find entire boxes collapsing in odd ways.
 A BFC is an HTML box that satisfies at least one of the following conditions:
 - The value of `float` is not `none`.
 - The value of `position` is neither `static` nor `relative`.
 - The value of `display` is `table-cell`, `table-caption`, `inline-block`, `flex`, or `inline-flex`, `grid`, or `inline-grid`.
 - The value of `overflow` is not `visible`.
 In a BFC, each box's left outer edge touches the left edge of the containing block (for right-to-left formatting, right edges touch).
 Vertical margins between adjacent block-level boxes in a BFC collapse. Read more on [collapsing margins](https://www.sitepoint.com/web-foundations/collapsing-margins/).
 "
fe,What are the various clearing techniques and which is appropriate for what context?,CSS,"- Empty `div` method - `<div style=""clear:both;""></div>`.
 - Clearfix method - Refer to the `.clearfix` class above.
 - `overflow: auto` or `overflow: hidden` method - Parent will establish a new block formatting context and expand to contains its floated children.
 In large projects, I would write a utility `.clearfix` class and use them in places where I need it. `overflow: hidden` might clip children if the children is taller than the parent and is not very ideal.
 "
fe,"Explain CSS sprites, and how you would implement them on a page or site.",CSS,"CSS sprites combine multiple images into one single larger image. It is a commonly-used technique for icons (Gmail uses it). How to implement it:
 1. Use a sprite generator that packs multiple images into one and generate the appropriate CSS for it.
 1. Each image would have a corresponding CSS class with `background-image`, `background-position` and `background-size` properties defined.
 1. To use that image, add the corresponding class to your element.
 **Advantages:**
 - Reduce the number of HTTP requests for multiple images (only one single request is required per spritesheet). But with HTTP2, loading multiple images is no longer much of an issue.
 - Advance downloading of assets that won't be downloaded until needed, such as images that only appear upon `:hover` pseudo-states. Blinking wouldn't be seen.
 "
fe,How would you approach fixing browser-specific styling issues?,CSS,"- After identifying the issue and the offending browser, use a separate style sheet that only loads when that specific browser is being used. This technique requires server-side rendering though.
 - Use libraries like Bootstrap that already handles these styling issues for you.
 - Use `autoprefixer` to automatically add vendor prefixes to your code.
 - Use Reset CSS or Normalize.css.
 - If you're using Postcss (or a similar transpiling library), there may be plugins which allow you to opt in for using modern CSS syntax (and even W3C proposals) that will transform those sections of your code into corresponding safe code that will work in the targets you've used.
 "
fe,How do you serve your pages for feature-constrained browsers? What techniques/processes do you use?,CSS,"- Graceful degradation - The practice of building an application for modern browsers while ensuring it remains functional in older browsers.
 - Progressive enhancement - The practice of building an application for a base level of user experience, but adding functional enhancements when a browser supports it.
 - Use [caniuse.com](https://caniuse.com/) to check for feature support.
 - Autoprefixer for automatic vendor prefix insertion.
 - Feature detection using [Modernizr](https://modernizr.com/).
 - Use CSS Feature queries [@support](https://developer.mozilla.org/en-US/docs/Web/CSS/@supports)
 "
fe,What are the different ways to visually hide content (and make it available only for screen readers)?,CSS,"These techniques are related to accessibility (a11y).
 - `width: 0; height: 0`. Make the element not take up any space on the screen at all, resulting in not showing it.
 - `position: absolute; left: -99999px`. Position it outside of the screen.
 - `text-indent: -9999px`. This only works on text within the `block` elements. This is a widely used and famous trick, but it comes with [some downsides](https://www.zeldman.com/2012/03/01/replacing-the-9999px-hack-new-image-replacement/) like causing performance issues, so you might want to consider using `text-indent: 100%` instead.
 - Meta tags. For example by using Schema.org, RDF, and JSON-LD.
 - WAI-ARIA. A W3C technical specification that specifies how to increase the accessibility of web pages.
 Even if WAI-ARIA is the ideal solution, I would go with the `absolute` positioning approach, as it has the least caveats, works for most elements and it's an easy technique.
 "
fe,"Have you ever used a grid system, and if so, what do you prefer?",CSS,"Before Flex became popular (around 2014), the `float`-based grid system was the most reliable because it still has the most browser support among the alternative existing systems (flex, grid). Bootstrap was using the `float` approach until Bootstrap 4 which switched to the `flex`-based approach. As of writing (2020), `flex` is the recommended approach for building grid systems and has [decent browser support](https://caniuse.com/#search=flex).
 For the adventurous, they can look into [CSS Grid Layout](https://css-tricks.com/snippets/css/complete-guide-grid/), which uses the shiny new `grid` property; it is even better than `flex` for building grid layouts and will be the de facto way to do so in the future.
 "
fe,Have you used or implemented media queries or mobile-specific layouts/CSS?,CSS,"Yes. An example would be transforming a stacked pill navigation into a fixed-bottom tab navigation beyond a certain breakpoint.
 "
fe,Are you familiar with styling SVG?,CSS,"Yes, there are several ways to color shapes (including specifying attributes on the object) using inline CSS, an embedded CSS section, or an external CSS file. Most SVG you'll find around the web use inline CSS, but there are advantages and disadvantages associated with each type.
 Basic coloring can be done by setting two attributes on the node: `fill` and `stroke`. `fill` sets the color inside the object and `stroke` sets the color of the line drawn around the object. You can use the same CSS color naming schemes that you use in HTML, whether that's color names (that is `red`), RGB values (that is `rgb(255,0,0)`), Hex values, RGBA values, etc.
 ```html
 <rect
   x=""10""
   y=""10""
   width=""100""
   height=""100""
   stroke=""blue""
   fill=""purple""
   fill-opacity=""0.5""
   stroke-opacity=""0.8"" />
 ```
 The above `fill=""purple""` is an example of a _presentational attribute_. Interestingly, and unlike inline styles like `style=""fill: purple""` which also happens to be an attribute, presentational attributes can be [overriden by CSS](https://css-tricks.com/presentation-attributes-vs-inline-styles/) styles defined in a stylesheet. So, if you did something like `svg { fill: blue; }` it would override the purple fill we've defined.
 "
fe,Can you give an example of an @media property other than screen?,CSS,"Yes, there are four types of @media properties (including _screen_):
 - `all` - for all media type devices
 - `print` - for printers
 - `speech` - for screenreaders that ""reads"" the page out loud
 - `screen` - for computer screens, tablets, smart-phones etc.
 Here is an example of `print` media type's usage:
 ```css
 @media print {
   body {
     color: black;
   }
 }
 ```
 "
fe,"What are some of the ""gotchas"" for writing efficient CSS?",CSS,"Firstly, understand that browsers match selectors from rightmost (key selector) to left. Browsers filter out elements in the DOM according to the key selector and traverse up its parent elements to determine matches. The shorter the length of the selector chain, the faster the browser can determine if that element matches the selector. Hence avoid key selectors that are tag and universal selectors. They match a large number of elements and browsers will have to do more work in determining if the parents do match.
 [BEM (Block Element Modifier)](https://bem.info/) methodology recommends that everything has a single class, and, where you need hierarchy, that gets baked into the name of the class as well, this naturally makes the selector efficient and easy to override.
 Be aware of which CSS properties [trigger](https://csstriggers.com/) reflow, repaint, and compositing. Avoid writing styles that change the layout (trigger reflow) where possible.
 "
fe,What are the advantages/disadvantages of using CSS preprocessors?,CSS,"**Advantages:**
 - CSS is made more maintainable.
 - Easy to write nested selectors.
 - Variables for consistent theming. Can share theme files across different projects.
 - Mixins to generate repeated CSS.
 - Sass features like loops, lists, and maps can make configuration easier and less verbose.
 - Splitting your code into multiple files. CSS files can be split up too but doing so will require an HTTP request to download each CSS file.
 **Disadvantages:**
 - Requires tools for preprocessing. Re-compilation time can be slow.
 - Not writing currently and potentially usable CSS. For example, by using something like [postcss-loader](https://github.com/postcss/postcss-loader) with [webpack](https://webpack.js.org/), you can write potentially future-compatible CSS, allowing you to use things like CSS variables instead of Sass variables. Thus, you're learning new skills that could pay off if/when they become standardized.
 "
fe,Describe what you like and dislike about the CSS preprocessors you have used.,CSS,"**Likes:**
 - Mostly the advantages mentioned above.
 - Less is written in JavaScript, which plays well with Node.
 **Dislikes:**
 - I use Sass via `node-sass`, which is a binding for LibSass written in C++. I have to frequently recompile it when switching between node versions.
 - In Less, variable names are prefixed with `@`, which can be confused with native CSS keywords like `@media`, `@import` and `@font-face` rule.
 "
fe,How would you implement a web design comp that uses non-standard fonts?,CSS,"Use `@font-face` and define `font-family` for different `font-weight`s.
 "
fe,Explain how a browser determines what elements match a CSS selector.,CSS,"This part is related to the above about [writing efficient CSS](#what-are-some-of-the-gotchas-for-writing-efficient-css). Browsers match selectors from rightmost (key selector) to left. Browsers filter out elements in the DOM according to the key selector and traverse up its parent elements to determine matches. The shorter the length of the selector chain, the faster the browser can determine if that element matches the selector.
 For example with this selector `p span`, browsers firstly find all the `<span>` elements and traverse up its parent all the way up to the root to find the `<p>` element. For a particular `<span>`, as soon as it finds a `<p>`, it knows that the `<span>` matches and can stop its matching.
 "
fe,Describe pseudo-elements and discuss what they are used for.,CSS,"A CSS pseudo-element is a keyword added to a selector that lets you style a specific part of the selected element(s). They can be used for decoration (`:first-line`, `:first-letter`) or adding elements to the markup (combined with `content: ...`) without having to modify the markup (`:before`, `:after`).
 - `:first-line` and `:first-letter` can be used to decorate text.
 - Used in the `.clearfix` hack as shown above to add a zero-space element with `clear: both`.
 - Triangular arrows in tooltips use `:before` and `:after`. Encourages separation of concerns because the triangle is considered part of styling and not really the DOM.
 "
fe,Explain your understanding of the box model and how you would tell the browser in CSS to render your layout in different box models.,CSS,"The CSS box model describes the rectangular boxes that are generated for elements in the document tree and laid out according to the visual formatting model. Each box has a content area (e.g. text, an image, etc.) and optional surrounding `padding`, `border`, and `margin` areas.
 The CSS box model is responsible for calculating:
 - How much space a block element takes up.
 - Whether or not borders and/or margins overlap, or collapse.
 - A box's dimensions.
 The box model has the following rules:
 - The dimensions of a block element are calculated by `width`, `height`, `padding`, `border`s, and `margin`s.
 - If no `height` is specified, a block element will be as high as the content it contains, plus `padding` (unless there are floats, for which see below).
 - If no `width` is specified, a non-floated block element will expand to fit the width of its parent minus `padding`.
 - The `height` of an element is calculated by the content's `height`.
 - The `width` of an element is calculated by the content's `width`.
 - By default, `padding`s and `border`s are not part of the `width` and `height` of an element.
 "
fe,What does `* { box-sizing: border-box; }` do? What are its advantages?,CSS,"- By default, elements have `box-sizing: content-box` applied, and only the content size is being accounted for.
 - `box-sizing: border-box` changes how the `width` and `height` of elements are being calculated, `border` and `padding` are also being included in the calculation.
 - The `height` of an element is now calculated by the content's `height` + vertical `padding` + vertical `border` width.
 - The `width` of an element is now calculated by the content's `width` + horizontal `padding` + horizontal `border` width.
 - Taking into account `padding`s and `border`s as part of our box model resonates better with how designers actually imagine content in grids.
 "
fe,What is the CSS `display` property and can you give a few examples of its use?,CSS,"- `none`, `block`, `inline`, `inline-block`, `flex`, `grid`, `table`, `table-row`, `table-cell`, `list-item`.
 | `display` | Description |
 | :-- | :-- |
 | `none` | Does not display an element (the element no longer affects the layout of the document). All child element are also no longer displayed. The document is rendered as if the element did not exist in the document tree |
 | `block` | The element consumes the whole line in the block direction (which is usually horizontal) |
 | `inline` | Elements can be laid out beside each other |
 | `inline-block` | Similar to `inline`, but allows some `block` properties like setting `width` and `height` |
 | `table` | Behaves like the `<table>` element |
 | `table-row` | Behaves like the `<tr>` element |
 | `table-cell` | Behaves like the `<td>` element |
 | `list-item` | Behaves like a `<li>` element which allows it to define `list-style-type` and `list-style-position` |
 "
fe,What's the difference between `inline` and `inline-block`?,CSS,"I shall throw in a comparison with `block` for good measure.
 |  | `block` | `inline-block` | `inline` |
 | --- | --- | --- | --- |
 | Size | Fills up the width of its parent container. | Depends on content. | Depends on content. |
 | Positioning | Start on a new line and tolerates no HTML elements next to it (except when you add `float`) | Flows along with other content and allows other elements beside it. | Flows along with other content and allows other elements beside it. |
 | Can specify `width` and `height` | Yes | Yes | No. Will ignore if being set. |
 | Can be aligned with `vertical-align` | No | Yes | Yes |
 | Margins and paddings | All sides respected. | All sides respected. | Only horizontal sides respected. Vertical sides, if specified, do not affect layout. Vertical space it takes up depends on `line-height`, even though the `border` and `padding` appear visually around the content. |
 | Float | - | - | Becomes like a `block` element where you can set vertical margins and paddings. |
 "
fe,"What's the difference between a `relative`, `fixed`, `absolute` and `static`ally positioned element?",CSS,"A positioned element is an element whose computed `position` property is either `relative`, `absolute`, `fixed` or `sticky`.
 - `static` - The default position; the element will flow into the page as it normally would. The `top`, `right`, `bottom`, `left` and `z-index` properties do not apply.
 - `relative` - The element's position is adjusted relative to itself, without changing layout (and thus leaving a gap for the element where it would have been had it not been positioned).
 - `absolute` - The element is removed from the flow of the page and positioned at a specified position relative to its closest positioned ancestor if any, or otherwise relative to the initial containing block. Absolutely positioned boxes can have margins, and they do not collapse with any other margins. These elements do not affect the position of other elements.
 - `fixed` - The element is removed from the flow of the page and positioned at a specified position relative to the viewport and doesn't move when scrolled.
 - `sticky` - Sticky positioning is a hybrid of relative and fixed positioning. The element is treated as `relative` positioned until it crosses a specified threshold, at which point it is treated as `fixed` positioned.
 "
fe,"What existing CSS frameworks have you used locally, or in production? How would you change/improve them?",CSS,"- **Bootstrap** - Slow release cycle. Bootstrap 4 has been in alpha for almost 2 years. Add a spinner button component, as it is widely used.
 - **Semantic UI** - Source code structure makes theme customization extremely hard to understand. Its unconventional theming system is a pain to customize. Hardcoded config path within the vendor library. Not well-designed for overriding variables unlike in Bootstrap.
 - **Bulma** - A lot of non-semantic and superfluous classes and markup required. Not backward compatible. Upgrading versions breaks the app in subtle manners.
 "
fe,Have you played around with the new CSS Flexbox or Grid specs?,CSS,"Yes. Flexbox is mainly meant for 1-dimensional layouts while Grid is meant for 2-dimensional layouts.
 Flexbox solves many common problems in CSS, such as vertical centering of elements within a container, sticky footer, etc. Bootstrap and Bulma are based on Flexbox, and it is probably the recommended way to create layouts these days. Have tried Flexbox before but ran into some browser incompatibility issues (Safari) in using `flex-grow`, and I had to rewrite my code using `inline-blocks` and math to calculate the widths in percentages, it wasn't a nice experience.
 Grid is by far the most intuitive approach for creating grid-based layouts (it better be!) but browser support is not wide at the moment.
 "
fe,Can you explain the difference between coding a website to be responsive versus using a mobile-first strategy?,CSS,"Note that these two 2 approaches are not exclusive.
 Making a website responsive means that some elements will respond by adapting its size or other functionality according to the device's screen size, typically the viewport width, through CSS media queries, for example, making the font size smaller on smaller devices.
 ```css
 @media (min-width: 601px) {
   .my-class {
     font-size: 24px;
   }
 }
 @media (max-width: 600px) {
   .my-class {
     font-size: 12px;
   }
 }
 ```
 A mobile-first strategy is also responsive, however it agrees we should default and define all the styles for mobile devices, and only add specific responsive rules to other devices later. Following the previous example:
 ```css
 .my-class {
   font-size: 12px;
 }
 @media (min-width: 600px) {
   .my-class {
     font-size: 24px;
   }
 }
 ```
 A mobile-first strategy has 2 main advantages:
 - It's more performant on mobile devices, since all the rules applied for them don't have to be validated against any media queries.
 - It forces to write cleaner code in respect to responsive CSS rules.
 "
fe,How is responsive design different from adaptive design?,CSS,"Both responsive and adaptive design attempt to optimize the user experience across different devices, adjusting for different viewport sizes, resolutions, usage contexts, control mechanisms, and so on.
 Responsive design works on the principle of flexibility - a single fluid website that can look good on any device. Responsive websites use media queries, flexible grids, and responsive images to create a user experience that flexes and changes based on a multitude of factors. Like a single ball growing or shrinking to fit through several different hoops.
 Adaptive design is more like the modern definition of progressive enhancement. Instead of one flexible design, adaptive design detects the device and other features and then provides the appropriate feature and layout based on a predefined set of viewport sizes and other characteristics. The site detects the type of device used and delivers the pre-set layout for that device. Instead of a single ball going through several different-sized hoops, you'd have several different balls to use depending on the hoop size.
 Both have these methods have some issues that need to be weighed:
 - Responsive design can be quite challenging, as you're essentially using a single albeit responsive layout to fit all situations. How to set the media query breakpoints is one such challenge. Do you use standardized breakpoint values? Or, do you use breakpoints that make sense to your particular layout? What if that layout changes?
 - Adaptive design generally requires user agent sniffing, or DPI detection, etc., all of which can prove unreliable.
 "
fe,"Have you ever worked with retina graphics? If so, when and what techniques did you use?",CSS,"_Retina_ is just a marketing term to refer to high resolution screens with a pixel ratio bigger than 1. The key thing to know is that using a pixel ratio means these displays are emulating a lower resolution screen in order to show elements with the same size. Nowadays we consider all mobile devices _retina_ defacto displays.
 Browsers by default render DOM elements according to the device resolution, except for images.
 In order to have crisp, good-looking graphics that make the best of retina displays we need to use high resolution images whenever possible. However using always the highest resolution images will have an impact on performance as more bytes will need to be sent over the wire.
 To overcome this problem, we can use responsive images, as specified in HTML5. It requires making available different resolution files of the same image to the browser and let it decide which image is best, using the html attribute `srcset` and optionally `sizes`, for instance:
 ```html
 <div responsive-background-image>
   <img
     src=""/images/test-1600.jpg""
     sizes=""
       (min-width: 768px) 50vw,
       (min-width: 1024px) 66vw,
       100vw""
     srcset=""
       /images/test-400.jpg   400w,
       /images/test-800.jpg   800w,
       /images/test-1200.jpg 1200w
     "" />
 </div>
 ```
 It is important to note that browsers which don't support HTML5's `srcset` (i.e. IE11) will ignore it and use `src` instead. If we really need to support IE11 and we want to provide this feature for performance reasons, we can use a JavaScript polyfill, e.g. Picturefill (link in the references).
 For icons, I would also opt to use SVGs and icon fonts where possible, as they render very crisply regardless of resolution.
 "
fe,"Is there any reason you'd want to use `translate()` instead of `absolute` positioning, or vice-versa? And why?",CSS,"`translate()` is a value of CSS `transform`. Changing `transform` or `opacity` does not trigger browser reflow or repaint but does trigger compositions; whereas changing the absolute positioning triggers `reflow`. `transform` causes the browser to create a GPU layer for the element but changing absolute positioning properties uses the CPU. Hence `translate()` is more efficient and will result in shorter paint times for smoother animations.
 When using `translate()`, the element still occupies its original space (sort of like `position: relative`), unlike in changing the absolute positioning.
 "
fe,What does a DOCTYPE do?,html,"**DOCTYPE** is an abbreviation for **Document Type**. A DOCTYPE is always associated to a **DTD** - for **Document Type Definition**.
 A DTD defines how documents of a certain type should be structured (i.e. a `button` can contain a `span` but not a `div`), whereas a DOCTYPE declares what DTD a document _supposedly_ respects (i.e. this document respects the HTML DTD).
 For webpages, the DOCTYPE declaration is required. It is used to tell user agents what version of the HTML specifications your document respects. Once a user agent has recognized a correct DOCTYPE, it will trigger the **no-quirks mode** matching this DOCTYPE for reading the document. If a user agent doesn't recognize a correct DOCTYPE, it will trigger the **quirks mode**.
 The DOCTYPE declaration for the HTML5 standards is `<!DOCTYPE html>`.
 "
fe,How do you serve a page with content in multiple languages?,html,"I will assume that it is asking about the most common case, which is how to serve a page with content available in multiple languages, but the content within the page should be displayed only in one consistent language.
 When an HTTP request is made to a server, the requesting user agent usually sends information about language preferences, such as in the `Accept-Language` header. The server can then use this information to return a version of the document in the appropriate language if such an alternative is available. The returned HTML document should also declare the `lang` attribute in the `<html>` tag, such as `<html lang=""en"">...</html>`.
 Of course this is useless for letting a search engine know that the same content is available in different languages, and so you must also make use of the `hreflang` attribute in the `<head>`. Eg. `<link rel=""alternate"" hreflang=""de"" href=""http://de.example.com/page.html"" />`
 In the back end, the HTML markup will contain `i18n` placeholders and content for the specific language stored in YML or JSON formats. The server then dynamically generates the HTML page with content in that particular language, usually with the help of a back end framework.
 "
fe,What kind of things must you be wary of when designing or developing for multilingual sites?,html,"- Use `lang` attribute in your HTML.
 - Directing users to their native language - Allow a user to change his country/language easily without hassle.
 - Text in raster-based images (e.g. png, gif, jpg, etc.), is not a scalable approach - Placing text in an image is still a popular way to get good-looking, non-system fonts to display on any computer. However, to translate image text, each string of text will need to have a separate image created for each language. Anything more than a handful of replacements like this can quickly get out of control.
 - Restrictive words/sentence length - Some content can be longer when written in another language. Be wary of layout or overflow issues in the design. It's best to avoid designing where the amount of text would make or break a design. Character counts come into play with things like headlines, labels, and buttons. They are less of an issue with free-flowing text such as body text or comments.
 - Be mindful of how colors are perceived - Colors are perceived differently across languages and cultures. The design should use color appropriately.
 - Formatting dates and currencies - Calendar dates are sometimes presented in different ways. Eg. ""May 31, 2012"" in the U.S. vs. ""31 May 2012"" in parts of Europe.
 - Do not concatenate translated strings - Do not do anything like `""The date today is "" + date`. It will break in languages with different word order. Use a template string with parameters substitution for each language instead. For example, look at the following two sentences in English and Chinese respectively: `I will travel on {% date %}` and `{% date %} 我会出发`. Note that the position of the variable is different due to grammar rules of the language.
 - Language reading direction - In English, we read from left-to-right, top-to-bottom, in traditional Japanese, text is read up-to-down, right-to-left.
 - Useful-to-have - include the locale in the path (e.g en_US, zh_CN, etc).
 "
fe,What are `data-` attributes good for?,html,"Before JavaScript frameworks became popular, fe end developers used `data-` attributes to store extra data within the DOM itself, without other hacks such as non-standard attributes, extra properties on the DOM. It is intended to store custom data private to the page or application, for which there are no more appropriate attributes or elements.
 These days, using `data-` attributes is generally not encouraged. One reason is that users can modify the data attribute easily by using inspect element in the browser. The data model is better stored within JavaScript itself and stay updated with the DOM via data binding possibly through a library or a framework.
 However, one perfectly valid use of data attributes, is to add a hook for _end to end_ testing frameworks such as Selenium and Capybara without having to create a meaningless classes or ID attributes. The element needs a way to be found by a particular Selenium spec and something like `data-selector='the-thing'` is a valid way to do so without convoluting the semantic markup otherwise.
 "
fe,Consider HTML5 as an open web platform. What are the building blocks of HTML5?,html,"- Semantics - Allowing you to describe more precisely what your content is.
 - Connectivity - Allowing you to communicate with the server in new and innovative ways.
 - Offline and storage - Allowing webpages to store data on the client-side locally and operate offline more efficiently.
 - Multimedia - Making video and audio first-class citizens in the Open Web.
 - 2D/3D graphics and effects - Allowing a much more diverse range of presentation options.
 - Performance and integration - Providing greater speed optimization and better usage of computer hardware.
 - Device access - Allowing for the usage of various input and output devices.
 - Styling - Letting authors write more sophisticated themes.
 "
fe,"Describe the difference between a `cookie`, `sessionStorage` and `localStorage`.",html,"All the above-mentioned technologies are key-value storage mechanisms on the client side. They are only able to store values as strings.
 |  | `cookie` | `localStorage` | `sessionStorage` |
 | --- | --- | --- | --- |
 | Initiator | Client or server. Server can use `Set-Cookie` header | Client | Client |
 | Expiry | Manually set | Forever | On tab close |
 | Persistent across browser sessions | Depends on whether expiration is set | Yes | No |
 | Sent to server with every HTTP request | Cookies are automatically being sent via `Cookie` header | No | No |
 | Capacity (per domain) | 4kb | 5MB | 5MB |
 | Accessibility | Any window | Any window | Same tab |
 _Note: If the user decides to clear browsing data via whatever mechanism provided by the browser, this will clear out any `cookie`, `localStorage`, or `sessionStorage` stored. It's important to keep this in mind when designing for local persistance, especially when comparing to alternatives such as server side storing in a database or similar (which of course will persist despite user actions)._
 "
fe,"Describe the difference between `<script>`, `<script async>` and `<script defer>`.",html,"- `<script>` - HTML parsing is blocked, the script is fetched and executed immediately, HTML parsing resumes after the script is executed.
 - `<script async>` - The script will be fetched in parallel to HTML parsing and executed as soon as it is available (potentially before HTML parsing completes). Use `async` when the script is independent of any other scripts on the page, for example, analytics.
 - `<script defer>` - The script will be fetched in parallel to HTML parsing and executed when the page has finished parsing. If there are multiple of them, each deferred script is executed in the order they were encountered in the document. If a script relies on a fully-parsed DOM, the `defer` attribute will be useful in ensuring that the HTML is fully parsed before executing. A deferred script must not contain `document.write`.
 Note: The `async` and `defer` attributes are ignored for scripts that have no `src` attribute.
 "
fe,Why is it generally a good idea to position CSS `<link>`s between `<head></head>` and JS `<script>`s just before `</body>`? Do you know any exceptions?,html,"**Placing `<link>`s in the `<head>`**
 Putting `<link>`s in the `<head>` is part of proper specification in building an optimized website. When a page first loads, HTML and CSS are being parsed simultaneously; HTML creates the DOM (Document Object Model) and CSS creates the CSSOM (CSS Object Model). Both are needed to create the visuals in a website, allowing for a quick ""first meaningful paint"" timing. This progressive rendering is a category optimization sites are measured in their performance scores. Putting stylesheets near the bottom of the document is what prohibits progressive rendering in many browsers. Some browsers block rendering to avoid having to repaint elements of the page if their styles change. The user is then stuck viewing a blank white page. Other times there can be flashes of unstyled content (FOUC), which show a webpage with no styling applied.
 **Placing `<script>`s just before `</body>`**
 `<script>` tags block HTML parsing while they are being downloaded and executed which can slow down your page. Placing the scripts at the bottom will allow the HTML to be parsed and displayed to the user first.
 An exception for positioning of `<script>`s at the bottom is when your script contains `document.write()`, but these days it's not a good practice to use `document.write()`. Also, placing `<script>`s at the bottom means that the browser cannot start downloading the scripts until the entire document is parsed. This ensures your code that needs to manipulate DOM elements will not throw an error and halt the entire script. If you need to put `<script>`s in the `<head>`, use the `defer` attribute, which will achieve the same effect of running the script only after the HTML is parsed but the browser can download the script earlier.
 Keep in mind that putting scripts just before the closing `</body>` tag will create the illusion that the page loads faster on an empty cache (since the scripts won't block downloading the rest of the document). However, if you have some code you want to run during page load, it will only start executing after the entire page has loaded. If you put those scripts in the `<head>` tag, they would start executing before - so on a primed cache the page would actually appear to load faster.
 **`<head>` and `<body>` tags are now optional**
 As per the HTML5 specification, certain HTML tags like `<head>` and `<body>` are optional. Google's style guide even recommends removing them to save bytes. However, this practice is still not widely adopted and the performance gain is likely to be minimal and for most sites it's not likely going to matter.
 "
fe,What is progressive rendering?,html,"Progressive rendering is the name given to techniques used to improve the performance of a webpage (in particular, improve perceived load time) to render content for display as quickly as possible.
 It used to be much more prevalent in the days before broadband internet but it is still used in modern development as mobile data connections are becoming increasingly popular (and unreliable)!
 Examples of such techniques:
 - Lazy loading of images - Images on the page are not loaded all at once. JavaScript will be used to load an image when the user scrolls into the part of the page that displays the image.
 - Prioritizing visible content (or above-the-fold rendering) - Include only the minimum CSS/content/scripts necessary for the amount of page that would be rendered in the users browser first to display as quickly as possible, you can then use deferred scripts or listen for the `DOMContentLoaded`/`load` event to load in other resources and content.
 - Async HTML fragments - Flushing parts of the HTML to the browser as the page is constructed on the back end. More details on the technique can be found [here](http://www.ebaytechblog.com/2014/12/08/async-fragments-rediscovering-progressive-html-rendering-with-marko/).
 "
fe,Why you would use a `srcset` attribute in an image tag? Explain the process the browser uses when evaluating the content of this attribute.,html,"You would use the `srcset` attribute when you want to serve different images to users depending on their device display width - serve higher quality images to devices with retina display enhances the user experience while serving lower resolution images to low-end devices increase performance and decrease data wastage (because serving a larger image will not have any visible difference). For example: `<img srcset=""small.jpg 500w, medium.jpg 1000w, large.jpg 2000w"" src=""..."" alt="""">` tells the browser to display the small, medium or large `.jpg` graphic depending on the client's resolution. The first value is the image name and the second is the width of the image in pixels. For a device width of 320px, the following calculations are made:
 - 500 / 320 = 1.5625
 - 1000 / 320 = 3.125
 - 2000 / 320 = 6.25
 If the client's resolution is 1x, 1.5625 is the closest, and `500w` corresponding to `small.jpg` will be selected by the browser.
 If the resolution is retina (2x), the browser will use the closest resolution above the minimum. Meaning it will not choose the 500w (1.5625) because it is greater than 1 and the image might look bad. The browser would then choose the image with a resulting ratio closer to 2 which is 1000w (3.125).
 `srcset`s solve the problem whereby you want to serve smaller image files to narrow screen devices, as they don't need huge images like desktop displays do — and also optionally that you want to serve different resolution images to high density/low-density screens.
 "
fe,Explain event delegation,javascript,"Event delegation is a technique involving adding event listeners to a parent element instead of adding them to the descendant elements. The listener will fire whenever the event is triggered on the descendant elements due to event bubbling up the DOM. The benefits of this technique are:
 - Memory footprint goes down because only one single handler is needed on the parent element, rather than having to attach event handlers on each descendant.
 - There is no need to unbind the handler from elements that are removed and to bind the event for new elements.
 "
fe,Explain how `this` works in JavaScript,javascript,"There's no simple explanation for `this`; it is one of the most confusing concepts in JavaScript. A hand-wavey explanation is that the value of `this` depends on how the function is called. I have read many explanations on `this` online, and I found [Arnav Aggrawal](https://medium.com/@arnav_aggarwal)'s explanation to be the clearest. The following rules are applied:
 1. If the `new` keyword is used when calling the function, `this` inside the function is a brand new object.
 2. If `apply`, `call`, or `bind` are used to call/create a function, `this` inside the function is the object that is passed in as the argument.
 3. If a function is called as a method, such as `obj.method()` — `this` is the object that the function is a property of.
 4. If a function is invoked as a free function invocation, meaning it was invoked without any of the conditions present above, `this` is the global object. In a browser, it is the `window` object. If in strict mode (`'use strict'`), `this` will be `undefined` instead of the global object.
 5. If multiple of the above rules apply, the rule that is higher wins and will set the `this` value.
 6. If the function is an ES2015 arrow function, it ignores all the rules above and receives the `this` value of its surrounding scope at the time it is created.
 For an in-depth explanation, do check out his [article on Medium](https://codeburst.io/the-simple-rules-to-this-in-javascript-35d97f31bde3).
 "
fe,Can you give an example of one of the ways that working with this has changed in ES6?,javascript,"ES6 allows you to use [arrow functions](http://2ality.com/2017/12/alternate-this.html#arrow-functions) which uses the [enclosing lexical scope](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions#No_separate_this). This is usually convenient, but does prevent the caller from controlling context via `.call` or `.apply`—the consequences being that a library such as `jQuery` will not properly bind `this` in your event handler functions. Thus, it's important to keep this in mind when refactoring large legacy applications.
 "
fe,Explain how prototypal inheritance works,javascript,"This is an extremely common JavaScript interview question. All JavaScript objects have a `__proto__` property with the exception of objects created with `Object.create(null)`, that is a reference to another object, which is called the object's ""prototype"". When a property is accessed on an object and if the property is not found on that object, the JavaScript engine looks at the object's `__proto__`, and the `__proto__`'s `__proto__` and so on, until it finds the property defined on one of the `__proto__`s or until it reaches the end of the prototype chain. This behavior simulates classical inheritance, but it is really more of [delegation than inheritance](https://davidwalsh.name/javascript-objects).
 "
fe,Example of Prototypal Inheritance,javascript,"```js
 function Parent() {
   this.name = 'Parent';
 }
 Parent.prototype.greet = function () {
   console.log('Hello from ' + this.name);
 };
 const child = Object.create(Parent.prototype);
 child.cry = function () {
   console.log('waaaaaahhhh!');
 };
 child.cry();
 // waaaaaahhhh!
 child.greet();
 // hello from Parent
 child.constructor;
 // ƒ Parent() {
 //   this.name = 'Parent';
 // }
 child.constructor.name;
 // 'Parent'
 ```
 Things to note are:
 - `.greet` is not defined on the _child_, so the engine goes up the prototype chain and finds `.greet` off the inherited from _Parent_.
 - We need to call `Object.create` in one of following ways for the prototype methods to be inherited:
   - Object.create(Parent.prototype);
   - Object.create(new Parent(null));
   - Object.create(objLiteral);
 - Currently, `child.constructor` is pointing to the `Parent`. If we'd like to correct this, one option would be to do:
 ```js
 function Parent() {
   this.name = 'Parent';
 }
 Parent.prototype.greet = function () {
   console.log('Hello from ' + this.name);
 };
 function Child() {
   Parent.call(this);
   this.name = 'Child';
 }
 Child.prototype = Object.create(Parent.prototype);
 Child.prototype.constructor = Child;
 const child = new Child();
 child.greet();
 // hello from Child
 child.constructor.name;
 // 'Child'
 ```
 "
fe,What do you think of AMD vs CommonJS?,javascript,"Both are ways to implement a module system, which was not natively present in JavaScript until ES2015 came along. CommonJS is synchronous while AMD (Asynchronous Module Definition) is obviously asynchronous. CommonJS is designed with server-side development in mind while AMD, with its support for asynchronous loading of modules, is more intended for browsers.
 I find AMD syntax to be quite verbose and CommonJS is closer to the style you would write import statements in other languages. Most of the time, I find AMD unnecessary, because if you served all your JavaScript into one concatenated bundle file, you wouldn't benefit from the async loading properties. Also, CommonJS syntax is closer to Node style of writing modules and there is less context-switching overhead when switching between client side and server side JavaScript development.
 I'm glad that with ES2015 modules, that has support for both synchronous and asynchronous loading, we can finally just stick to one approach. Although it hasn't been fully rolled out in browsers and in Node, we can always use transpilers to convert our code.
 "
fe,Explain why the following doesn't work as an IIFE: `function foo(){ }();`. What needs to be changed to properly make it an IIFE?,javascript,"IIFE stands for Immediately Invoked Function Expressions. The JavaScript parser reads `function foo(){ }();` as `function foo(){ }` and `();`, where the former is a _function declaration_ and the latter (a pair of parentheses) is an attempt at calling a function but there is no name specified, hence it throws `Uncaught SyntaxError: Unexpected token )`.
 Here are two ways to fix it that involves adding more parentheses: `(function foo(){ })()` and `(function foo(){ }())`. Statements that begin with `function` are considered to be _function declarations_; by wrapping this function within `()`, it becomes a _function expression_ which can then be executed with the subsequent `()`. These functions are not exposed in the global scope and you can even omit its name if you do not need to reference itself within the body.
 You might also use `void` operator: `void function foo(){ }();`. Unfortunately, there is one issue with such approach. The evaluation of given expression is always `undefined`, so if your IIFE function returns anything, you can't use it. An example:
 ```js
 const foo = void (function bar() {
   return 'foo';
 })();
 console.log(foo); // undefined
 ```
 "
fe,"What's the difference between a variable that is: `null`, `undefined` or undeclared? How would you go about checking for any of these states?",javascript,"**Undeclared** variables are created when you assign a value to an identifier that is not previously created using `var`, `let` or `const`. Undeclared variables will be defined globally, outside of the current scope. In strict mode, a `ReferenceError` will be thrown when you try to assign to an undeclared variable. Undeclared variables are bad just like how global variables are bad. Avoid them at all cost! To check for them, wrap its usage in a `try`/`catch` block.
 ```js
 function foo() {
   x = 1; // Throws a ReferenceError in strict mode
 }
 foo();
 console.log(x); // 1
 ```
 A variable that is `undefined` is a variable that has been declared, but not assigned a value. It is of type `undefined`. If a function does not return any value as the result of executing it is assigned to a variable, the variable also has the value of `undefined`. To check for it, compare using the strict equality (`===`) operator or `typeof` which will give the `'undefined'` string. Note that you should not be using the abstract equality operator to check, as it will also return `true` if the value is `null`.
 ```js
 var foo;
 console.log(foo); // undefined
 console.log(foo === undefined); // true
 console.log(typeof foo === 'undefined'); // true
 console.log(foo == null); // true. Wrong, don't use this to check!
 function bar() {}
 var baz = bar();
 console.log(baz); // undefined
 ```
 A variable that is `null` will have been explicitly assigned to the `null` value. It represents no value and is different from `undefined` in the sense that it has been explicitly assigned. To check for `null,` simply compare using the strict equality operator. Note that like the above, you should not be using the abstract equality operator (`==`) to check, as it will also return `true` if the value is `undefined`.
 ```js
 var foo = null;
 console.log(foo === null); // true
 console.log(typeof foo === 'object'); // true
 console.log(foo == undefined); // true. Wrong, don't use this to check!
 ```
 As a personal habit, I never leave my variables undeclared or unassigned. I will explicitly assign `null` to them after declaring if I don't intend to use it yet. If you use a linter in your workflow, it will usually also be able to check that you are not referencing undeclared variables.
 "
fe,"What is a closure, and how/why would you use one?",javascript,"A closure is the combination of a function and the lexical environment within which that function was declared. The word ""lexical"" refers to the fact that lexical scoping uses the location where a variable is declared within the source code to determine where that variable is available. Closures are functions that have access to the outer (enclosing) function's variables—scope chain even after the outer function has returned.
 **Why would you use one?**
 - Data privacy / emulating private methods with closures. Commonly used in the [module pattern](https://addyosmani.com/resources/essentialjsdesignpatterns/book/#modulepatternjavascript).
 - [Partial applications or currying](https://medium.com/javascript-scene/curry-or-partial-application-8150044c78b8#.l4b6l1i3x).
 "
fe,Can you describe the main difference between a `.forEach` loop and a `.map()` loop and why you would pick one versus the other?,javascript,"To understand the differences between the two, let's look at what each function does.
 **`forEach`**
 - Iterates through the elements in an array.
 - Executes a callback for each element.
 - Does not return a value.
 ```js
 const a = [1, 2, 3];
 const doubled = a.forEach((num, index) => {
   // Do something with num and/or index.
 });
 // doubled = undefined
 ```
 **`map`**
 - Iterates through the elements in an array.
 - ""Maps"" each element to a new element by calling the function on each element, creating a new array as a result.
 ```js
 const a = [1, 2, 3];
 const doubled = a.map((num) => {
   return num * 2;
 });
 // doubled = [2, 4, 6]
 ```
 The main difference between `.forEach` and `.map()` is that `.map()` returns a new array. If you need the result, but do not wish to mutate the original array, `.map()` is the clear choice. If you simply need to iterate over an array, `forEach` is a fine choice.
 "
fe,What's a typical use case for anonymous functions?,javascript,"They can be used in IIFEs to encapsulate some code within a local scope so that variables declared in it do not leak to the global scope.
 ```js
 (function () {
   // Some code here.
 })();
 ```
 As a callback that is used once and does not need to be used anywhere else. The code will seem more self-contained and readable when handlers are defined right inside the code calling them, rather than having to search elsewhere to find the function body.
 ```js
 setTimeout(function () {
   console.log('Hello world!');
 }, 1000);
 ```
 Arguments to functional programming constructs or Lodash (similar to callbacks).
 ```js
 const arr = [1, 2, 3];
 const double = arr.map(function (el) {
   return el * 2;
 });
 console.log(double); // [2, 4, 6]
 ```
 "
fe,"How do you organize your code? (module pattern, classical inheritance?)",javascript,"In the past, I've used Backbone for my models which encourages a more OOP approach, creating Backbone models and attaching methods to them.
 The module pattern is still great, but these days, I use React/Redux which utilize a single-directional data flow based on Flux architecture. I would represent my app's models using plain objects and write utility pure functions to manipulate these objects. State is manipulated using actions and reducers like in any other Redux application.
 I avoid using classical inheritance where possible. When and if I do, I stick to [these rules](https://medium.com/@dan_abramov/how-to-use-classes-and-sleep-at-night-9af8de78ccb4).
 "
fe,What's the difference between host objects and native objects?,javascript,"Native objects are objects that are part of the JavaScript language defined by the ECMAScript specification, such as `String`, `Math`, `RegExp`, `Object`, `Function`, etc.
 Host objects are provided by the runtime environment (browser or Node), such as `window`, `XMLHTTPRequest`, etc.
 "
fe,"Difference between: `function Person(){}`, `var person = Person()`, and `var person = new Person()`?",javascript,"This question is pretty vague. My best guess at its intention is that it is asking about constructors in JavaScript. Technically speaking, `function Person(){}` is just a normal function declaration. The convention is to use PascalCase for functions that are intended to be used as constructors.
 `var person = Person()` invokes the `Person` as a function, and not as a constructor. Invoking as such is a common mistake if the function is intended to be used as a constructor. Typically, the constructor does not return anything, hence invoking the constructor like a normal function will return `undefined` and that gets assigned to the variable intended as the instance.
 `var person = new Person()` creates an instance of the `Person` object using the `new` operator, which inherits from `Person.prototype`. An alternative would be to use `Object.create`, such as: `Object.create(Person.prototype)`.
 ```js
 function Person(name) {
   this.name = name;
 }
 var person = Person('John');
 console.log(person); // undefined
 console.log(person.name); // Uncaught TypeError: Cannot read property 'name' of undefined
 var person = new Person('John');
 console.log(person); // Person { name: ""John"" }
 console.log(person.name); // ""john""
 ```
 "
fe,What's the difference between `.call` and `.apply`?,javascript,"Both `.call` and `.apply` are used to invoke functions and the first parameter will be used as the value of `this` within the function. However, `.call` takes in comma-separated arguments as the next arguments while `.apply` takes in an array of arguments as the next argument. An easy way to remember this is C for `call` and comma-separated and A for `apply` and an array of arguments.
 ```js
 function add(a, b) {
   return a + b;
 }
 console.log(add.call(null, 1, 2)); // 3
 console.log(add.apply(null, [1, 2])); // 3
 ```
 "
fe,Explain `Function.prototype.bind`.,javascript,"Taken word-for-word from [MDN](https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_objects/Function/bind):
 > The `bind()` method creates a new function that, when called, has its `this` keyword set to the provided value, with a given sequence of arguments preceding any provided when the new function is called.
 In my experience, it is most useful for binding the value of `this` in methods of classes that you want to pass into other functions. This is frequently done in React components.
 "
fe,When would you use `document.write()`?,javascript,"`document.write()` writes a string of text to a document stream opened by `document.open()`. When `document.write()` is executed after the page has loaded, it will call `document.open` which clears the whole document (`<head>` and `<body>` removed!) and replaces the contents with the given parameter value. Hence it is usually considered dangerous and prone to misuse.
 There are some answers online that explain `document.write()` is being used in analytics code or [when you want to include styles that should only work if JavaScript is enabled](https://www.quirksmode.org/blog/archives/2005/06/three_javascrip_1.html). It is even being used in HTML5 boilerplate to [load scripts in parallel and preserve execution order](https://github.com/paulirish/html5-boilerplate/wiki/Script-Loading-Techniques#documentwrite-script-tag)! However, I suspect those reasons might be outdated and in the modern day, they can be achieved without using `document.write()`. Please do correct me if I'm wrong about this.
 "
fe,"What's the difference between feature detection, feature inference, and using the UA string?",javascript,"**Feature Detection**
 Feature detection involves working out whether a browser supports a certain block of code, and running different code depending on whether it does (or doesn't), so that the browser can always provide a working experience rather crashing/erroring in some browsers. For example:
 ```js
 if ('geolocation' in navigator) {
   // Can use navigator.geolocation
 } else {
   // Handle lack of feature
 }
 ```
 [Modernizr](https://modernizr.com/) is a great library to handle feature detection.
 **Feature Inference**
 Feature inference checks for a feature just like feature detection, but uses another function because it assumes it will also exist, e.g.:
 ```js
 if (document.getElementsByTagName) {
   element = document.getElementById(id);
 }
 ```
 This is not really recommended. Feature detection is more foolproof.
 **UA String**
 This is a browser-reported string that allows the network protocol peers to identify the application type, operating system, software vendor or software version of the requesting software user agent. It can be accessed via `navigator.userAgent`. However, the string is tricky to parse and can be spoofed. For example, Chrome reports both as Chrome and Safari. So to detect Safari you have to check for the Safari string and the absence of the Chrome string. Avoid this method.
 "
fe,Explain Ajax in as much detail as possible.,javascript,"Ajax (asynchronous JavaScript and XML) is a set of web development techniques using many web technologies on the client side to create asynchronous web applications. With Ajax, web applications can send data to and retrieve from a server asynchronously (in the background) without interfering with the display and behavior of the existing page. By decoupling the data interchange layer from the presentation layer, Ajax allows for web pages, and by extension web applications, to change content dynamically without the need to reload the entire page. In practice, modern implementations commonly use JSON instead of XML, due to the advantages of JSON being native to JavaScript.
 The `XMLHttpRequest` API is frequently used for the asynchronous communication or these days, the `fetch` API.
 "
fe,What are the advantages and disadvantages of using Ajax?,javascript,"**Advantages**
 - Better interactivity. New content from the server can be changed dynamically without the need to reload the entire page.
 - Reduce connections to the server since scripts and stylesheets only have to be requested once.
 - State can be maintained on a page. JavaScript variables and DOM state will persist because the main container page was not reloaded.
 - Basically most of the advantages of an SPA.
 **Disadvantages**
 - Dynamic webpages are harder to bookmark.
 - Does not work if JavaScript has been disabled in the browser.
 - Some webcrawlers do not execute JavaScript and would not see content that has been loaded by JavaScript.
 - Webpages using Ajax to fetch data will likely have to combine the fetched remote data with client-side templates to update the DOM. For this to happen, JavaScript will have to be parsed and executed on the browser, and low-end mobile devices might struggle with this.
 - Basically most of the disadvantages of an SPA.
 "
fe,Explain how JSONP works (and how it's not really Ajax).,javascript,"JSONP (JSON with Padding) is a method commonly used to bypass the cross-domain policies in web browsers because Ajax requests from the current page to a cross-origin domain is not allowed.
 JSONP works by making a request to a cross-origin domain via a `<script>` tag and usually with a `callback` query parameter, for example: `https://example.com?callback=printData`. The server will then wrap the data within a function called `printData` and return it to the client.
 ```html
 <!-- https://mydomain.com -->
 <script>
   function printData(data) {
     console.log(`My name is ${data.name}!`);
   }
 </script>
 <script src=""https://example.com?callback=printData""></script>
 ```
 ```js
 // File loaded from https://example.com?callback=printData
 printData({name: 'Yang Shun'});
 ```
 The client has to have the `printData` function in its global scope and the function will be executed by the client when the response from the cross-origin domain is received.
 JSONP can be unsafe and has some security implications. As JSONP is really JavaScript, it can do everything else JavaScript can do, so you need to trust the provider of the JSONP data.
 These days, [CORS](http://en.wikipedia.org/wiki/Cross-origin_resource_sharing) is the recommended approach and JSONP is seen as a hack.
 "
fe,"Have you ever used JavaScript templating? If so, what libraries have you used?",javascript,"Yes. Handlebars, Underscore, Lodash, AngularJS, and JSX. I disliked templating in AngularJS because it made heavy use of strings in the directives and typos would go uncaught. JSX is my new favorite as it is closer to JavaScript and there is barely any syntax to learn. Nowadays, you can even use ES2015 template string literals as a quick way for creating templates without relying on third-party code.
 ```js
 const template = `<div>My name is: ${name}</div>`;
 ```
 However, do be aware of a potential XSS in the above approach as the contents are not escaped for you, unlike in templating libraries.
 "
fe,"Explain ""hoisting"".",javascript,"Hoisting is a term used to explain the behavior of variable declarations in your code. Variables declared or initialized with the `var` keyword will have their declaration ""moved"" up to the top of their module/function-level scope, which we refer to as hoisting. However, only the declaration is hoisted, the assignment (if there is one), will stay where it is.
 Note that the declaration is not actually moved - the JavaScript engine parses the declarations during compilation and becomes aware of declarations and their scopes. It is just easier to understand this behavior by visualizing the declarations as being hoisted to the top of their scope. Let's explain with a few examples.
 ```js
 console.log(foo); // undefined
 var foo = 1;
 console.log(foo); // 1
 ```
 Function declarations have the body hoisted while the function expressions (written in the form of variable declarations) only has the variable declaration hoisted.
 ```js
 // Function Declaration
 console.log(foo); // [Function: foo]
 foo(); // 'FOOOOO'
 function foo() {
   console.log('FOOOOO');
 }
 console.log(foo); // [Function: foo]
 // Function Expression
 console.log(bar); // undefined
 bar(); // Uncaught TypeError: bar is not a function
 var bar = function () {
   console.log('BARRRR');
 };
 console.log(bar); // [Function: bar]
 ```
 Variables declared via `let` and `const` are hoisted as well. However, unlike `var` and `function`, they are not initialized and accessing them before the declaration will result in a `ReferenceError` exception. The variable is in a ""temporal dead zone"" from the start of the block until the declaration is processed.
 ```js
 x; // undefined
 y; // Reference error: y is not defined
 var x = 'local';
 let y = 'local';
 ```
 "
fe,Describe event bubbling.,javascript,"When an event triggers on a DOM element, it will attempt to handle the event if there is a listener attached, then the event is bubbled up to its parent and the same thing happens. This bubbling occurs up the element's ancestors all the way to the `document`. Event bubbling is the mechanism behind event delegation.
 "
fe,"What's the difference between an ""attribute"" and a ""property""?",javascript,"Attributes are defined on the HTML markup but properties are defined on the DOM. To illustrate the difference, imagine we have this text field in our HTML: `<input type=""text"" value=""Hello"">`.
 ```js
 const input = document.querySelector('input');
 console.log(input.getAttribute('value')); // Hello
 console.log(input.value); // Hello
 ```
 But after you change the value of the text field by adding ""World!"" to it, this becomes:
 ```js
 console.log(input.getAttribute('value')); // Hello
 console.log(input.value); // Hello World!
 ```
 "
fe,Why is extending built-in JavaScript objects not a good idea?,javascript,"Extending a built-in/native JavaScript object means adding properties/functions to its `prototype`. While this may seem like a good idea at first, it is dangerous in practice. Imagine your code uses a few libraries that both extend the `Array.prototype` by adding the same `contains` method, the implementations will overwrite each other and your code will break if the behavior of these two methods is not the same.
 The only time you may want to extend a native object is when you want to create a polyfill, essentially providing your own implementation for a method that is part of the JavaScript specification but might not exist in the user's browser due to it being an older browser.
 "
fe,Difference between document `load` event and document `DOMContentLoaded` event?,javascript,"The `DOMContentLoaded` event is fired when the initial HTML document has been completely loaded and parsed, without waiting for stylesheets, images, and subframes to finish loading.
 `window`'s `load` event is only fired after the DOM and all dependent resources and assets have loaded.
 "
fe,What is the difference between `==` and `===`?,javascript,"`==` is the abstract equality operator while `===` is the strict equality operator. The `==` operator will compare for equality after doing any necessary type conversions. The `===` operator will not do type conversion, so if two values are not the same type `===` will simply return `false`. When using `==`, funky things can happen, such as:
 ```js
 1 == '1'; // true
 1 == [1]; // true
 1 == true; // true
 0 == ''; // true
 0 == '0'; // true
 0 == false; // true
 ```
 My advice is never to use the `==` operator, except for convenience when comparing against `null` or `undefined`, where `a == null` will return `true` if `a` is `null` or `undefined`.
 ```js
 var a = null;
 console.log(a == null); // true
 console.log(a == undefined); // true
 ```
 "
fe,Explain the same-origin policy with regards to JavaScript.,javascript,"The same-origin policy prevents JavaScript from making requests across domain boundaries. An origin is defined as a combination of URI scheme, hostname, and port number. This policy prevents a malicious script on one page from obtaining access to sensitive data on another web page through that page's Document Object Model.
 "
fe,Make this work:,javascript,"```js
 duplicate([1, 2, 3, 4, 5]); // [1,2,3,4,5,1,2,3,4,5]
 ```
 ```js
 function duplicate(arr) {
   return arr.concat(arr);
 }
 duplicate([1, 2, 3, 4, 5]); // [1,2,3,4,5,1,2,3,4,5]
 ```
 Or with ES6:
 ```js
 const duplicate = (arr) => [...arr, ...arr];
 duplicate([1, 2, 3, 4, 5]); // [1,2,3,4,5,1,2,3,4,5]
 ```
 "
fe,"Why is it called a Ternary expression, what does the word ""Ternary"" indicate?",javascript,"""Ternary"" indicates three, and a ternary expression accepts three operands, the test condition, the ""then"" expression and the ""else"" expression. Ternary expressions are not specific to JavaScript and I'm not sure why it is even in this list.
 "
fe,"What is `""use strict"";`? What are the advantages and disadvantages to using it?",javascript,"'use strict' is a statement used to enable strict mode to entire scripts or individual functions. Strict mode is a way to opt into a restricted variant of JavaScript.
 Advantages:
 - Makes it impossible to accidentally create global variables.
 - Makes assignments which would otherwise silently fail to throw an exception.
 - Makes attempts to delete undeletable properties throw an exception (where before the attempt would simply have no effect).
 - Requires that function parameter names be unique.
 - `this` is undefined in the global context.
 - It catches some common coding bloopers, throwing exceptions.
 - It disables features that are confusing or poorly thought out.
 Disadvantages:
 - Many missing features that some developers might be used to.
 - No more access to `function.caller` and `function.arguments`.
 - Concatenation of scripts written in different strict modes might cause issues.
 Overall, I think the benefits outweigh the disadvantages, and I never had to rely on the features that strict mode blocks. I would recommend using strict mode.
 "
fe,"Create a for loop that iterates up to `100` while outputting **""fizz""** at multiples of `3`, **""buzz""** at multiples of `5` and **""fizzbuzz""** at multiples of `3` and `5`.",javascript,"Check out this version of FizzBuzz by [Paul Irish](https://gist.github.com/jaysonrowe/1592432#gistcomment-790724).
 ```js
 for (let i = 1; i <= 100; i++) {
   let f = i % 3 == 0,
     b = i % 5 == 0;
   console.log(f ? (b ? 'FizzBuzz' : 'Fizz') : b ? 'Buzz' : i);
 }
 ```
 I would not advise you to write the above during interviews though. Just stick with the long but clear approach. For more wacky versions of FizzBuzz, check out the reference link below.
 "
fe,"Why is it, in general, a good idea to leave the global scope of a website as-is and never touch it?",javascript,"Every script has access to the global scope, and if everyone uses the global namespace to define their variables, collisions will likely occur. Use the module pattern (IIFEs) to encapsulate your variables within a local namespace.
 "
fe,"Why would you use something like the `load` event? Does this event have disadvantages? Do you know any alternatives, and why would you use those?",javascript,"The `load` event fires at the end of the document loading process. At this point, all of the objects in the document are in the DOM, and all the images, scripts, links and sub-frames have finished loading.
 The DOM event `DOMContentLoaded` will fire after the DOM for the page has been constructed, but do not wait for other resources to finish loading. This is preferred in certain cases when you do not need the full page to be loaded before initializing.
 TODO.
 "
fe,Explain what a single page app is and how to make one SEO-friendly.,javascript,"The below is taken from the awesome [Grab fe End Guide](https://github.com/grab/fe-end-guide), which coincidentally, is written by me!
 Web developers these days refer to the products they build as web apps, rather than websites. While there is no strict difference between the two terms, web apps tend to be highly interactive and dynamic, allowing the user to perform actions and receive a response to their action. Traditionally, the browser receives HTML from the server and renders it. When the user navigates to another URL, a full-page refresh is required and the server sends fresh new HTML to the new page. This is called server-side rendering.
 However, in modern SPAs, client-side rendering is used instead. The browser loads the initial page from the server, along with the scripts (frameworks, libraries, app code) and stylesheets required for the whole app. When the user navigates to other pages, a page refresh is not triggered. The URL of the page is updated via the [HTML5 History API](https://developer.mozilla.org/en-US/docs/Web/API/History_API). New data required for the new page, usually in JSON format, is retrieved by the browser via [AJAX](https://developer.mozilla.org/en-US/docs/AJAX/Getting_Started) requests to the server. The SPA then dynamically updates the page with the data via JavaScript, which it has already downloaded in the initial page load. This model is similar to how native mobile apps work.
 The benefits:
 - The app feels more responsive and users do not see the flash between page navigations due to full-page refreshes.
 - Fewer HTTP requests are made to the server, as the same assets do not have to be downloaded again for each page load.
 - Clear separation of the concerns between the client and the server; you can easily build new clients for different platforms (e.g. mobile, chatbots, smart watches) without having to modify the server code. You can also modify the technology stack on the client and server independently, as long as the API contract is not broken.
 The downsides:
 - Heavier initial page load due to the loading of framework, app code, and assets required for multiple pages.
 - There's an additional step to be done on your server which is to configure it to route all requests to a single entry point and allow client-side routing to take over from there.
 - SPAs are reliant on JavaScript to render content, but not all search engines execute JavaScript during crawling, and they may see empty content on your page. This inadvertently hurts the Search Engine Optimization (SEO) of your app. However, most of the time, when you are building apps, SEO is not the most important factor, as not all the content needs to be indexable by search engines. To overcome this, you can either server-side render your app or use services such as [Prerender](https://prerender.io/) to ""render your javascript in a browser, save the static HTML, and return that to the crawlers"".
 "
fe,What is the extent of your experience with Promises and/or their polyfills?,javascript,"Possess working knowledge of it. A promise is an object that may produce a single value sometime in the future: either a resolved value or a reason that it's not resolved (e.g., a network error occurred). A promise may be in one of 3 possible states: fulfilled, rejected, or pending. Promise users can attach callbacks to handle the fulfilled value or the reason for rejection.
 Some common polyfills are `$.deferred`, Q and Bluebird but not all of them comply with the specification. ES2015 supports Promises out of the box and polyfills are typically not needed these days.
 "
fe,What are the pros and cons of using Promises instead of callbacks?,javascript,"**Pros**
 - Avoid callback hell which can be unreadable.
 - Makes it easy to write sequential asynchronous code that is readable with `.then()`.
 - Makes it easy to write parallel asynchronous code with `Promise.all()`.
 - With promises, these scenarios which are present in callbacks-only coding, will not happen:
   - Call the callback too early
   - Call the callback too late (or never)
   - Call the callback too few or too many times
   - Fail to pass along any necessary environment/parameters
   - Swallow any errors/exceptions that may happen
 **Cons**
 - Slightly more complex code (debatable).
 - In older browsers where ES2015 is not supported, you need to load a polyfill in order to use it.
 "
fe,What are some of the advantages/disadvantages of writing JavaScript code in a language that compiles to JavaScript?,javascript,"Some examples of languages that compile to JavaScript include CoffeeScript, Elm, ClojureScript, PureScript, and TypeScript.
 Advantages:
 - Fixes some of the longstanding problems in JavaScript and discourages JavaScript anti-patterns.
 - Enables you to write shorter code, by providing some syntactic sugar on top of JavaScript, which I think ES5 lacks, but ES2015 is awesome.
 - Static types are awesome (in the case of TypeScript) for large projects that need to be maintained over time.
 Disadvantages:
 - Require a build/compile process as browsers only run JavaScript and your code will need to be compiled into JavaScript before being served to browsers.
 - Debugging can be a pain if your source maps do not map nicely to your pre-compiled source.
 - Most developers are not familiar with these languages and will need to learn it. There's a ramp up cost involved for your team if you use it for your projects.
 - Smaller community (depends on the language), which means resources, tutorials, libraries, and tooling would be harder to find.
 - IDE/editor support might be lacking.
 - These languages will always be behind the latest JavaScript standard.
 - Developers should be cognizant of what their code is being compiled to — because that is what would actually be running, and that is what matters in the end.
 Practically, ES2015 has vastly improved JavaScript and made it much nicer to write. I don't really see the need for CoffeeScript these days.
 "
fe,What tools and techniques do you use for debugging JavaScript code?,javascript,"- React and Redux
   - [React Devtools](https://github.com/facebook/react-devtools)
   - [Redux Devtools](https://github.com/gaearon/redux-devtools)
 - Vue
   - [Vue Devtools](https://github.com/vuejs/vue-devtools)
 - JavaScript
   - [Chrome Devtools](https://hackernoon.com/twelve-fancy-chrome-devtools-tips-dc1e39d10d9d)
   - `debugger` statement
   - Good old `console.log` debugging
 "
fe,What language constructions do you use for iterating over object properties and array items?,javascript,"For objects:
 - `for-in` loops - `for (var property in obj) { console.log(property); }`. However, this will also iterate through its inherited properties, and you will add an `obj.hasOwnProperty(property)` check before using it.
 - `Object.keys()` - `Object.keys(obj).forEach(function (property) { ... })`. `Object.keys()` is a static method that will lists all enumerable properties of the object that you pass it.
 - `Object.getOwnPropertyNames()` - `Object.getOwnPropertyNames(obj).forEach(function (property) { ... })`. `Object.getOwnPropertyNames()` is a static method that will lists all enumerable and non-enumerable properties of the object that you pass it.
 For arrays:
 - `for` loops - `for (var i = 0; i < arr.length; i++)`. The common pitfall here is that `var` is in the function scope and not the block scope and most of the time you would want block scoped iterator variable. ES2015 introduces `let` which has block scope and it is recommended to use that instead. So this becomes: `for (let i = 0; i < arr.length; i++)`.
 - `forEach` - `arr.forEach(function (el, index) { ... })`. This construct can be more convenient at times because you do not have to use the `index` if all you need is the array elements. There are also the `every` and `some` methods which will allow you to terminate the iteration early.
 - `for-of` loops - `for (let elem of arr) { ... }`. ES6 introduces a new loop, the `for-of` loop, that allows you to loop over objects that conform to the [iterable protocol](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#The_iterable_protocol) such as `String`, `Array`, `Map`, `Set`, etc. It combines the advantages of the `for` loop and the `forEach()` method. The advantage of the `for` loop is that you can break from it, and the advantage of `forEach()` is that it is more concise than the `for` loop because you don't need a counter variable. With the `for-of` loop, you get both the ability to break from a loop and a more concise syntax.
 Most of the time, I would prefer the `.forEach` method, but it really depends on what you are trying to do. Before ES6, we used `for` loops when we needed to prematurely terminate the loop using `break`. But now with ES6, we can do that with `for-of` loops. I would use `for` loops when I need even more flexibility, such as incrementing the iterator more than once per loop.
 Also, when using the `for-of` loop, if you need to access both the index and value of each array element, you can do so with the ES6 Array `entries()` method and destructuring:
 ```js
 const arr = ['a', 'b', 'c'];
 for (let [index, elem] of arr.entries()) {
   console.log(index, ': ', elem);
 }
 ```
 "
fe,Explain the difference between mutable and immutable objects.,javascript,"Immutability is a core principle in functional programming, and has lots to offer to object-oriented programs as well. A mutable object is an object whose state can be modified after it is created. An immutable object is an object whose state cannot be modified after it is created.
 "
fe,What is an example of an immutable object in JavaScript?,javascript,"In JavaScript, some built-in types (numbers, strings) are immutable, but custom objects are generally mutable.
 Some built-in immutable JavaScript objects are `Math`, `Date`.
 Here are a few ways to add/simulate immutability on plain JavaScript objects.
 **Object Constant Properties**
 By combining `writable: false` and `configurable: false`, you can essentially create a constant (cannot be changed, redefined or deleted) as an object property, like:
 ```js
 let myObject = {};
 Object.defineProperty(myObject, 'number', {
   value: 42,
   writable: false,
   configurable: false,
 });
 console.log(myObject.number); // 42
 myObject.number = 43;
 console.log(myObject.number); // 42
 ```
 **Prevent Extensions**
 If you want to prevent an object from having new properties added to it, but otherwise leave the rest of the object's properties alone, call `Object.preventExtensions(...)`:
 ```js
 var myObject = {
   a: 2,
 };
 Object.preventExtensions(myObject);
 myObject.b = 3;
 myObject.b; // undefined
 ```
 In non-strict mode, the creation of `b` fails silently. In strict mode, it throws a `TypeError`.
 **Seal**
 `Object.seal()` creates a ""sealed"" object, which means it takes an existing object and essentially calls `Object.preventExtensions()` on it, but also marks all its existing properties as `configurable: false`.
 So, not only can you not add any more properties, but you also cannot reconfigure or delete any existing properties (though you can still modify their values).
 **Freeze**
 `Object.freeze()` creates a frozen object, which means it takes an existing object and essentially calls `Object.seal()` on it, but it also marks all ""data accessor"" properties as writable:false, so that their values cannot be changed.
 This approach is the highest level of immutability that you can attain for an object itself, as it prevents any changes to the object or to any of its direct properties (though, as mentioned above, the contents of any referenced other objects are unaffected).
 ```js
 var immutable = Object.freeze({});
 ```
 Freezing an object does not allow new properties to be added to an object and prevents from removing or altering the existing properties. `Object.freeze()` preserves the enumerability, configurability, writability and the prototype of the object. It returns the passed object and does not create a frozen copy.
 "
fe,What are the pros and cons of immutability?,javascript,"**Pros**
 - Easier change detection - Object equality can be determined in a performant and easy manner through referential equality. This is useful for comparing object differences in React and Redux.
 - Programs with immutable objects are less complicated to think about, since you don't need to worry about how an object may evolve over time.
 - Defensive copies are no longer necessary when immutable objects are returning from or passed to functions, since there is no possibility an immutable object will be modified by it.
 - Easy sharing via references - One copy of an object is just as good as another, so you can cache objects or reuse the same object multiple times.
 - Thread-safe - Immutable objects can be safely used between threads in a multi-threaded environment since there is no risk of them being modified in other concurrently running threads.
 - Using libraries like ImmutableJS, objects are modified using structural sharing and less memory is needed for having multiple objects with similar structures.
 **Cons**
 - Naive implementations of immutable data structures and its operations can result in extremely poor performance because new objects are created each time. It is recommended to use libraries for efficient immutable data structures and operations that leverage on structural sharing.
 - Allocation (and deallocation) of many small objects rather than modifying existing ones can cause a performance impact. The complexity of either the allocator or the garbage collector usually depends on the number of objects on the heap.
 - Cyclic data structures such as graphs are difficult to build. If you have two objects which can't be modified after initialization, how can you get them to point to each other?
 "
fe,How can you achieve immutability in your own code?,javascript,"One way to achieve immutability is to use libraries like [immutable.js](http://facebook.github.io/immutable-js/), [mori](https://github.com/swannodette/mori) or [immer](https://github.com/immerjs/immer).
 The alternative is to use `const` declarations combined with the techniques mentioned above for creation. For ""mutating"" objects, use the spread operator, `Object.assign`, `Array.concat()`, etc., to create new objects instead of mutate the original object.
 Examples:
 ```js
 // Array Example
 const arr = [1, 2, 3];
 const newArr = [...arr, 4]; // [1, 2, 3, 4]
 // Object Example
 const human = Object.freeze({race: 'human'});
 const john = {...human, name: 'John'}; // {race: ""human"", name: ""John""}
 const alienJohn = {...john, race: 'alien'}; // {race: ""alien"", name: ""John""}
 ```
 "
fe,Explain the difference between synchronous and asynchronous functions.,javascript,"Synchronous functions are blocking while asynchronous functions are not. In synchronous functions, statements complete before the next statement is run. In this case, the program is evaluated exactly in order of the statements and execution of the program is paused if one of the statements take a very long time.
 Asynchronous functions usually accept a callback as a parameter and execution continue on the next line immediately after the asynchronous function is invoked. The callback is only invoked when the asynchronous operation is complete and the call stack is empty. Heavy duty operations such as loading data from a web server or querying a database should be done asynchronously so that the main thread can continue executing other operations instead of blocking until that long operation to complete (in the case of browsers, the UI will freeze).
 "
fe,What is event loop? What is the difference between call stack and task queue?,javascript,"The event loop is a single-threaded loop that monitors the call stack and checks if there is any work to be done in the task queue. If the call stack is empty and there are callback functions in the task queue, a function is dequeued and pushed onto the call stack to be executed.
 If you haven't already checked out Philip Robert's [talk on the Event Loop](https://2014.jsconf.eu/speakers/philip-roberts-what-the-heck-is-the-event-loop-anyway.html), you should. It is one of the most viewed videos on JavaScript.
 "
fe,Explain the differences on the usage of `foo` between `function foo() {}` and `var foo = function() {}`,javascript,"The former is a function declaration while the latter is a function expression. The key difference is that function declarations have its body hoisted but the bodies of function expressions are not (they have the same hoisting behavior as variables). For more explanation on hoisting, refer to the question above [on hoisting](#explain-hoisting). If you try to invoke a function expression before it is defined, you will get an `Uncaught TypeError: XXX is not a function` error.
 **Function Declaration**
 ```js
 foo(); // 'FOOOOO'
 function foo() {
   console.log('FOOOOO');
 }
 ```
 **Function Expression**
 ```js
 foo(); // Uncaught TypeError: foo is not a function
 var foo = function () {
   console.log('FOOOOO');
 };
 ```
 "
fe,"What are the differences between variables created using `let`, `var` or `const`?",javascript,"Variables declared using the `var` keyword are scoped to the function in which they are created, or if created outside of any function, to the global object. `let` and `const` are _block scoped_, meaning they are only accessible within the nearest set of curly braces (function, if-else block, or for-loop).
 ```js
 function foo() {
   // All variables are accessible within functions.
   var bar = 'bar';
   let baz = 'baz';
   const qux = 'qux';
   console.log(bar); // bar
   console.log(baz); // baz
   console.log(qux); // qux
 }
 console.log(bar); // ReferenceError: bar is not defined
 console.log(baz); // ReferenceError: baz is not defined
 console.log(qux); // ReferenceError: qux is not defined
 ```
 ```js
 if (true) {
   var bar = 'bar';
   let baz = 'baz';
   const qux = 'qux';
 }
 // var declared variables are accessible anywhere in the function scope.
 console.log(bar); // bar
 // let and const defined variables are not accessible outside of the block they were defined in.
 console.log(baz); // ReferenceError: baz is not defined
 console.log(qux); // ReferenceError: qux is not defined
 ```
 `var` allows variables to be hoisted, meaning they can be referenced in code before they are declared. `let` and `const` will not allow this, instead throwing an error.
 ```js
 console.log(foo); // undefined
 var foo = 'foo';
 console.log(baz); // ReferenceError: can't access lexical declaration 'baz' before initialization
 let baz = 'baz';
 console.log(bar); // ReferenceError: can't access lexical declaration 'bar' before initialization
 const bar = 'bar';
 ```
 Redeclaring a variable with `var` will not throw an error, but `let` and `const` will.
 ```js
 var foo = 'foo';
 var foo = 'bar';
 console.log(foo); // ""bar""
 let baz = 'baz';
 let baz = 'qux'; // Uncaught SyntaxError: Identifier 'baz' has already been declared
 ```
 `let` and `const` differ in that `let` allows reassigning the variable's value while `const` does not.
 ```js
 // This is fine.
 let foo = 'foo';
 foo = 'bar';
 // This causes an exception.
 const baz = 'baz';
 baz = 'qux';
 ```
 "
fe,What are the differences between ES6 class and ES5 function constructors?,javascript,"Let's first look at example of each:
 ```js
 // ES5 Function Constructor
 function Person(name) {
   this.name = name;
 }
 // ES6 Class
 class Person {
   constructor(name) {
     this.name = name;
   }
 }
 ```
 For simple constructors, they look pretty similar.
 The main difference in the constructor comes when using inheritance. If we want to create a `Student` class that subclasses `Person` and add a `studentId` field, this is what we have to do in addition to the above.
 ```js
 // ES5 Function Constructor
 function Student(name, studentId) {
   // Call constructor of superclass to initialize superclass-derived members.
   Person.call(this, name);
   // Initialize subclass's own members.
   this.studentId = studentId;
 }
 Student.prototype = Object.create(Person.prototype);
 Student.prototype.constructor = Student;
 // ES6 Class
 class Student extends Person {
   constructor(name, studentId) {
     super(name);
     this.studentId = studentId;
   }
 }
 ```
 It's much more verbose to use inheritance in ES5 and the ES6 version is easier to understand and remember.
 "
fe,Can you offer a use case for the new arrow => function syntax? How does this new syntax differ from other functions?,javascript,"One obvious benefit of arrow functions is to simplify the syntax needed to create functions, without a need for the `function` keyword. The `this` within arrow functions is also bound to the enclosing scope which is different compared to regular functions where the `this` is determined by the object calling it. Lexically-scoped `this` is useful when invoking callbacks especially in React components.
 "
fe,What advantage is there for using the arrow syntax for a method in a constructor?,javascript,"The main advantage of using an arrow function as a method inside a constructor is that the value of `this` gets set at the time of the function creation and can't change after that. So, when the constructor is used to create a new object, `this` will always refer to that object. For example, let's say we have a `Person` constructor that takes a first name as an argument has two methods to `console.log` that name, one as a regular function and one as an arrow function:
 ```js
 const Person = function (firstName) {
   this.firstName = firstName;
   this.sayName1 = function () {
     console.log(this.firstName);
   };
   this.sayName2 = () => {
     console.log(this.firstName);
   };
 };
 const john = new Person('John');
 const dave = new Person('Dave');
 john.sayName1(); // John
 john.sayName2(); // John
 // The regular function can have its 'this' value changed, but the arrow function cannot
 john.sayName1.call(dave); // Dave (because ""this"" is now the dave object)
 john.sayName2.call(dave); // John
 john.sayName1.apply(dave); // Dave (because 'this' is now the dave object)
 john.sayName2.apply(dave); // John
 john.sayName1.bind(dave)(); // Dave (because 'this' is now the dave object)
 john.sayName2.bind(dave)(); // John
 var sayNameFromWindow1 = john.sayName1;
 sayNameFromWindow1(); // undefined (because 'this' is now the window object)
 var sayNameFromWindow2 = john.sayName2;
 sayNameFromWindow2(); // John
 ```
 The main takeaway here is that `this` can be changed for a normal function, but the context always stays the same for an arrow function. So even if you are passing around your arrow function to different parts of your application, you wouldn't have to worry about the context changing.
 This can be particularly helpful in React class components. If you define a class method for something such as a click handler using a normal function, and then you pass that click handler down into a child component as a prop, you will need to also bind `this` in the constructor of the parent component. If you instead use an arrow function, there is no need to also bind ""this"", as the method will automatically get its ""this"" value from its enclosing lexical context. (See this article for an excellent demonstration and sample code: https://medium.com/@machnicki/handle-events-in-react-with-arrow-functions-ede88184bbb)
 "
fe,What is the definition of a higher-order function?,javascript,"A higher-order function is any function that takes one or more functions as arguments, which it uses to operate on some data, and/or returns a function as a result. Higher-order functions are meant to abstract some operation that is performed repeatedly. The classic example of this is `map`, which takes an array and a function as arguments. `map` then uses this function to transform each item in the array, returning a new array with the transformed data. Other popular examples in JavaScript are `forEach`, `filter`, and `reduce`. A higher-order function doesn't just need to be manipulating arrays as there are many use cases for returning a function from another function. `Function.prototype.bind` is one such example in JavaScript.
 **Map**
 Let say we have an array of names which we need to transform each string to uppercase.
 ```js
 const names = ['irish', 'daisy', 'anna'];
 ```
 The imperative way will be as such:
 ```js
 const transformNamesToUppercase = function (names) {
   const results = [];
   for (let i = 0; i < names.length; i++) {
     results.push(names[i].toUpperCase());
   }
   return results;
 };
 transformNamesToUppercase(names); // ['IRISH', 'DAISY', 'ANNA']
 ```
 Use `.map(transformerFn)` makes the code shorter and more declarative.
 ```js
 const transformNamesToUppercase = function (names) {
   return names.map((name) => name.toUpperCase());
 };
 transformNamesToUppercase(names); // ['IRISH', 'DAISY', 'ANNA']
 ```
 "
fe,Can you give an example for destructuring an object or an array?,javascript,"Destructuring is an expression available in ES6 which enables a succinct and convenient way to extract values of Objects or Arrays and place them into distinct variables.
 **Array destructuring**
 ```js
 // Variable assignment.
 const foo = ['one', 'two', 'three'];
 const [one, two, three] = foo;
 console.log(one); // ""one""
 console.log(two); // ""two""
 console.log(three); // ""three""
 ```
 ```js
 // Swapping variables
 let a = 1;
 let b = 3;
 [a, b] = [b, a];
 console.log(a); // 3
 console.log(b); // 1
 ```
 **Object destructuring**
 ```js
 // Variable assignment.
 const o = {p: 42, q: true};
 const {p, q} = o;
 console.log(p); // 42
 console.log(q); // true
 ```
 "
fe,"ES6 Template Literals offer a lot of flexibility in generating strings, can you give an example?",javascript,"Template literals help make it simple to do string interpolation, or to include variables in a string. Before ES2015, it was common to do something like this:
 ```js
 var person = {name: 'Tyler', age: 28};
 console.log(
   'Hi, my name is ' + person.name + ' and I am ' + person.age + ' years old!',
 );
 // 'Hi, my name is Tyler and I am 28 years old!'
 ```
 With template literals, you can now create that same output like this instead:
 ```js
 const person = {name: 'Tyler', age: 28};
 console.log(`Hi, my name is ${person.name} and I am ${person.age} years old!`);
 // 'Hi, my name is Tyler and I am 28 years old!'
 ```
 Note that you use backticks, not quotes, to indicate that you are using a template literal and that you can insert expressions inside the `${}` placeholders.
 A second helpful use case is in creating multi-line strings. Before ES2015, you could create a multi-line string like this:
 ```js
 console.log('This is line one.\nThis is line two.');
 // This is line one.
 // This is line two.
 ```
 Or if you wanted to break it up into multiple lines in your code so you didn't have to scroll to the right in your text editor to read a long string, you could also write it like this:
 ```js
 console.log('This is line one.\n' + 'This is line two.');
 // This is line one.
 // This is line two.
 ```
 Template literals, however, preserve whatever spacing you add to them. For example, to create that same multi-line output that we created above, you can simply do:
 ```js
 console.log(`This is line one.
 This is line two.`);
 // This is line one.
 // This is line two.
 ```
 Another use case of template literals would be to use as a substitute for templating libraries for simple variable interpolations:
 ```js
 const person = {name: 'Tyler', age: 28};
 document.body.innerHTML = `
   <div>
     <p>Name: ${person.name}</p>
     <p>Age: ${person.age}</p>
   </div>
 `;
 ```
 **Note that your code may be susceptible to XSS by using `.innerHTML`. Sanitize your data before displaying it if it came from a user!**
 "
fe,Can you give an example of a curry function and why this syntax offers an advantage?,javascript,"Currying is a pattern where a function with more than one parameter is broken into multiple functions that, when called in series, will accumulate all of the required parameters one at a time. This technique can be useful for making code written in a functional style easier to read and compose. It's important to note that for a function to be curried, it needs to start out as one function, then broken out into a sequence of functions that each accepts one parameter.
 ```js
 function curry(fn) {
   if (fn.length === 0) {
     return fn;
   }
   function _curried(depth, args) {
     return function (newArgument) {
       if (depth - 1 === 0) {
         return fn(...args, newArgument);
       }
       return _curried(depth - 1, [...args, newArgument]);
     };
   }
   return _curried(fn.length, []);
 }
 function add(a, b) {
   return a + b;
 }
 var curriedAdd = curry(add);
 var addFive = curriedAdd(5);
 var result = [0, 1, 2, 3, 4, 5].map(addFive); // [5, 6, 7, 8, 9, 10]
 ```
 "
fe,What are the benefits of using spread syntax and how is it different from rest syntax?,javascript,"ES6's spread syntax is very useful when coding in a functional paradigm as we can easily create copies of arrays or objects without resorting to `Object.create`, `slice`, or a library function. This language feature is used often in Redux and RxJS projects.
 ```js
 function putDookieInAnyArray(arr) {
   return [...arr, 'dookie'];
 }
 const result = putDookieInAnyArray(['I', 'really', ""don't"", 'like']); // [""I"", ""really"", ""don't"", ""like"", ""dookie""]
 const person = {
   name: 'Todd',
   age: 29,
 };
 const copyOfTodd = {...person};
 ```
 ES6's rest syntax offers a shorthand for including an arbitrary number of arguments to be passed to a function. It is like an inverse of the spread syntax, taking data and stuffing it into an array rather than unpacking an array of data, and it works in function arguments, as well as in array and object destructuring assignments.
 ```js
 function addFiveToABunchOfNumbers(...numbers) {
   return numbers.map((x) => x + 5);
 }
 const result = addFiveToABunchOfNumbers(4, 5, 6, 7, 8, 9, 10); // [9, 10, 11, 12, 13, 14, 15]
 const [a, b, ...rest] = [1, 2, 3, 4]; // a: 1, b: 2, rest: [3, 4]
 const {e, f, ...others} = {
   e: 1,
   f: 2,
   g: 3,
   h: 4,
 }; // e: 1, f: 2, others: { g: 3, h: 4 }
 ```
 "
fe,How can you share code between files?,javascript,"This depends on the JavaScript environment.
 On the client (browser environment), as long as the variables/functions are declared in the global scope (`window`), all scripts can refer to them. Alternatively, adopt the Asynchronous Module Definition (AMD) via RequireJS for a more modular approach.
 On the server (Node.js), the common way has been to use CommonJS. Each file is treated as a module and it can export variables and functions by attaching them to the `module.exports` object.
 ES2015 defines a module syntax which aims to replace both AMD and CommonJS. This will eventually be supported in both browser and Node environments.
 "
fe,Why you might want to create static class members?,javascript,"Static class members (properties/methods) are not tied to a specific instance of a class and have the same value regardless of which instance is referring to it. Static properties are typically configuration variables and static methods are usually pure utility functions which do not depend on the state of the instance.
 "
